hydra:
  run:
    dir: ./pipeline
    
praw:
  praw_output: praw_output.csv
  subreddits:
    - datascience
    - MachineLearning
    - ChatGPT
    - CharacterAI
    - cybersecurity

sentiment:
  input_file: praw_output.csv
  output_file: sentiment_analysis_output.csv
  model_name: distilbert-base-uncased-finetuned-sst-2-english
  output_dir: wordcloud_images

extract:
  extraction_model_name: 'google/flan-t5-small'
  reddit_dataset: sentiment_analysis_output.csv
  reddit_results_file: reddit_keywords.csv

top_keywords:
  reddit_results_file: reddit_keywords.csv
  top_n: 20
  output_dir: reddit_keywords_results


base_model_name: facebook/bart-large
save_model_name: 'tech-keywords-extractor_finetuned_bart'
saved_model_in_hf: '/Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/outputs/2024-09-16/12-47-35/tech-keywords-extractor_finetuned_bart'
# saved_model_in_hf: 'wbcmthh42/bart_tech_keywords_model2'

# base_model_name: google/flan-t5-large
# save_model_name: 'tech-keywords-extractor_finetuned_t5'
dataset_name: ilsilfverskiold/tech-keywords-topics-summary

output_dir: './bart_tech_keywords_model'

#Training
training:
  num_train_epochs: 3
  warmup_steps: 500
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  weight_decay: 0.01
  logging_steps: 10
  evaluation_strategy: 'steps'
  eval_steps: 50
  save_steps: 1e6
  gradient_accumulation_steps: 16

#Evaluation
eval:
  # evaluation_model_name: 'google/flan-t5-large'
  # evaluation_model_name: 'facebook/bart-large'
  evaluation_model_name: /Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/outputs/2024-09-16/08-48-55/tech-keywords-extractor_finetuned_t5
  # evaluation_model_name: ./outputs/2024-09-16/12-47-35/tech-keywords-extractor_finetuned_bart
  # evaluation_model_name: ./finetune_llm/model_checkpoint_bert

  # results_file: ${hydra:output}/evaluation_results/T5_base_model_results.csv
  results_file: ${hydra:output}/evaluation_results/bart_base_model_results.csv
  # results_file: ${hydra:output}/evaluation_results/t5_finetuned_model_results.csv
  # results_file: ${hydra:output}/evaluation_results/bart_finetuned_model_results.csv

reddit_dataset: /Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/data/sentiment_by_vader_sentlevel.csv
reddit_results_file: /Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/reddit_keywords_results/reddit_keywords.csv
reddit_results_file_for_ui: /Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/reddit_keywords_results/reddit_keywords_hybrid.csv

reddit_inference:
  batch_size: 256
  inference_row_limit: 400000

get_trending_keywords:
  top_n: 20
  output_dir: /Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/reddit_keywords_results

date_range:
  from_date: '2022-01-01'
  until_date: '2024-10-03'
max_results: 200000
output_file: '/Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/arxiv/arxiv_papers_2022_2024_with_links_final.csv'

embedding_model:
  name: "sentence-transformers/all-MiniLM-L6-v2"

vector_store:
  persist_directory: "./vector_store"

search:
  top_n: 15

summary:
  word_limit: 30