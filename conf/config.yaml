hydra:
  run:
    dir: ./pipeline
    
praw:
  praw_output: praw_output.csv
  subreddits:
    - datascience
    - MachineLearning
    - ChatGPT
    - CharacterAI
    - cybersecurity

sentiment:
  input_file: praw_output.csv
  output_file: sentiment_analysis_output.csv
  model_name: distilbert-base-uncased-finetuned-sst-2-english
  output_dir: wordcloud_images

extract:
  extraction_model_name: 'google/flan-t5-small'
  reddit_dataset: sentiment_analysis_output.csv
  reddit_results_file: reddit_keywords.csv

top_keywords:
  reddit_results_file: reddit_keywords.csv
  top_n: 20
  output_dir: reddit_keywords_results


base_model_name: facebook/bart-large
save_model_name: 'tech-keywords-extractor_finetuned_bart'
# base_model_name: google/flan-t5-large
# save_model_name: 'tech-keywords-extractor_finetuned_t5'
dataset_name: ilsilfverskiold/tech-keywords-topics-summary

output_dir: './bart_tech_keywords_model'

#Training
training:
  num_train_epochs: 3
  warmup_steps: 500
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  weight_decay: 0.01
  logging_steps: 10
  evaluation_strategy: 'steps'
  eval_steps: 50
  save_steps: 1e6
  gradient_accumulation_steps: 16

#Evaluation
eval:
  # evaluation_model_name: 'google/flan-t5-large'
  # evaluation_model_name: 'facebook/bart-large'
  evaluation_model_name: /Users/tayjohnny/Documents/My_MTECH/PLP/plp_practice_proj/outputs/2024-09-16/08-48-55/tech-keywords-extractor_finetuned_t5
  # evaluation_model_name: ./outputs/2024-09-16/12-47-35/tech-keywords-extractor_finetuned_bart
  # evaluation_model_name: ./finetune_llm/model_checkpoint_bert

  # results_file: ${hydra:output}/evaluation_results/T5_base_model_results.csv
  results_file: ${hydra:output}/evaluation_results/bart_base_model_results.csv
  # results_file: ${hydra:output}/evaluation_results/t5_finetuned_model_results.csv
  # results_file: ${hydra:output}/evaluation_results/bart_finetuned_model_results.csv

