Title,Summary,Published,Category
"MaxMind: A Memory Loop Network to Enhance Software Productivity based on
  Large Language Models","  The application of large language models to facilitate automated software
operations and tool generation (SOTG), thus augmenting software productivity,
mirrors the early stages of human evolution when the ability to create and use
tools accelerated the progress of civilization. These complex tasks require AI
to continuously summarize and improve. Current research often overlooks the
importance of converting real-time task experiences into system memory and
differentiating the value of existing knowledge for future reference. This
paper addresses these issues by evolving external memory models into
Memory-Loop Networks for timely memorization and experience referencing. We
also enhance a RAG mechanism with knowledge precision segmentation to utilize
memory based on value differentiation, and design the MaxMind model for SOTG
accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an
electronic spreadsheet processing system aligned with the MaxMind philosophy.
Comparative experiments with SheetCopilot have demonstrated that the
accumulation and recycling of task memories lead to a steady enhancement in
task success rate, with an improvement rate of approximately 3%-6% per round in
this implementation example. Note that as the memories continue to grow, this
cumulative improvement may be substantial. The inclusion of memory recycling
can also boost the system's task execution efficiency by up to 25%, and it can
address the retraining issue faced by LLMs when handling specialized tasks
through memories transfer.These suggest that MaxMind has significant potential
to enhance the capabilities and productivity of LLM systems in SOTG.
",2024-08-07 15:27:22+00:00,cs.SE
"Improving the quality of Persian clinical text with a novel spelling
  correction system","  Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.
",2024-08-07 08:31:42+00:00,cs.CL
"Automatic identification of the area covered by acorn trees in the
  dehesa (pastureland) Extremadura of Spain","  The acorn is the fruit of the oak and is an important crop in the Spanish
dehesa extreme\~na, especially for the value it provides in the Iberian pig
food to obtain the ""acorn"" certification. For this reason, we want to maximise
the production of Iberian pigs with the appropriate weight. Hence the need to
know the area covered by the crowns of the acorn trees, to determine the
covered wooded area (CWA, from the Spanish Superficie Arbolada Cubierta SAC)
and thereby estimate the number of Iberian pigs that can be released per
hectare, as indicated by the royal decree 4/2014. In this work, we propose the
automatic estimation of the CWA, through aerial digital images (orthophotos) of
the pastureland of Extremadura, and with this, to offer the possibility of
determining the number of Iberian pigs to be released in a specific plot of
land. Among the main issues for automatic detection are, first, the correct
identification of acorn trees, secondly, correctly discriminating the shades of
the acorn trees and, finally, detect the arbuscles (young acorn trees not yet
productive, or shrubs that are not oaks). These difficulties represent a real
challenge, both for the automatic segmentation process and for manual
segmentation. In this work, the proposed method for automatic segmentation is
based on the clustering algorithm proposed by Gustafson-Kessel (GK) but the
modified version of Babuska (GK-B) and on the use of real orthophotos. The
obtained results are promising both in their comparison with the real images
and when compared with the images segmented by hand. The whole set of
orthophotos used in this work correspond to an approximate area of 142
hectares, and the results are of great interest to producers of certified
""acorn"" pork.
",2024-08-07 04:42:10+00:00,cs.CV
"HeTraX: Energy Efficient 3D Heterogeneous Manycore Architecture for
  Transformer Acceleration","  Transformers have revolutionized deep learning and generative modeling to
enable unprecedented advancements in natural language processing tasks and
beyond. However, designing hardware accelerators for executing transformer
models is challenging due to the wide variety of computing kernels involved in
the transformer architecture. Existing accelerators are either inadequate to
accelerate end-to-end transformer models or suffer notable thermal limitations.
In this paper, we propose the design of a three-dimensional heterogeneous
architecture referred to as HeTraX specifically optimized to accelerate
end-to-end transformer models. HeTraX employs hardware resources aligned with
the computational kernels of transformers and optimizes both performance and
energy. Experimental results show that HeTraX outperforms existing
state-of-the-art by up to 5.6x in speedup and improves EDP by 14.5x while
ensuring thermally feasibility.
",2024-08-06 18:48:01+00:00,cs.AR
Potential and Limitation of High-Frequency Cores and Caches,"  This paper explores the potential of cryogenic computing and superconducting
electronics as promising alternatives to traditional semiconductor devices. As
semiconductor devices face challenges such as increased leakage currents and
reduced performance at higher temperatures, these novel technologies offer high
performance and low power computation. Cryogenic computing operates at
ultra-low temperatures near 77 K, leading to lower leakage currents and
improved electron mobility. On the other hand, superconducting electronics,
operating near 0 K, allow electrons to flow without resistance, offering the
potential for ultra-low-power, high-speed computation. This study presents a
comprehensive performance modeling and analysis of these technologies and
provides insights into their potential benefits and limitations. We implement
models of in-order and out-of-order cores operating at high clock frequencies
associated with superconducting electronics and cryogenic computing in gem5. We
evaluate the performance of these components using workloads representative of
real-world applications like NPB, SPEC CPU2006, and GAPBS. Our results show the
potential speedups achievable by these components and the limitations posed by
cache bandwidth. This work provides valuable insights into the performance
implications and design trade-offs associated with cryogenic and
superconducting technologies, laying the foundation for future research in this
field using gem5.
",2024-08-06 17:16:19+00:00,cs.AR
"Training on the Fly: On-device Self-supervised Learning aboard
  Nano-drones within 20 mW","  Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning
(TinyML), such as nano-drones, are becoming an increasingly attractive
technology. Their small form factor (i.e., ~10cm diameter) ensures vast
applicability, ranging from the exploration of narrow disaster scenarios to
safe human-robot interaction. Simple electronics make these CPSes inexpensive,
but strongly limit the computational, memory, and sensing resources available
on board. In real-world applications, these limitations are further exacerbated
by domain shift. This fundamental machine learning problem implies that model
perception performance drops when moving from the training domain to a
different deployment one. To cope with and mitigate this general problem, we
present a novel on-device fine-tuning approach that relies only on the limited
ultra-low power resources available aboard nano-drones. Then, to overcome the
lack of ground-truth training labels aboard our CPS, we also employ a
self-supervised method based on ego-motion consistency. Albeit our work builds
on top of a specific real-world vision-based human pose estimation task, it is
widely applicable for many embedded TinyML use cases. Our 512-image on-device
training procedure is fully deployed aboard an ultra-low power GWT GAP9
System-on-Chip and requires only 1MB of memory while consuming as low as 19mW
or running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our
on-device learning approach by field-testing our closed-loop CPS, showing a
reduction in horizontal position error of up to 26% vs. a non-fine-tuned
state-of-the-art baseline. In the most challenging never-seen-before
environment, our on-device learning procedure makes the difference between
succeeding or failing the mission.
",2024-08-06 13:11:36+00:00,cs.RO
"Integrating Large Language Models and Knowledge Graphs for Extraction
  and Validation of Textual Test Data","  Aerospace manufacturing companies, such as Thales Alenia Space, design,
develop, integrate, verify, and validate products characterized by high
complexity and low volume. They carefully document all phases for each product
but analyses across products are challenging due to the heterogeneity and
unstructured nature of the data in documents. In this paper, we propose a
hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with
Large Language Models (LLMs) to extract and validate data contained in these
documents. We consider a case study focused on test data related to electronic
boards for satellites. To do so, we extend the Semantic Sensor Network
ontology. We store the metadata of the reports in a KG, while the actual test
results are stored in parquet accessible via a Virtual Knowledge Graph. The
validation process is managed using an LLM-based approach. We also conduct a
benchmarking study to evaluate the performance of state-of-the-art LLMs in
executing this task. Finally, we analyze the costs and benefits of automating
preexisting processes of manual data extraction and validation for subsequent
cross-report analyses.
",2024-08-03 07:42:53+00:00,cs.AI
"Accelerating Domain-Aware Electron Microscopy Analysis Using Deep
  Learning Models with Synthetic Data and Image-Wide Confidence Scoring","  The integration of machine learning (ML) models enhances the efficiency,
affordability, and reliability of feature detection in microscopy, yet their
development and applicability are hindered by the dependency on scarce and
often flawed manually labeled datasets and a lack of domain awareness. We
addressed these challenges by creating a physics-based synthetic image and data
generator, resulting in a machine learning model that achieves comparable
precision (0.86), recall (0.63), F1 scores (0.71), and engineering property
predictions (R2=0.82) to a model trained on human-labeled data. We enhanced
both models by using feature prediction confidence scores to derive an
image-wide confidence metric, enabling simple thresholding to eliminate
ambiguous and out-of-domain images resulting in performance boosts of 5-30%
with a filtering-out rate of 25%. Our study demonstrates that synthetic data
can eliminate human reliance in ML and provides a means for domain awareness in
cases where many feature detections per image are needed.
",2024-08-02 20:15:15+00:00,cs.CV
Solid-State Oxide-Ion Synaptic Transistor for Neuromorphic Computing,"  Neuromorphic hardware facilitates rapid and energy-efficient training and
operation of neural network models for artificial intelligence. However,
existing analog in-memory computing devices, like memristors, continue to face
significant challenges that impede their commercialization. These challenges
include high variability due to their stochastic nature. Microfabricated
electrochemical synapses offer a promising approach by functioning as an analog
programmable resistor based on deterministic ion-insertion mechanisms. Here, we
developed an all-solid-state oxide-ion synaptic transistor employing
$\text{Bi}_2\text{V}_{0.9}\text{Cu}_{0.1}\text{O}_{5.35}$ as a superior
oxide-ion conductor electrolyte and
$\text{La}_\text{0.5}\text{Sr}_\text{0.5}\text{F}\text{O}_\text{3-$\delta$}$ as
a variable resistance channel able to efficiently operate at temperatures
compatible with conventional electronics. Our transistor exhibits essential
synaptic behaviors such as long- and short-term potentiation, paired-pulse
facilitation, and post-tetanic potentiation, mimicking fundamental properties
of biological neural networks. Key criteria for efficient neuromorphic
computing are satisfied, including excellent linear and symmetric synaptic
plasticity, low energy consumption per programming pulse, and high endurance
with minimal cycle-to-cycle variation. Integrated into an artificial neural
network (ANN) simulation for handwritten digit recognition, the presented
synaptic transistor achieved a 96% accuracy on the MNIST dataset, illustrating
the effective implementation of our device in ANNs. These findings demonstrate
the potential of oxide-ion based synaptic transistors for effective
implementation in analog neuromorphic computing based on iontronics.
",2024-08-01 10:15:51+00:00,cs.ET
"Optimizing Disease Prediction with Artificial Intelligence Driven
  Feature Selection and Attention Networks","  The rapid integration of machine learning methodologies in healthcare has
ignited innovative strategies for disease prediction, particularly with the
vast repositories of Electronic Health Records (EHR) data. This article delves
into the realm of multi-disease prediction, presenting a comprehensive study
that introduces a pioneering ensemble feature selection model. This model,
designed to optimize learning systems, combines statistical, deep, and
optimally selected features through the innovative Stabilized Energy Valley
Optimization with Enhanced Bounds (SEV-EB) algorithm. The objective is to
achieve unparalleled accuracy and stability in predicting various disorders.
This work proposes an advanced ensemble model that synergistically integrates
statistical, deep, and optimally selected features. This combination aims to
enhance the predictive power of the model by capturing diverse aspects of the
health data. At the heart of the proposed model lies the SEV-EB algorithm, a
novel approach to optimal feature selection. The algorithm introduces enhanced
bounds and stabilization techniques, contributing to the robustness and
accuracy of the overall prediction model. To further elevate the predictive
capabilities, an HSC-AttentionNet is introduced. This network architecture
combines deep temporal convolution capabilities with LSTM, allowing the model
to capture both short-term patterns and long-term dependencies in health data.
Rigorous evaluations showcase the remarkable performance of the proposed model.
Achieving a 95% accuracy and 94% F1-score in predicting various disorders, the
model surpasses traditional methods, signifying a significant advancement in
disease prediction accuracy. The implications of this research extend beyond
the confines of academia.
",2024-07-31 14:12:27+00:00,cs.LG
"Self-Sovereign Identity for Consented and Content-Based Access to
  Medical Records using Blockchain","  Electronic Health Records (EHRs) and Medical Data are classified as personal
data in every privacy law, meaning that any related service that includes
processing such data must come with full security, confidentiality, privacy and
accountability. Solutions for health data management, as in storing it, sharing
and processing it, are emerging quickly and were significantly boosted by the
Covid-19 pandemic that created a need to move things online. EHRs makes a
crucial part of digital identity data, and the same digital identity trends --
as in self sovereign identity powered by decentralized ledger technologies like
Blockchain, are being researched or implemented in contexts managing digital
interactions between health facilities, patients and health professionals. In
this paper, we propose a blockchain-based solution enabling secure exchange of
EHRs between different parties powered by a self-sovereign identity (SSI)
wallet and decentralized identifiers. We also make use of a consortium IPFS
network for off-chain storage and attribute-based encryption (ABE) to ensure
data confidentiality and integrity. Through our solution, we grant users full
control over their medical data, and enable them to securely share it in total
confidentiality over secure communication channels between user wallets using
encryption. We also use DIDs for better user privacy and limit any possible
correlations or identification by using pairwise DIDs. Overall, combining this
set of technologies guarantees secure exchange of EHRs, secure storage and
management along with by-design features inherited from the technological
stack.
",2024-07-31 12:27:31+00:00,cs.CR
"Blink: Fast Automated Design of Run-Time Power Monitors on FPGA-Based
  Computing Platforms","  The current over-provisioned heterogeneous multi-cores require effective
run-time optimization strategies, and the run-time power monitoring subsystem
is paramount for their success. Several state-of-the-art methodologies address
the design of a run-time power monitoring infrastructure for generic computing
platforms. However, the power model's training requires time-consuming
gate-level simulations that, coupled with the ever-increasing complexity of the
modern heterogeneous platforms, dramatically hinder the usability of such
solutions. This paper introduces Blink, a scalable framework for the fast and
automated design of run-time power monitoring infrastructures targeting
computing platforms implemented on FPGA. Blink optimizes the time-to-solution
to deliver the run-time power monitoring infrastructure by replacing
traditional methodologies' gate-level simulations and power trace computations
with behavioral simulations and direct power trace measurements. Applying Blink
to multiple designs mixing a set of HLS-generated accelerators from a
state-of-the-art benchmark suite demonstrates an average time-to-solution
speedup of 18 times without affecting the quality of the run-time power
estimates.
",2024-07-31 06:31:41+00:00,cs.AR
Functional ISS-Driven Verification of Superscalar RISC-V Processors,"  A time-efficient and comprehensive verification is a fundamental part of the
design process for modern computing platforms, and it becomes ever more
important and critical to optimize as the latter get ever more complex.
SupeRFIVe is a methodology for the functional verification of superscalar
processors that leverages an instruction set simulator to validate their
correctness according to a simulation-based approach, interfacing a testbench
for the design under test with the instruction set simulator by means of socket
communication. We demonstrate the effectiveness of the SupeRFIVe methodology by
applying it to verify the functional correctness of a RISC-V dual-issue
superscalar CPU, leveraging the state-of-the-art RISC-V instruction set
simulator Spike and executing a set of benchmark applications from the open
literature.
",2024-07-30 21:00:21+00:00,cs.AR
"Multi-task Photonic Reservoir Computing: Wavelength Division
  Multiplexing for Parallel Computing with a Silicon Microring Resonator","  Nowadays, as the ever-increasing demand for more powerful computing resources
continues, alternative advanced computing paradigms are under extensive
investigation. Significant effort has been made to deviate from conventional
Von Neumann architectures. In-memory computing has emerged in the field of
electronics as a possible solution to the infamous bottleneck between memory
and computing processors, which reduces the effective throughput of data. In
photonics, novel schemes attempt to collocate the computing processor and
memory in a single device. Photonics offers the flexibility of multiplexing
streams of data not only spatially and in time, but also in frequency or,
equivalently, in wavelength, which makes it highly suitable for parallel
computing. Here, we numerically show the use of time and wavelength division
multiplexing (WDM) to solve four independent tasks at the same time in a single
photonic chip, serving as a proof of concept for our proposal. The system is a
time-delay reservoir computing (TDRC) based on a microring resonator (MRR). The
addressed tasks cover different applications: Time-series prediction, waveform
signal classification, wireless channel equalization, and radar signal
prediction. The system is also tested for simultaneous computing of up to 10
instances of the same task, exhibiting excellent performance. The footprint of
the system is reduced by using time-division multiplexing of the nodes that act
as the neurons of the studied neural network scheme. WDM is used for the
parallelization of wavelength channels, each addressing a single task. By
adjusting the input power and frequency of each optical channel, we can achieve
levels of performance for each of the tasks that are comparable to those quoted
in state-of-the-art reports focusing on single-task operation...
",2024-07-30 20:54:07+00:00,cs.NE
"Evolutionary Approximation of Ternary Neurons for On-sensor Printed
  Neural Networks","  Printed electronics offer ultra-low manufacturing costs and the potential for
on-demand fabrication of flexible hardware. However, significant intrinsic
constraints stemming from their large feature sizes and low integration density
pose design challenges that hinder their practicality. In this work, we conduct
a holistic exploration of printed neural network accelerators, starting from
the analog-to-digital interface - a major area and power sink for sensor
processing applications - and extending to networks of ternary neurons and
their implementation. We propose bespoke ternary neural networks using
approximate popcount and popcount-compare units, developed through a
multi-phase evolutionary optimization approach and interfaced with sensors via
customizable analog-to-binary converters. Our evaluation results show that the
presented designs outperform the state of the art, achieving at least 6x
improvement in area and 19x in power. To our knowledge, they represent the
first open-source digital printed neural network classifiers capable of
operating with existing printed energy harvesters.
",2024-07-30 06:51:13+00:00,cs.AR
"Brain-inspired polymer dendrite networks for morphology-dependent
  computing hardware","  Variability has always been a challenge to mitigate in electronics. This
especially holds true for organic semiconductors, where reproducibility and
long-term stability concerns hinder industrialization. By relying on a
bio-inspired computing paradigm, we show that AC-electropolymerization is a
powerful platform for the development of morphology-dependent computing
hardware. Our findings reveal that electropolymerized polymer dendrite networks
exhibit a complex relationship between structure and operation that allows them
to implement nearly linear to nonlinear functions depending on the complexity
of their structure. Moreover, dendritic networks can integrate a limitless
number of inputs from their environment, for which their unique morphologies
induce specific patterns in the dynamic encoding of the network's output. We
demonstrate that this property can be used to our advantage in the context of
in materio computing to discriminate between different spatiotemporal inputs.
These results show how, due to its inherent stochasticity,
electropolymerization is a pivotal technique for the bottom-up implementation
of computationally powerful objects. We anticipate this study will help
shifting the negative perception of variability in the material science
community and promote the electropolymerization framework as a foundation for
the development of a new generation of hardware defined by its topological
richness.
",2024-07-29 09:58:01+00:00,cs.ET
"Enhancing material property prediction with ensemble deep graph
  convolutional networks","  Machine learning (ML) models have emerged as powerful tools for accelerating
materials discovery and design by enabling accurate predictions of properties
from compositional and structural data. These capabilities are vital for
developing advanced technologies across fields such as energy, electronics, and
biomedicine, potentially reducing the time and resources needed for new
material exploration and promoting rapid innovation cycles. Recent efforts have
focused on employing advanced ML algorithms, including deep learning - based
graph neural network, for property prediction. Additionally, ensemble models
have proven to enhance the generalizability and robustness of ML and DL.
However, the use of such ensemble strategies in deep graph networks for
material property prediction remains underexplored. Our research provides an
in-depth evaluation of ensemble strategies in deep learning - based graph
neural network, specifically targeting material property prediction tasks. By
testing the Crystal Graph Convolutional Neural Network (CGCNN) and its
multitask version, MT-CGCNN, we demonstrated that ensemble techniques,
especially prediction averaging, substantially improve precision beyond
traditional metrics for key properties like formation energy per atom ($\Delta
E^{f}$), band gap ($E_{g}$) and density ($\rho$) in 33,990 stable inorganic
materials. These findings support the broader application of ensemble methods
to enhance predictive accuracy in the field.
",2024-07-26 16:12:06+00:00,cs.LG
"Is larger always better? Evaluating and prompting large language models
  for non-generative medical tasks","  The use of Large Language Models (LLMs) in medicine is growing, but their
ability to handle both structured Electronic Health Record (EHR) data and
unstructured clinical notes is not well-studied. This study benchmarks various
models, including GPT-based LLMs, BERT-based models, and traditional clinical
predictive models, for non-generative medical tasks utilizing renowned
datasets. We assessed 14 language models (9 GPT-based and 5 BERT-based) and 7
traditional predictive models using the MIMIC dataset (ICU patient records) and
the TJH dataset (early COVID-19 EHR data), focusing on tasks such as mortality
and readmission prediction, disease hierarchy reconstruction, and biomedical
sentence matching, comparing both zero-shot and finetuned performance. Results
indicated that LLMs exhibited robust zero-shot predictive capabilities on
structured EHR data when using well-designed prompting strategies, frequently
surpassing traditional models. However, for unstructured medical texts, LLMs
did not outperform finetuned BERT models, which excelled in both supervised and
unsupervised tasks. Consequently, while LLMs are effective for zero-shot
learning on structured data, finetuned BERT models are more suitable for
unstructured texts, underscoring the importance of selecting models based on
specific task requirements and data characteristics to optimize the application
of NLP technology in healthcare.
",2024-07-26 06:09:10+00:00,cs.CL
SMiCRM: A Benchmark Dataset of Mechanistic Molecular Images,"  Optical chemical structure recognition (OCSR) systems aim to extract the
molecular structure information, usually in the form of molecular graph or
SMILES, from images of chemical molecules. While many tools have been developed
for this purpose, challenges still exist due to different types of noises that
might exist in the images. Specifically, we focus on the 'arrow-pushing'
diagrams, a typical type of chemical images to demonstrate electron flow in
mechanistic steps. We present Structural molecular identifier of Molecular
images in Chemical Reaction Mechanisms (SMiCRM), a dataset designed to
benchmark machine recognition capabilities of chemical molecules with
arrow-pushing annotations. Comprising 453 images, it spans a broad array of
organic chemical reactions, each illustrated with molecular structures and
mechanistic arrows. SMiCRM offers a rich collection of annotated molecule
images for enhancing the benchmarking process for OCSR methods. This dataset
includes a machine-readable molecular identity for each image as well as
mechanistic arrows showing electron flow during chemical reactions. It presents
a more authentic and challenging task for testing molecular recognition
technologies, and achieving this task can greatly enrich the mechanisitic
information in computer-extracted chemical reaction data.
",2024-07-25 18:52:10+00:00,cs.CV
"Investigation to answer three key questions concerning plant pest
  identification and development of a practical identification framework","  The development of practical and robust automated diagnostic systems for
identifying plant pests is crucial for efficient agricultural production. In
this paper, we first investigate three key research questions (RQs) that have
not been addressed thus far in the field of image-based plant pest
identification. Based on the knowledge gained, we then develop an accurate,
robust, and fast plant pest identification framework using 334K images
comprising 78 combinations of four plant portions (the leaf front, leaf back,
fruit, and flower of cucumber, tomato, strawberry, and eggplant) and 20 pest
species captured at 27 farms. The results reveal the following. (1) For an
appropriate evaluation of the model, the test data should not include images of
the field from which the training images were collected, or other
considerations to increase the diversity of the test set should be taken into
account. (2) Pre-extraction of ROIs, such as leaves and fruits, helps to
improve identification accuracy. (3) Integration of closely related species
using the same control methods and cross-crop training methods for the same
pests, are effective. Our two-stage plant pest identification framework,
enabling ROI detection and convolutional neural network (CNN)-based
identification, achieved a highly practical performance of 91.0% and 88.5% in
mean accuracy and macro F1 score, respectively, for 12,223 instances of test
data of 21 classes collected from unseen fields, where 25 classes of images
from 318,971 samples were used for training; the average identification time
was 476 ms/image.
",2024-07-25 12:49:24+00:00,cs.CV
"Synthetic High-resolution Cryo-EM Density Maps with Generative
  Adversarial Networks","  Generating synthetic cryogenic electron microscopy (cryo-EM) 3D density maps
from molecular structures has potential important applications in structural
biology. Yet existing simulation-based methods cannot mimic all the complex
features present in experimental maps, such as secondary structure elements. As
an alternative, we propose struc2mapGAN, a novel data-driven method that
employs a generative adversarial network (GAN) to produce high-resolution
experimental-like density maps from molecular structures. More specifically,
struc2mapGAN uses a U-Net++ architecture as the generator, with an additional
L1 loss term and further processing of raw experimental maps to enhance
learning efficiency. While struc2mapGAN can promptly generate maps after
training, we demonstrate that it outperforms existing simulation-based methods
for a wide array of tested maps and across various evaluation metrics. Our code
is available at https://github.com/chenwei-zhang/struc2mapGAN.
",2024-07-24 23:47:05+00:00,cs.LG
"What Matters in Explanations: Towards Explainable Fake Review Detection
  Focusing on Transformers","  Customers' reviews and feedback play crucial role on electronic
commerce~(E-commerce) platforms like Amazon, Zalando, and eBay in influencing
other customers' purchasing decisions. However, there is a prevailing concern
that sellers often post fake or spam reviews to deceive potential customers and
manipulate their opinions about a product. Over the past decade, there has been
considerable interest in using machine learning (ML) and deep learning (DL)
models to identify such fraudulent reviews. Unfortunately, the decisions made
by complex ML and DL models - which often function as \emph{black-boxes} - can
be surprising and difficult for general users to comprehend. In this paper, we
propose an explainable framework for detecting fake reviews with high precision
in identifying fraudulent content with explanations and investigate what
information matters most for explaining particular decisions by conducting
empirical user evaluation. Initially, we develop fake review detection models
using DL and transformer models including XLNet and DistilBERT. We then
introduce layer-wise relevance propagation (LRP) technique for generating
explanations that can map the contributions of words toward the predicted
class. The experimental results on two benchmark fake review detection datasets
demonstrate that our predictive models achieve state-of-the-art performance and
outperform several existing methods. Furthermore, the empirical user evaluation
of the generated explanations concludes which important information needs to be
considered in generating explanations in the context of fake review
identification.
",2024-07-24 13:26:02+00:00,cs.CL
"Robust Deep Hawkes Process under Label Noise of Both Event and
  Occurrence","  Integrating deep neural networks with the Hawkes process has significantly
improved predictive capabilities in finance, health informatics, and
information technology. Nevertheless, these models often face challenges in
real-world settings, particularly due to substantial label noise. This issue is
of significant concern in the medical field, where label noise can arise from
delayed updates in electronic medical records or misdiagnoses, leading to
increased prediction risks. Our research indicates that deep Hawkes process
models exhibit reduced robustness when dealing with label noise, particularly
when it affects both event types and timing. To address these challenges, we
first investigate the influence of label noise in approximated intensity
functions and present a novel framework, the Robust Deep Hawkes Process (RDHP),
to overcome the impact of label noise on the intensity function of Hawkes
models, considering both the events and their occurrences. We tested RDHP using
multiple open-source benchmarks with synthetic noise and conducted a case study
on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting
with inherent label noise. The results demonstrate that RDHP can effectively
perform classification and regression tasks, even in the presence of noise
related to events and their timing. To the best of our knowledge, this is the
first study to successfully address both event and time label noise in deep
Hawkes process models, offering a promising solution for medical applications,
specifically in diagnosing OSAHS.
",2024-07-24 11:12:01+00:00,cs.LG
"Transformer-based Capacity Prediction for Lithium-ion Batteries with
  Data Augmentation","  Lithium-ion batteries are pivotal to technological advancements in
transportation, electronics, and clean energy storage. The optimal operation
and safety of these batteries require proper and reliable estimation of battery
capacities to monitor the state of health. Current methods for estimating the
capacities fail to adequately account for long-term temporal dependencies of
key variables (e.g., voltage, current, and temperature) associated with battery
aging and degradation. In this study, we explore the usage of transformer
networks to enhance the estimation of battery capacity. We develop a
transformer-based battery capacity prediction model that accounts for both
long-term and short-term patterns in battery data. Further, to tackle the data
scarcity issue, data augmentation is used to increase the data size, which
helps to improve the performance of the model. Our proposed method is validated
with benchmark datasets. Simulation results show the effectiveness of data
augmentation and the transformer network in improving the accuracy and
robustness of battery capacity prediction.
",2024-07-22 20:21:40+00:00,cs.LG
"Model editing for distribution shifts in uranium oxide morphological
  analysis","  Deep learning still struggles with certain kinds of scientific data. Notably,
pretraining data may not provide coverage of relevant distribution shifts
(e.g., shifts induced via the use of different measurement instruments). We
consider deep learning models trained to classify the synthesis conditions of
uranium ore concentrates (UOCs) and show that model editing is particularly
effective for improving generalization to distribution shifts common in this
domain. In particular, model editing outperforms finetuning on two curated
datasets comprising of micrographs taken of U$_{3}$O$_{8}$ aged in humidity
chambers and micrographs acquired with different scanning electron microscopes,
respectively.
",2024-07-22 16:06:51+00:00,cs.LG
"Customized Retrieval Augmented Generation and Benchmarking for EDA Tool
  Documentation QA","  Retrieval augmented generation (RAG) enhances the accuracy and reliability of
generative AI models by sourcing factual information from external databases,
which is extensively employed in document-grounded question-answering (QA)
tasks. Off-the-shelf RAG flows are well pretrained on general-purpose
documents, yet they encounter significant challenges when being applied to
knowledge-intensive vertical domains, such as electronic design automation
(EDA). This paper addresses such issue by proposing a customized RAG framework
along with three domain-specific techniques for EDA tool documentation QA,
including a contrastive learning scheme for text embedding model fine-tuning, a
reranker distilled from proprietary LLM, and a generative LLM fine-tuned with
high-quality domain corpus. Furthermore, we have developed and released a
documentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced
RTL-to-GDSII design platform. Experimental results demonstrate that our
proposed RAG flow and techniques have achieved superior performance on ORD-QA
as well as on a commercial tool, compared with state-of-the-arts. The ORD-QA
benchmark and the training dataset for our customized RAG flow are open-source
at https://github.com/lesliepy99/RAG-EDA.
",2024-07-22 03:44:27+00:00,cs.CL
"Mapping Patient Trajectories: Understanding and Visualizing Sepsis
  Prognostic Pathways from Patients Clinical Narratives","  In recent years, healthcare professionals are increasingly emphasizing on
personalized and evidence-based patient care through the exploration of
prognostic pathways. To study this, structured clinical variables from
Electronic Health Records (EHRs) data have traditionally been employed by many
researchers. Presently, Natural Language Processing models have received great
attention in clinical research which expanded the possibilities of using
clinical narratives. In this paper, we propose a systematic methodology for
developing sepsis prognostic pathways derived from clinical notes, focusing on
diverse patient subgroups identified by exploring comorbidities associated with
sepsis and generating explanations of these subgroups using SHAP. The extracted
prognostic pathways of these subgroups provide valuable insights into the
dynamic trajectories of sepsis severity over time. Visualizing these pathways
sheds light on the likelihood and direction of disease progression across
various contexts and reveals patterns and pivotal factors or biomarkers
influencing the transition between sepsis stages, whether toward deterioration
or improvement. This empowers healthcare providers to implement more
personalized and effective healthcare strategies for individual patients.
",2024-07-20 14:45:55+00:00,cs.CL
"Intelligent Artistic Typography: A Comprehensive Review of Artistic Text
  Design and Generation","  Artistic text generation aims to amplify the aesthetic qualities of text
while maintaining readability. It can make the text more attractive and better
convey its expression, thus enjoying a wide range of application scenarios such
as social media display, consumer electronics, fashion, and graphic design.
Artistic text generation includes artistic text stylization and semantic
typography. Artistic text stylization concentrates on the text effect overlaid
upon the text, such as shadows, outlines, colors, glows, and textures. By
comparison, semantic typography focuses on the deformation of the characters to
strengthen their visual representation by mimicking the semantic understanding
within the text. This overview paper provides an introduction to both artistic
text stylization and semantic typography, including the taxonomy, the key ideas
of representative methods, and the applications in static and dynamic artistic
text generation. Furthermore, the dataset and evaluation metrics are
introduced, and the future directions of artistic text generation are
discussed. A comprehensive list of artistic text generation models studied in
this review is available at
https://github.com/williamyang1991/Awesome-Artistic-Typography/.
",2024-07-20 06:45:09+00:00,cs.CV
"LaMAGIC: Language-Model-based Topology Generation for Analog Integrated
  Circuits","  In the realm of electronic and electrical engineering, automation of analog
circuit is increasingly vital given the complexity and customized requirements
of modern applications. However, existing methods only develop search-based
algorithms that require many simulation iterations to design a custom circuit
topology, which is usually a time-consuming process. To this end, we introduce
LaMAGIC, a pioneering language model-based topology generation model that
leverages supervised finetuning for automated analog circuit design. LaMAGIC
can efficiently generate an optimized circuit design from the custom
specification in a single pass. Our approach involves a meticulous development
and analysis of various input and output formulations for circuit. These
formulations can ensure canonical representations of circuits and align with
the autoregressive nature of LMs to effectively addressing the challenges of
representing analog circuits as graphs. The experimental results show that
LaMAGIC achieves a success rate of up to 96\% under a strict tolerance of 0.01.
We also examine the scalability and adaptability of LaMAGIC, specifically
testing its performance on more complex circuits. Our findings reveal the
enhanced effectiveness of our adjacency matrix-based circuit formulation with
floating-point input, suggesting its suitability for handling intricate circuit
designs. This research not only demonstrates the potential of language models
in graph generation, but also builds a foundational framework for future
explorations in automated analog circuit design.
",2024-07-19 22:51:41+00:00,cs.AR
"Blockchain in Healthcare: Implementing Hyperledger Fabric for Electronic
  Health Records at Frere Provincial Hospital","  As healthcare systems worldwide continue to grapple with the challenges of
interoperability, data security, and accessibility, integrating emerging
technologies becomes imperative. This paper investigates the implementation of
blockchain technology, specifically Hyperledger Fabric, for Electronic Health
Records (EHR) management at Frere Hospital in the Eastern Cape province of
South Africa. The paper examines the benefits and challenges of integrating
blockchain into healthcare information systems. Hyperledger Fabric's modular
architecture is harnessed to create a secure, transparent, and decentralized
platform for storing, managing, and sharing EHRs among stakeholders. The study
used a mixed-methods approach, integrating case studies and data collection
methods through observation and informal questions, with the specific goal of
understanding current record management methods and challenges. This method
offers practical insights and validates the approach. The result demonstrates
the role of blockchain in transforming healthcare, framed within a rigorous
exploration and analysis. The findings of this study have broader implications
for healthcare institutions seeking advanced solutions to address the
persistent challenges in electronic health record management. Ultimately, the
research underscores the transformative potential of blockchain technology in
healthcare settings, fostering trust, security, and efficiency in the
management of sensitive patient data.
",2024-07-19 14:27:55+00:00,cs.CR
Generative Language Model for Catalyst Discovery,"  Discovery of novel and promising materials is a critical challenge in the
field of chemistry and material science, traditionally approached through
methodologies ranging from trial-and-error to machine learning-driven inverse
design. Recent studies suggest that transformer-based language models can be
utilized as material generative models to expand chemical space and explore
materials with desired properties. In this work, we introduce the Catalyst
Generative Pretrained Transformer (CatGPT), trained to generate string
representations of inorganic catalyst structures from a vast chemical space.
CatGPT not only demonstrates high performance in generating valid and accurate
catalyst structures but also serves as a foundation model for generating
desired types of catalysts by fine-tuning with sparse and specified datasets.
As an example, we fine-tuned the pretrained CatGPT using a binary alloy
catalyst dataset designed for screening two-electron oxygen reduction reaction
(2e-ORR) catalyst and generate catalyst structures specialized for 2e-ORR. Our
work demonstrates the potential of language models as generative tools for
catalyst discovery.
",2024-07-19 05:34:08+00:00,cs.LG
Three-State Information Hiding: Provably Secure Asymmetric Steganography,"  The rise of language models has provided a fertile ground for the application
of steganography. Due to their qualified output, steganographic texts become
similar to human and have attracted most of the steganography researchers'
attention. However, running a language model requires a strong computation
platform. It limits the applicable scenario of steganography, since those
electronic devices controlled by the decoder may not even equipped with a GPU.
Traditional provably secure steganography methods cannot be applied to this
low-resource scenario. Therefore, we aim at design a novel steganography
framework that is practical in a low-resource scheme. We start from the
rigorous probability analysis with the help of hypothesis testing techniques to
construct an theoretical framework. Then we prove the security and robostness
of our framework and point out its optimization goal. We test our theoretical
framework in some famous LLMs and the results have proved its usability. There
are still some practical problems and this gives the direction of future work.
We hope that this work will expand the practical scope of steganography and
create a new branch of steganography.
",2024-07-18 13:32:00+00:00,cs.CR
End-To-End Clinical Trial Matching with Large Language Models,"  Matching cancer patients to clinical trials is essential for advancing
treatment and patient care. However, the inconsistent format of medical free
text documents and complex trial eligibility criteria make this process
extremely challenging and time-consuming for physicians. We investigated
whether the entire trial matching process - from identifying relevant trials
among 105,600 oncology-related clinical trials on clinicaltrials.gov to
generating criterion-level eligibility matches - could be automated using Large
Language Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic
Health Records (EHRs), we demonstrate that our approach identifies relevant
candidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%
when matching patient-level information at the criterion level against a
baseline defined by human experts. Utilizing LLM feedback reveals that 39.3%
criteria that were initially considered incorrect are either ambiguous or
inaccurately annotated, leading to a total model accuracy of 92.7% after
refining our human baseline. In summary, we present an end-to-end pipeline for
clinical trial matching using LLMs, demonstrating high precision in screening
and matching trials to individual patients, even outperforming the performance
of qualified medical doctors. Our fully end-to-end pipeline can operate
autonomously or with human supervision and is not restricted to oncology,
offering a scalable solution for enhancing patient-trial matching in real-world
settings.
",2024-07-18 12:36:26+00:00,cs.CL
"Quantum Key Distribution Routing Protocol in Quantum Networks: Overview
  and Challenges","  The use of quantum cryptography in everyday applications has gained attention
in both industrial and academic fields. Due to advancements in quantum
electronics, practical quantum devices are already available in the market, and
ready for wider use. Quantum Key Distribution (QKD) is a crucial aspect of
quantum cryptography, which involves generating and distributing symmetric
cryptographic keys between geographically separated users using principles of
quantum physics. Many successful QKD networks have been established to test
different solutions. The objective of this paper is to delve into the potential
of utilizing established routing design techniques in the context of quantum
key distribution, a field distinguished by its unique properties rooted in the
principles of quantum mechanics. However, the implementation of these
techniques poses substantial challenges, including quantum memory decoherence,
key rate generation, latency delays, inherent noise in quantum systems, limited
communication ranges, and the necessity for highly specialized hardware. This
paper conducts an in-depth examination of essential research pertaining to the
design methodologies for quantum key distribution. It also explores the
fundamental aspects of quantum routing and the associated properties inherent
to quantum QKD. This paper elucidates the necessary steps for constructing
efficient and resilient QKD networks. In summarizing the techniques relevant to
QKD networking and routing, including their underlying principles, protocols,
and challenges, this paper sheds light on potential applications and delineates
future research directions in this burgeoning field.
",2024-07-18 04:46:32+00:00,cs.CR
"An Evaluation of Continual Learning for Advanced Node Semiconductor
  Defect Inspection","  Deep learning-based semiconductor defect inspection has gained traction in
recent years, offering a powerful and versatile approach that provides high
accuracy, adaptability, and efficiency in detecting and classifying nano-scale
defects. However, semiconductor manufacturing processes are continually
evolving, leading to the emergence of new types of defects over time. This
presents a significant challenge for conventional supervised defect detectors,
as they may suffer from catastrophic forgetting when trained on new defect
datasets, potentially compromising performance on previously learned tasks. An
alternative approach involves the constant storage of previously trained
datasets alongside pre-trained model versions, which can be utilized for
(re-)training from scratch or fine-tuning whenever encountering a new defect
dataset. However, adhering to such a storage template is impractical in terms
of size, particularly when considering High-Volume Manufacturing (HVM).
Additionally, semiconductor defect datasets, especially those encompassing
stochastic defects, are often limited and expensive to obtain, thus lacking
sufficient representation of the entire universal set of defectivity. This work
introduces a task-agnostic, meta-learning approach aimed at addressing this
challenge, which enables the incremental addition of new defect classes and
scales to create a more robust and generalized model for semiconductor defect
inspection. We have benchmarked our approach using real resist-wafer SEM
(Scanning Electron Microscopy) datasets for two process steps, ADI and AEI,
demonstrating its superior performance compared to conventional supervised
training methods.
",2024-07-17 16:41:22+00:00,cs.CV
"SENTAUR: Security EnhaNced Trojan Assessment Using LLMs Against
  Undesirable Revisions","  A globally distributed IC supply chain brings risks due to untrusted third
parties. The risks span inadvertent use of hardware Trojan (HT), inserted
Intellectual Property (3P-IP) or Electronic Design Automation (EDA) flows. HT
can introduce stealthy HT behavior, prevent an IC work as intended, or leak
sensitive data via side channels. To counter HTs, rapidly examining HT
scenarios is a key requirement. While Trust-Hub benchmarks are a good starting
point to assess defenses, they encompass a small subset of manually created HTs
within the expanse of HT designs. Further, the HTs may disappear during
synthesis. We propose a large language model (LLM) framework SENTAUR to
generate a suite of legitimate HTs for a Register Transfer Level (RTL) design
by learning its specifications, descriptions, and natural language descriptions
of HT effects. Existing tools and benchmarks are limited; they need a learning
period to construct an ML model to mimic the threat model and are difficult to
reproduce. SENTAUR can swiftly produce HT instances by leveraging LLMs without
any learning period and sanitizing the HTs facilitating their rapid assessment.
Evaluation of SENTAUR involved generating effective, synthesizable, and
practical HTs from TrustHub and elsewhere, investigating impacts of
payloads/triggers at the RTL. While our evaluation focused on HT insertion,
SENTAUR can generalize to automatically transform an RTL code to have defined
functional modifications.
",2024-07-17 07:13:06+00:00,cs.CR
"MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and
  Large Language Models","  Electronic health records (EHRs) are multimodal by nature, consisting of
structured tabular features like lab tests and unstructured clinical notes. In
real-life clinical practice, doctors use complementary multimodal EHR data
sources to get a clearer picture of patients' health and support clinical
decision-making. However, most EHR predictive models do not reflect these
procedures, as they either focus on a single modality or overlook the
inter-modality interactions/redundancy. In this work, we propose MEDFuse, a
Multimodal EHR Data Fusion framework that incorporates masked lab-test modeling
and large language models (LLMs) to effectively integrate structured and
unstructured medical data. MEDFuse leverages multimodal embeddings extracted
from two sources: LLMs fine-tuned on free clinical text and masked tabular
transformers trained on structured lab test results. We design a disentangled
transformer module, optimized by a mutual information loss to 1) decouple
modality-specific and modality-shared information and 2) extract useful joint
representation from the noise and redundancy present in clinical notes. Through
comprehensive validation on the public MIMIC-III dataset and the in-house FEMH
dataset, MEDFuse demonstrates great potential in advancing clinical
predictions, achieving over 90% F1 score in the 10-disease multi-label
classification task.
",2024-07-17 04:17:09+00:00,cs.CL
"The Patchkeeper: An Integrated Wearable Electronic Stethoscope with
  Multiple Sensors","  Many parts of human body generate internal sound during biological processes,
which are rich sources of information for understanding health and wellbeing.
Despite a long history of development and usage of stethoscopes, there is still
a lack of proper tools for recording internal body sound together with
complementary sensors for long term monitoring. In this paper, we show our
development of a wearable electronic stethoscope, coined Patchkeeper (PK), that
can be used for internal body sound recording over long periods of time.
Patchkeeper also integrates several state-of-the-art biological sensors,
including electrocardiogram (ECG), photoplethysmography (PPG), and inertial
measurement unit (IMU) sensors. As a wearable device, Patchkeeper can be placed
on various parts of the body to collect sound from particular organs, including
heart, lung, stomach, and joints etc. We show in this paper that several vital
signals can be recorded simultaneously with high quality. As Patchkeeper can be
operated directly by the user, e.g. without involving health care
professionals, we believe it could be a useful tool for telemedicine and remote
diagnostics.
",2024-07-16 15:22:10+00:00,cs.HC
"FabGPT: An Efficient Large Multimodal Model for Complex Wafer Defect
  Knowledge Queries","  Intelligence is key to advancing integrated circuit (IC) fabrication. Recent
breakthroughs in Large Multimodal Models (LMMs) have unlocked unparalleled
abilities in understanding images and text, fostering intelligent fabrication.
Leveraging the power of LMMs, we introduce FabGPT, a customized IC fabrication
large multimodal model for wafer defect knowledge query. FabGPT manifests
expertise in conducting defect detection in Scanning Electron Microscope (SEM)
images, performing root cause analysis, and providing expert question-answering
(Q&A) on fabrication processes. FabGPT matches enhanced multimodal features to
automatically detect minute defects under complex wafer backgrounds and reduce
the subjectivity of manual threshold settings. Besides, the proposed modulation
module and interactive corpus training strategy embed wafer defect knowledge
into the pre-trained model, effectively balancing Q&A queries related to defect
knowledge and original knowledge and mitigating the modality bias issues.
Experiments on in-house fab data (SEM-WaD) show that our FabGPT achieves
significant performance improvement in wafer defect detection and knowledge
querying.
",2024-07-15 15:25:45+00:00,cs.CV
"Stacking-Enhanced Bagging Ensemble Learning for Breast Cancer
  Classification with CNN","  This paper proposes a CNN classification network based on Bagging and
stacking ensemble learning methods for breast cancer classification. The model
was trained and tested on the public dataset of DDSM. The model is capable of
fast and accurate classification of input images. According to our research
results, for binary classification (presence or absence of breast cancer), the
accuracy reached 98.84%, and for five-class classification, the accuracy
reached 98.34%. The model also achieved a micro-average recall rate of 94.80%
and an F1 score of 94.19%. In comparative experiments, we compared the effects
of different values of bagging_ratio and n_models on the model, as well as
several methods for ensemble bagging models. Furthermore, under the same
parameter settings, our BSECNN outperformed VGG16 and ResNet-50 in terms of
accuracy by 8.22% and 6.33% respectively.
",2024-07-15 09:44:43+00:00,cs.CV
Inertial Confinement Fusion Forecasting via LLMs,"  Controlled fusion energy is deemed pivotal for the advancement of human
civilization. In this study, we introduce $\textbf{Fusion-LLM}$, a novel
integration of Large Language Models (LLMs) with classical reservoir computing
paradigms tailored to address challenges in Inertial Confinement Fusion
($\texttt{ICF}$). Our approach offers several key contributions: Firstly, we
propose the $\textit{LLM-anchored Reservoir}$, augmented with a fusion-specific
prompt, enabling accurate forecasting of hot electron dynamics during
implosion. Secondly, we develop $\textit{Signal-Digesting Channels}$ to
temporally and spatially describe the laser intensity across time, capturing
the unique characteristics of $\texttt{ICF}$ inputs. Lastly, we design the
$\textit{Confidence Scanner}$ to quantify the confidence level in forecasting,
providing valuable insights for domain experts to design the $\texttt{ICF}$
process. Extensive experiments demonstrate the superior performance of our
method, achieving 1.90 CAE, 0.14 $\texttt{top-1}$ MAE, and 0.11
$\texttt{top-5}$ MAE in predicting Hard X-ray ($\texttt{HXR}$) energies of
$\texttt{ICF}$ tasks, which presents state-of-the-art comparisons against
concurrent best systems. Additionally, we present $\textbf{Fusion4AI}$, the
first $\texttt{ICF}$ benchmark based on physical experiments, aimed at
fostering novel ideas in plasma physics research and enhancing the utility of
LLMs in scientific exploration. Overall, our work strives to forge an
innovative synergy between AI and plasma science for advancing fusion energy.
",2024-07-15 05:46:44+00:00,cs.LG
DeepGate3: Towards Scalable Circuit Representation Learning,"  Circuit representation learning has shown promising results in advancing the
field of Electronic Design Automation (EDA). Existing models, such as DeepGate
Family, primarily utilize Graph Neural Networks (GNNs) to encode circuit
netlists into gate-level embeddings. However, the scalability of GNN-based
models is fundamentally constrained by architectural limitations, impacting
their ability to generalize across diverse and complex circuit designs. To
address these challenges, we introduce DeepGate3, an enhanced architecture that
integrates Transformer modules following the initial GNN processing. This novel
architecture not only retains the robust gate-level representation capabilities
of its predecessor, DeepGate2, but also enhances them with the ability to model
subcircuits through a novel pooling transformer mechanism. DeepGate3 is further
refined with multiple innovative supervision tasks, significantly enhancing its
learning process and enabling superior representation of both gate-level and
subcircuit structures. Our experiments demonstrate marked improvements in
scalability and generalizability over traditional GNN-based approaches,
establishing a significant step forward in circuit representation learning
technology.
",2024-07-15 02:44:21+00:00,cs.LG
A Study on Internet of Things in Women and Children Healthcare,"  Individual entities are being connected every day with the advancement of
Internet of Things (IoT). IoT contains various application domains and
healthcare is one of them indeed. It is receiving a lot of attention recently
because of its seamless integration with electronic health (eHealth) and
telemedicine. IoT has the capability of collecting patient data incessantly
which surely helps in preventive care. Doctors can diagnose their patients
early to avoid complications and they can suggest further modifications if
needed. As the whole process is automated, risk of errors is reduced.
Administrative paperwork and data entry tasks will be automated due to tracking
and connectivity. As a result, healthcare providers can engage themselves more
in patient care. In traditional healthcare services, an individual used to have
access to minimal insights into his own health. Hence, they were less conscious
about themselves and depended wholly on the healthcare facilities for
unfortunate events. But they can track their vitals, activities and fitness
with the aid of connected devices now. Furthermore, they can suggest their
preferred user interfaces. This paper describes several methods, practices and
prototypes regarding IoT in the field of healthcare for women and children.
",2024-07-14 17:34:00+00:00,cs.CY
"Cyber Attacks on Maritime Assets and their Impacts on Health and Safety
  Aboard: A Holistic View","  There has been an unprecedented digitization drive in the industrial sector,
especially in the maritime industry. The profusion of intelligent electronic
devices and IOT-enabled cyber-physical systems (CPS) has helped in the
efficient use of resources and increased convenience. CPS has enabled real-time
remote command and control of industrial assets. Unlike the relatively isolated
legacy systems, the intertwined nature of Information Technology(IT) and
Operations Technology(OT) brought by Industry 4.0 has increased the complexity
of the systems, thereby increasing the attack surface. This work explores the
possible consequences of these attacks from a more holistic view, focusing on
high-risk assets such as offshore oil rigs, offshore wind farms, and autonomous
vessels. The attacks have become more aggressive with the proliferation of such
technologies, disrupting the physical process, causing fire and explosion
hazards, and endangering human life and environmental health. The possible
attack scenarios, the attack vectors, and their physical consequences have been
discussed from the perspective of personnel safety and health, along with known
security breaches of such nature. To the best of the authors' knowledge, seldom
has any work been done that accentuates the possible human and environmental
impacts of such attacks.
",2024-07-11 11:20:36+00:00,cs.CR
"Predicting Heart Failure with Attention Learning Techniques Utilizing
  Cardiovascular Data","  Cardiovascular diseases (CVDs) encompass a group of disorders affecting the
heart and blood vessels, including conditions such as coronary artery disease,
heart failure, stroke, and hypertension. In cardiovascular diseases, heart
failure is one of the main causes of death and also long-term suffering in
patients worldwide. Prediction is one of the risk factors that is highly
valuable for treatment and intervention to minimize heart failure. In this
work, an attention learning-based heart failure prediction approach is proposed
on EHR(electronic health record) cardiovascular data such as ejection fraction
and serum creatinine. Moreover, different optimizers with various learning rate
approaches are applied to fine-tune the proposed approach. Serum creatinine and
ejection fraction are the two most important features to predict the patient's
heart failure. The computational result shows that the RMSProp optimizer with
0.001 learning rate has a better prediction based on serum creatinine. On the
other hand, the combination of SGD optimizer with 0.01 learning rate exhibits
optimum performance based on ejection fraction features. Overall, the proposed
attention learning-based approach performs very efficiently in predicting heart
failure compared to the existing state-of-the-art such as LSTM approach.
",2024-07-11 08:33:42+00:00,cs.AI
"OPIMA: Optical Processing-In-Memory for Convolutional Neural Network
  Acceleration","  Recent advances in machine learning (ML) have spotlighted the pressing need
for computing architectures that bridge the gap between memory bandwidth and
processing power. The advent of deep neural networks has pushed traditional Von
Neumann architectures to their limits due to the high latency and energy
consumption costs associated with data movement between the processor and
memory for these workloads. One of the solutions to overcome this bottleneck is
to perform computation within the main memory through processing-in-memory
(PIM), thereby limiting data movement and the costs associated with it.
However, DRAM-based PIM struggles to achieve high throughput and energy
efficiency due to internal data movement bottlenecks and the need for frequent
refresh operations. In this work, we introduce OPIMA, a PIM-based ML
accelerator, architected within an optical main memory. OPIMA has been designed
to leverage the inherent massive parallelism within main memory while
performing high-speed, low-energy optical computation to accelerate ML models
based on convolutional neural networks. We present a comprehensive analysis of
OPIMA to guide design choices and operational mechanisms. Additionally, we
evaluate the performance and energy consumption of OPIMA, comparing it with
conventional electronic computing systems and emerging photonic PIM
architectures. The experimental results show that OPIMA can achieve 2.98x
higher throughput and 137x better energy efficiency than the best-known prior
work.
",2024-07-11 06:12:04+00:00,cs.AR
"Can social media shape the security of next-generation connected
  vehicles?","  The increasing adoption of connectivity and electronic components in vehicles
makes these systems valuable targets for attackers. While automotive vendors
prioritize safety, there remains a critical need for comprehensive assessment
and analysis of cyber risks. In this context, this paper proposes a Social
Media Automotive Threat Intelligence (SOCMATI) framework, specifically designed
for the emerging field of automotive cybersecurity. The framework leverages
advanced intelligence techniques and machine learning models to extract
valuable insights from social media. Four use cases illustrate the framework's
potential by demonstrating how it can significantly enhance threat assessment
procedures within the automotive industry.
",2024-07-10 12:34:04+00:00,cs.SI
High-Resolution Cloud Detection Network,"  The complexity of clouds, particularly in terms of texture detail at high
resolutions, has not been well explored by most existing cloud detection
networks. This paper introduces the High-Resolution Cloud Detection Network
(HR-cloud-Net), which utilizes a hierarchical high-resolution integration
approach. HR-cloud-Net integrates a high-resolution representation module,
layer-wise cascaded feature fusion module, and multi-resolution pyramid pooling
module to effectively capture complex cloud features. This architecture
preserves detailed cloud texture information while facilitating feature
exchange across different resolutions, thereby enhancing overall performance in
cloud detection. Additionally, a novel approach is introduced wherein a student
view, trained on noisy augmented images, is supervised by a teacher view
processing normal images. This setup enables the student to learn from cleaner
supervisions provided by the teacher, leading to improved performance.
Extensive evaluations on three optical satellite image cloud detection datasets
validate the superior performance of HR-cloud-Net compared to existing
methods.The source code is available at
\url{https://github.com/kunzhan/HR-cloud-Net}.
",2024-07-10 04:54:03+00:00,cs.CV
"Several new classes of optimal ternary cyclic codes with two or three
  zeros","  Cyclic codes are a subclass of linear codes and have wide applications in
data storage systems, communication systems and consumer electronics due to
their efficient encoding and decoding algorithms. Let $\alpha $ be a generator
of $\mathbb{F}_{3^m}^*$, where $m$ is a positive integer. Denote by
$\mathcal{C}_{(i_1,i_2,\cdots, i_t)}$ the cyclic code with generator polynomial
$m_{\alpha^{i_1}}(x)m_{\alpha^{i_2}}(x)\cdots m_{\alpha^{i_t}}(x)$, where
${{m}_{\alpha^{i}}}(x)$ is the minimal polynomial of ${{\alpha }^{i}}$ over
${{\mathbb{F}}_{3}}$. In this paper, by analyzing the solutions of certain
equations over finite fields, we present four classes of optimal ternary cyclic
codes $\mathcal{C}_{(0,1,e)}$ and $\mathcal{C}_{(1,e,s)}$ with parameters
$[3^m-1,3^m-\frac{3m}{2}-2,4]$, where $s=\frac{3^m-1}{2}$. In addition, by
determining the solutions of certain equations and analyzing the irreducible
factors of certain polynomials over $\mathbb{F}_{3^m}$, we present four classes
of optimal ternary cyclic codes $\mathcal{C}_{(2,e)}$ and $\mathcal{C}_{(1,e)}$
with parameters $[3^m-1,3^m-2m-1,4]$. We show that our new optimal cyclic codes
are inequivalent to the known ones.
",2024-07-10 03:02:00+00:00,cs.IT
"A Physics Oriented Mathematical Vision for Creating Centered Trochoids
  and Co-Centered Ellipses Based on the Combination of Rolling and Sliding
  Motions","  The mathematical perspective for creating centered trochoids (through a solid
rule that is based on the pure rolling a circle along another circle) is
violated and changed it to a novel vision which is based on the combination of
rolling and sliding motions of a circle along another circle! In this new
vision we have not to define a centered trochoid as a path that is swept by an
attached point to a pure rolling circle along another circle. Instead, a
centered trochoid can be defined as a path that is swept by a definite point on
the circumference of a rolling and sliding circle along another one! In this
article we present two different methods for implement a definite combination
of sliding and rolling motions for a circle along another one in order to make
a simple experimental simulation to create centered trochoids and co-centered
ellipses. In our novel mathematical vision not only, the physical concepts are
playing basic role but also one can deduce the parametric equations of centered
trochoids and ellipses on the bases of rolling and sliding motions. In this
perspective, an ellipse can be visualized as a closed plane curve that can be
generated through a definite combination of rolling and sliding motions due to
two co-polarized rotational motions with different commensurable angular
frequencies! All the above subjects can be implemented with the help of Virtual
Rotating Circles Technique (VRCT) by an innovative device that we have named it
Mechanical Oscilloscope (MO). Although the function of our device is
independent from any electronic devices, but we can create these geometrical
objects on the bases of functional operation of (MO) with the help of computer.
This article establishes a strong link between mathematical vision and
meaningful physical concepts.
",2024-07-09 15:45:27+00:00,cs.GR
Joint prototype and coefficient prediction for 3D instance segmentation,"  3D instance segmentation is crucial for applications demanding comprehensive
3D scene understanding. In this paper, we introduce a novel method that
simultaneously learns coefficients and prototypes. Employing an overcomplete
sampling strategy, our method produces an overcomplete set of instance
predictions, from which the optimal ones are selected through a Non-Maximum
Suppression (NMS) algorithm during inference. The obtained prototypes are
visualizable and interpretable. Our method demonstrates superior performance on
S3DIS-blocks, consistently outperforming existing methods in mRec and mPrec.
Moreover, it operates 32.9% faster than the state-of-the-art. Notably, with
only 0.8% of the total inference time, our method exhibits an over 20-fold
reduction in the variance of inference time compared to existing methods. These
attributes render our method well-suited for practical applications requiring
both rapid inference and high reliability.
",2024-07-09 15:36:13+00:00,cs.CV
"FE-GUT: Factor Graph Optimization hybrid with Extended Kalman Filter for
  tightly coupled GNSS/UWB Integration","  Precise positioning and navigation information has been increasingly
important with the development of the consumer electronics market. Due to some
deficits of Global Navigation Satellite System (GNSS), such as susceptible to
interferences, integrating of GNSS with additional alternative sensors is a
promising approach to overcome the performance limitations of GNSS-based
localization systems. Ultra-Wideband (UWB) can be used to enhance GNSS in
constructing an integrated localization system. However, most low-cost UWB
devices lack a hardware-level time synchronization feature, which necessitates
the estimation and compensation of the time-offset in the tightly coupled
GNSS/UWB integration. Given the flexibility of probabilistic graphical models,
the time-offset can be modeled as an invariant constant in the discretization
of the continuous model. This work proposes a novel architecture in which
Factor Graph Optimization (FGO) is hybrid with Extend Kalman Filter (EKF) for
tightly coupled GNSS/UWB integration with online Temporal calibration (FE-GUT).
FGO is utilized to precisely estimate the time-offset, while EKF provides
initailization for the new factors and performs time-offset compensation.
Simulation-based experiments validate the integrated localization performance
of FE-GUT. In a four-wheeled robot scenario, the results demonstrate that,
compared to EKF, FE-GUT can improve horizontal and vertical localization
accuracy by 58.59\% and 34.80\%, respectively, while the time-offset estimation
accuracy is improved by 76.80\%. All the source codes and datasets can be
gotten via https://github.com/zhaoqj23/FE-GUT/.
",2024-07-09 14:50:14+00:00,cs.RO
Cue Point Estimation using Object Detection,"  Cue points indicate possible temporal boundaries in a transition between two
pieces of music in DJ mixing and constitute a crucial element in autonomous DJ
systems as well as for live mixing. In this work, we present a novel method for
automatic cue point estimation, interpreted as a computer vision object
detection task. Our proposed system is based on a pre-trained object detection
transformer which we fine-tune on our novel cue point dataset. Our provided
dataset contains 21k manually annotated cue points from human experts as well
as metronome information for nearly 5k individual tracks, making this dataset
35x larger than the previously available cue point dataset. Unlike previous
methods, our approach does not require low-level musical information analysis,
while demonstrating increased precision in retrieving cue point positions.
Moreover, our proposed method demonstrates high adherence to phrasing, a type
of high-level music structure commonly emphasized in electronic dance music.
The code, model checkpoints, and dataset are made publicly available.
",2024-07-09 12:56:30+00:00,cs.AI
iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine,"  The vision of IASIS project is to turn the wave of big biomedical data
heading our way into actionable knowledge for decision makers. This is achieved
by integrating data from disparate sources, including genomics, electronic
health records and bibliography, and applying advanced analytics methods to
discover useful patterns. The goal is to turn large amounts of available data
into actionable information to authorities for planning public health
activities and policies. The integration and analysis of these heterogeneous
sources of information will enable the best decisions to be made, allowing for
diagnosis and treatment to be personalised to each individual. The project
offers a common representation schema for the heterogeneous data sources. The
iASiS infrastructure is able to convert clinical notes into usable data,
combine them with genomic data, related bibliography, image data and more, and
create a global knowledge base. This facilitates the use of intelligent methods
in order to discover useful patterns across different resources. Using semantic
integration of data gives the opportunity to generate information that is rich,
auditable and reliable. This information can be used to provide better care,
reduce errors and create more confidence in sharing data, thus providing more
insights and opportunities. Data resources for two different disease categories
are explored within the iASiS use cases, dementia and lung cancer.
",2024-07-09 10:52:19+00:00,cs.AI
"Proceedings of the Thirteenth Workshop on Trends in Functional
  Programming in Education","  This volume of the Electronic Proceedings in Theoretical Computer Science
(EPTCS) contains revised selected papers that were initially presented at the
13th International Workshop on Trends in Functional Programming in Education
(TFPIE 2024). This workshop was held at Seton Hall University in South Orange,
NJ, USA on January 9, 2024. It was co-located with the 25th International
Symposium on Trends in Functional Programming (TFP 2024), which took place on
January 10-12, 2024.
  The goal of TFPIE is to gather researchers, teachers, and professionals that
use, or are interested in the use of, functional programming in education.
TFPIE aims to be a venue where novel ideas, classroom-tested ideas, and
works-in-progress on the use of functional programming in education are
discussed.
  TFPIE workshops have previously been held in St Andrews, Scotland (2012),
Provo, Utah, USA (2013), Soesterberg, The Netherlands (2014), Sophia-Antipolis,
France (2015), College Park, MD, USA (2016), Canterbury, UK (2017), Gothenburg,
Sweden (2018), Vancouver, Canada (2019), Krakow, Poland (2020), online due to
COVID-19 (2021, 2022, with some talks from TFPIE 2022 also presented in person
at the Lambda Days in Krakow, Poland), and Boston, MA, USA (2023, back
in-person).
",2024-07-08 19:48:43+00:00,cs.PL
"Scaling Analog Photonic Accelerators for Byte-Size, Integer General
  Matrix Multiply (GEMM) Kernels","  Deep Neural Networks (DNNs) predominantly rely on General Matrix Multiply
(GEMM) kernels, which are often accelerated using specialized hardware
architectures. Recently, analog photonic GEMM accelerators have emerged as a
promising alternative, offering vastly superior speed and energy efficiency
compared to traditional electronic accelerators. However, these photonic cannot
support wider than 4-bit integer operands due to their inherent trade-offs
between analog dynamic range and parallelism. This is often inadequate for DNN
training as at least 8-bit wide operands are deemed necessary to prevent
significant accuracy drops. To address these limitations, we introduce a
scalable photonic GEMM accelerator named SPOGA. SPOGA utilizes enhanced
features such as analog summation of homodyne optical signals and
in-transduction positional weighting of operands. By employing an extended
optical-analog dataflow that minimizes overheads associated with bit-sliced
integer arithmetic, SPOGA supports byte-size integer GEMM kernels, achieving
significant improvements in throughput, latency, and energy efficiency.
Specifically, SPOGA demonstrates up to 14.4$\times$, 2$\times$, and
28.5$\times$ improvements in frames-per-second (FPS), FPS/Watt, and
FPS/Watt/mm$^2$ respectively, compared to existing state-of-the-art photonic
solutions.
",2024-07-08 17:07:04+00:00,cs.AR
"Enabling Performant and Secure EDA as a Service in Public Clouds Using
  Confidential Containers","  Increasingly, business opportunities available to fabless design teams in the
semiconductor industry far exceed those addressable with on-prem compute
resources. An attractive option to capture these electronic design automation
(EDA) design opportunities is through public cloud bursting. However, security
concerns with public cloud bursting arise from having to protect process design
kits, third party intellectual property, and new design data for semiconductor
devices and chips. One way to address security concerns for public cloud
bursting is to leverage confidential containers for EDA workloads. Confidential
containers add zero trust computing elements to significantly reduce the
probability of intellectual property escapes. A key concern that often follows
security discussions is whether EDA workload performance will suffer with
confidential computing. In this work we demonstrate a full set of EDA
confidential containers and their deployment and characterize performance
impacts of confidential elements of the flow including storage and networking.
A complete end-to-end confidential container-based EDA workload exhibits 7.13%
and 2.05% performance overheads over bare-metal container and VM based
solutions, respectively.
",2024-07-08 15:36:30+00:00,cs.CR
"ISPO: An Integrated Ontology of Symptom Phenotypes for Semantic
  Integration of Traditional Chinese Medical Data","  Symptom phenotypes are one of the key types of manifestations for diagnosis
and treatment of various disease conditions. However, the diversity of symptom
terminologies is one of the major obstacles hindering the analysis and
knowledge sharing of various types of symptom-related medical data particularly
in the fields of Traditional Chinese Medicine (TCM). Objective: This study
aimed to construct an Integrated Ontology of symptom phenotypes (ISPO) to
support the data mining of Chinese EMRs and real-world study in TCM field.
Methods: To construct an integrated ontology of symptom phenotypes (ISPO), we
manually annotated classical TCM textbooks and large-scale Chinese electronic
medical records (EMRs) to collect symptom terms with support from a medical
text annotation system. Furthermore, to facilitate the semantic
interoperability between different terminologies, we incorporated public
available biomedical vocabularies by manual mapping between Chinese terms and
English terms with cross-references to source vocabularies. In addition, we
evaluated the ISPO using independent clinical EMRs to provide a high-usable
medical ontology for clinical data analysis. Results: By integrating 78,696
inpatient cases of EMRs, 5 biomedical vocabularies, 21 TCM books and
dictionaries, ISPO provides 3,147 concepts, 23,475 terms, and 55,552 definition
or contextual texts. Adhering to the taxonomical structure of the related
anatomical systems of symptom phenotypes, ISPO provides 12 top-level categories
and 79 middle-level sub-categories. The validation of data analysis showed the
ISPO has a coverage rate of 95.35%, 98.53% and 92.66% for symptom terms with
occurrence rates of 0.5% in additional three independent curated clinical
datasets, which can demonstrate the significant value of ISPO in mapping
clinical terms to ontologies.
",2024-07-08 15:23:50+00:00,cs.CL
"Model-agnostic meta-learners for estimating heterogeneous treatment
  effects over time","  Estimating heterogeneous treatment effects (HTEs) over time is crucial in
many disciplines such as personalized medicine. For example, electronic health
records are commonly collected over several time periods and then used to
personalize treatment decisions. Existing works for this task have mostly
focused on model-based learners (i.e., learners that adapt specific
machine-learning models). In contrast, model-agnostic learners -- so-called
meta-learners -- are largely unexplored. In our paper, we propose several
meta-learners that are model-agnostic and thus can be used in combination with
arbitrary machine learning models (e.g., transformers) to estimate HTEs over
time. Here, our focus is on learners that can be obtained via weighted
pseudo-outcome regressions, which allows for efficient estimation by targeting
the treatment effect directly. We then provide a comprehensive theoretical
analysis that characterizes the different learners and that allows us to offer
insights into when specific learners are preferable. Finally, we confirm our
theoretical insights through numerical experiments. In sum, while meta-learners
are already state-of-the-art for the static setting, we are the first to
propose a comprehensive set of meta-learners for estimating HTEs in the
time-varying setting.
",2024-07-07 07:07:48+00:00,cs.LG
"BadCLM: Backdoor Attack in Clinical Language Models for Electronic
  Health Records","  The advent of clinical language models integrated into electronic health
records (EHR) for clinical decision support has marked a significant
advancement, leveraging the depth of clinical notes for improved
decision-making. Despite their success, the potential vulnerabilities of these
models remain largely unexplored. This paper delves into the realm of backdoor
attacks on clinical language models, introducing an innovative attention-based
backdoor attack method, BadCLM (Bad Clinical Language Models). This technique
clandestinely embeds a backdoor within the models, causing them to produce
incorrect predictions when a pre-defined trigger is present in inputs, while
functioning accurately otherwise. We demonstrate the efficacy of BadCLM through
an in-hospital mortality prediction task with MIMIC III dataset, showcasing its
potential to compromise model integrity. Our findings illuminate a significant
security risk in clinical decision support systems and pave the way for future
endeavors in fortifying clinical language models against such vulnerabilities.
",2024-07-06 23:56:43+00:00,cs.CL
"VIPS-Odom: Visual-Inertial Odometry Tightly-coupled with Parking Slots
  for Autonomous Parking","  Precise localization is of great importance for autonomous parking task since
it provides service for the downstream planning and control modules, which
significantly affects the system performance. For parking scenarios, dynamic
lighting, sparse textures, and the instability of global positioning system
(GPS) signals pose challenges for most traditional localization methods. To
address these difficulties, we propose VIPS-Odom, a novel semantic
visual-inertial odometry framework for underground autonomous parking, which
adopts tightly-coupled optimization to fuse measurements from multi-modal
sensors and solves odometry. Our VIPS-Odom integrates parking slots detected
from the synthesized bird-eye-view (BEV) image with traditional feature points
in the frontend, and conducts tightly-coupled optimization with joint
constraints introduced by measurements from the inertial measurement unit,
wheel speed sensor and parking slots in the backend. We develop a multi-object
tracking framework to robustly track parking slots' states. To prove the
superiority of our method, we equip an electronic vehicle with related sensors
and build an experimental platform based on ROS2 system. Extensive experiments
demonstrate the efficacy and advantages of our method compared with other
baselines for parking scenarios.
",2024-07-06 09:21:25+00:00,cs.RO
SID: Stereo Image Dataset for Autonomous Driving in Adverse Conditions,"  Robust perception is critical for autonomous driving, especially under
adverse weather and lighting conditions that commonly occur in real-world
environments. In this paper, we introduce the Stereo Image Dataset (SID), a
large-scale stereo-image dataset that captures a wide spectrum of challenging
real-world environmental scenarios. Recorded at a rate of 20 Hz using a ZED
stereo camera mounted on a vehicle, SID consists of 27 sequences totaling over
178k stereo image pairs that showcase conditions from clear skies to heavy
snow, captured during the day, dusk, and night. The dataset includes detailed
sequence-level annotations for weather conditions, time of day, location, and
road conditions, along with instances of camera lens soiling, offering a
realistic representation of the challenges in autonomous navigation. Our work
aims to address a notable gap in research for autonomous driving systems by
presenting high-fidelity stereo images essential for the development and
testing of advanced perception algorithms. These algorithms support consistent
and reliable operation across variable weather and lighting conditions, even
when handling challenging situations like lens soiling. SID is publicly
available at: https://doi.org/10.7302/esz6-nv83.
",2024-07-06 00:58:31+00:00,cs.CV
"Hyperspectral Dataset and Deep Learning methods for Waste from Electric
  and Electronic Equipment Identification (WEEE)","  Hyperspectral imaging, a rapidly evolving field, has witnessed the ascendancy
of deep learning techniques, supplanting classical feature extraction and
classification methods in various applications. However, many researchers
employ arbitrary architectures for hyperspectral image processing, often
without rigorous analysis of the interplay between spectral and spatial
information. This oversight neglects the implications of combining these two
modalities on model performance.
  In this paper, we evaluate the performance of diverse deep learning
architectures for hyperspectral image segmentation. Our analysis disentangles
the impact of different architectures, spanning various spectral and spatial
granularities. Specifically, we investigate the effects of spectral resolution
(capturing spectral information) and spatial texture (conveying spatial
details) on segmentation outcomes. Additionally, we explore the transferability
of knowledge from large pre-trained image foundation models, originally
designed for RGB images, to the hyperspectral domain.
  Results show that incorporating spatial information alongside spectral data
leads to improved segmentation results, and that it is essential to further
work on novel architectures comprising spectral and spatial information and on
the adaption of RGB foundation models into the hyperspectral domain.
  Furthermore, we contribute to the field by cleaning and publicly releasing
the Tecnalia WEEE Hyperspectral dataset. This dataset contains different
non-ferrous fractions of Waste Electrical and Electronic Equipment (WEEE),
including Copper, Brass, Aluminum, Stainless Steel, and White Copper, spanning
the range of 400 to 1000 nm.
  We expect these conclusions can guide novel researchers in the field of
hyperspectral imaging.
",2024-07-05 13:45:11+00:00,cs.CV
"Multi-modal Masked Siamese Network Improves Chest X-Ray Representation
  Learning","  Self-supervised learning methods for medical images primarily rely on the
imaging modality during pretraining. While such approaches deliver promising
results, they do not leverage associated patient or scan information collected
within Electronic Health Records (EHR). Here, we propose to incorporate EHR
data during self-supervised pretraining with a Masked Siamese Network (MSN) to
enhance the quality of chest X-ray representations. We investigate three types
of EHR data, including demographic, scan metadata, and inpatient stay
information. We evaluate our approach on three publicly available chest X-ray
datasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)
backbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the
representations via linear evaluation, our proposed method demonstrates
significant improvement compared to vanilla MSN and state-of-the-art
self-supervised learning baselines. Our work highlights the potential of
EHR-enhanced self-supervised pre-training for medical imaging. The code is
publicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN
",2024-07-05 12:04:12+00:00,cs.CV
Query-Guided Self-Supervised Summarization of Nursing Notes,"  Nursing notes, an important component of Electronic Health Records (EHRs),
keep track of the progression of a patient's health status during a care
episode. Distilling the key information in nursing notes through text
summarization techniques can improve clinicians' efficiency in understanding
patients' conditions when reviewing nursing notes. However, existing
abstractive summarization methods in the clinical setting have often overlooked
nursing notes and require the creation of reference summaries for supervision
signals, which is time-consuming. In this work, we introduce QGSumm, a
query-guided self-supervised domain adaptation framework for nursing note
summarization. Using patient-related clinical queries as guidance, our approach
generates high-quality, patient-centered summaries without relying on reference
summaries for training. Through automatic and manual evaluation by an expert
clinician, we demonstrate the strengths of our approach compared to the
state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot
settings. Ultimately, our approach provides a new perspective on conditional
text summarization, tailored to the specific interests of clinical personnel.
",2024-07-04 18:54:30+00:00,cs.CL
"Resistive Memory for Computing and Security: Algorithms, Architectures,
  and Platforms","  Resistive random-access memory (RRAM) is gaining popularity due to its
ability to offer computing within the memory and its non-volatile nature. The
unique properties of RRAM, such as binary switching, multi-state switching, and
device variations, can be leveraged to design novel techniques and algorithms.
This thesis proposes a technique for utilizing RRAM devices in three major
directions: i) digital logic implementation, ii) multi-valued computing, and
iii) hardware security primitive design. We proposed new algorithms and
architectures and conducted \textit{experimental studies} on each
implementation. Moreover, we developed the electronic design automation
framework and hardware platforms to facilitate these experiments.
",2024-07-04 11:18:46+00:00,cs.ET
Classification-Based Automatic HDL Code Generation Using LLMs,"  While large language models (LLMs) have demonstrated the ability to generate
hardware description language (HDL) code for digital circuits, they still
suffer from the hallucination problem, which leads to the generation of
incorrect HDL code or misunderstanding of specifications. In this work, we
introduce a human-expert-inspired method to mitigate the hallucination of LLMs
and improve the performance in HDL code generation. We first let LLMs classify
the type of the circuit based on the specifications. Then, according to the
type of the circuit, we split the tasks into several sub-procedures, including
information extraction and human-like design flow using Electronic Design
Automation (EDA) tools. Besides, we also use a search method to mitigate the
variation in code generation. Experimental results show that our method can
significantly improve the functional correctness of the generated Verilog and
reduce the hallucination of LLMs.
",2024-07-04 09:00:13+00:00,cs.AR
"Stacked Intelligent Metasurfaces for Wireless Sensing and Communication:
  Applications and Challenges","  The rapid advancement of wireless communication technologies has precipitated
an unprecedented demand for high data rates, extremely low latency, and
ubiquitous connectivity. In order to achieve these goals, stacked intelligent
metasurfaces (SIM) has been developed as a novel solution to perform advanced
signal processing tasks directly in the electromagnetic wave domain, thus
achieving ultra-fast computing speed and reducing hardware complexity. This
article provides an overview of the SIM technology by discussing its hardware
architectures, advantages, and potential applications for wireless sensing and
communication. Specifically, we explore the utilization of SIMs in enabling
wave-domain beamforming, channel modeling and estimation in SIM-assisted
communication systems. Furthermore, we elaborate on the potential of utilizing
a SIM to build a hybrid optical-electronic neural network (HOENN) and
demonstrate its efficacy by examining two case studies: disaster monitoring and
direction-of-arrival estimation. Finally, we identify key implementation
challenges, including practical hardware imperfections, efficient SIM
configuration for realizing wave-domain signal processing, and performance
analysis to motivate future research on this important and far-reaching topic.
",2024-07-04 01:39:52+00:00,cs.IT
3D Multimodal Image Registration for Plant Phenotyping,"  The use of multiple camera technologies in a combined multimodal monitoring
system for plant phenotyping offers promising benefits. Compared to
configurations that only utilize a single camera technology, cross-modal
patterns can be recorded that allow a more comprehensive assessment of plant
phenotypes. However, the effective utilization of cross-modal patterns is
dependent on precise image registration to achieve pixel-accurate alignment, a
challenge often complicated by parallax and occlusion effects inherent in plant
canopy imaging.
  In this study, we propose a novel multimodal 3D image registration method
that addresses these challenges by integrating depth information from a
time-of-flight camera into the registration process. By leveraging depth data,
our method mitigates parallax effects and thus facilitates more accurate pixel
alignment across camera modalities. Additionally, we introduce an automated
mechanism to identify and differentiate different types of occlusions, thereby
minimizing the introduction of registration errors.
  To evaluate the efficacy of our approach, we conduct experiments on a diverse
image dataset comprising six distinct plant species with varying leaf
geometries. Our results demonstrate the robustness of the proposed registration
algorithm, showcasing its ability to achieve accurate alignment across
different plant types and camera compositions. Compared to previous methods it
is not reliant on detecting plant specific image features and can thereby be
utilized for a wide variety of applications in plant sciences. The registration
approach principally scales to arbitrary numbers of cameras with different
resolutions and wavelengths. Overall, our study contributes to advancing the
field of plant phenotyping by offering a robust and reliable solution for
multimodal image registration.
",2024-07-03 09:29:46+00:00,cs.CV
"Benchmarking End-To-End Performance of AI-Based Chip Placement
  Algorithms","  The increasing complexity of modern very-large-scale integration (VLSI)
design highlights the significance of Electronic Design Automation (EDA)
technologies. Chip placement is a critical step in the EDA workflow, which
positions chip modules on the canvas with the goal of optimizing performance,
power, and area (PPA) metrics of final chip designs. Recent advances have
demonstrated the great potential of AI-based algorithms in enhancing chip
placement. However, due to the lengthy workflow of chip design, the evaluations
of these algorithms often focus on intermediate surrogate metrics, which are
easy to compute but frequently reveal a substantial misalignment with the
end-to-end performance (i.e., the final design PPA). To address this challenge,
we introduce ChiPBench, which can effectively facilitate research in chip
placement within the AI community. ChiPBench is a comprehensive benchmark
specifically designed to evaluate the effectiveness of existing AI-based chip
placement algorithms in improving final design PPA metrics. Specifically, we
have gathered 20 circuits from various domains (e.g., CPU, GPU, and
microcontrollers). These designs are compiled by executing the workflow from
the verilog source code, which preserves necessary physical implementation
kits, enabling evaluations for the placement algorithms on their impacts on the
final design PPA. We executed six state-of-the-art AI-based chip placement
algorithms on these designs and plugged the results of each single-point
algorithm into the physical implementation workflow to obtain the final PPA
results. Experimental results show that even if intermediate metric of a
single-point algorithm is dominant, while the final PPA results are
unsatisfactory. We believe that our benchmark will serve as an effective
evaluation framework to bridge the gap between academia and industry.
",2024-07-03 03:29:23+00:00,cs.AR
μ-Bench: A Vision-Language Benchmark for Microscopy Understanding,"  Recent advances in microscopy have enabled the rapid generation of terabytes
of image data in cell biology and biomedical research. Vision-language models
(VLMs) offer a promising solution for large-scale biological image analysis,
enhancing researchers' efficiency, identifying new image biomarkers, and
accelerating hypothesis generation and scientific discovery. However, there is
a lack of standardized, diverse, and large-scale vision-language benchmarks to
evaluate VLMs' perception and cognition capabilities in biological image
understanding. To address this gap, we introduce {\mu}-Bench, an expert-curated
benchmark encompassing 22 biomedical tasks across various scientific
disciplines (biology, pathology), microscopy modalities (electron,
fluorescence, light), scales (subcellular, cellular, tissue), and organisms in
both normal and abnormal states. We evaluate state-of-the-art biomedical,
pathology, and general VLMs on {\mu}-Bench and find that: i) current models
struggle on all categories, even for basic tasks such as distinguishing
microscopy modalities; ii) current specialist models fine-tuned on biomedical
data often perform worse than generalist models; iii) fine-tuning in specific
microscopy domains can cause catastrophic forgetting, eroding prior biomedical
knowledge encoded in their base model. iv) weight interpolation between
fine-tuned and pre-trained models offers one solution to forgetting and
improves general performance across biomedical tasks. We release {\mu}-Bench
under a permissive license to accelerate the research and development of
microscopy foundation models.
",2024-07-01 20:30:26+00:00,cs.CV
"A Novel HDL Code Generator for Effectively Testing FPGA Logic Synthesis
  Compilers","  Field Programmable Gate Array (FPGA) logic synthesis compilers (e.g., Vivado,
Iverilog, Yosys, and Quartus) are widely applied in Electronic Design
Automation (EDA), such as the development of FPGA programs.However, defects
(i.e., incorrect synthesis) in logic synthesis compilers may lead to unexpected
behaviors in target applications, posing security risks. Therefore, it is
crucial to thoroughly test logic synthesis compilers to eliminate such
defects.Despite several Hardware Design Language (HDL) code generators (e.g.,
Verismith) have been proposed to find defects in logic synthesis compilers, the
effectiveness of these generators is still limited by the simple code
generation strategy and the monogeneity of the generated HDL code.This paper
proposes LegoHDL, a novel method to generate syntax valid HDL code for
comprehensively testing FPGA logic synthesis compilers.LegoHDL can generate
more complex and diverse defect-trigger HDL code (e.g., Verilog, VHDL, and
SystemVerilog) by leveraging the guidance of abstract syntax tree and the
extensive function block libraries of cyber-physical systems. Extensive
experiments show that the diversity and defect-trigger capability of HDL code
generated by LegoHDL are significantly better than the state-of-the-art method
(i.e., Verismith).In three months, LegoHDL has reported 20 new defects--many of
which are deep and important; 16 of them have been confirmed.
",2024-07-01 06:41:05+00:00,cs.AR
"MUSE-Net: Missingness-aware mUlti-branching Self-attention Encoder for
  Irregular Longitudinal Electronic Health Records","  The era of big data has made vast amounts of clinical data readily available,
particularly in the form of electronic health records (EHRs), which provides
unprecedented opportunities for developing data-driven diagnostic tools to
enhance clinical decision making. However, the application of EHRs in
data-driven modeling faces challenges such as irregularly spaced multi-variate
time series, issues of incompleteness, and data imbalance. Realizing the full
data potential of EHRs hinges on the development of advanced analytical models.
In this paper, we propose a novel Missingness-aware mUlti-branching
Self-attention Encoder (MUSE-Net) to cope with the challenges in modeling
longitudinal EHRs for data-driven disease prediction. The MUSE-Net leverages a
multi-task Gaussian process (MGP) with missing value masks for data imputation,
a multi-branching architecture to address the data imbalance problem, and a
time-aware self-attention encoder to account for the irregularly spaced time
interval in longitudinal EHRs. We evaluate the proposed MUSE-Net using both
synthetic and real-world datasets. Experimental results show that our MUSE-Net
outperforms existing methods that are widely used to investigate longitudinal
signals.
",2024-06-30 21:54:41+00:00,cs.LG
"EHRmonize: A Framework for Medical Concept Abstraction from Electronic
  Health Records using Large Language Models","  Electronic health records (EHRs) contain vast amounts of complex data, but
harmonizing and processing this information remains a challenging and costly
task requiring significant clinical expertise. While large language models
(LLMs) have shown promise in various healthcare applications, their potential
for abstracting medical concepts from EHRs remains largely unexplored. We
introduce EHRmonize, a framework leveraging LLMs to abstract medical concepts
from EHR data. Our study uses medication data from two real-world EHR databases
to evaluate five LLMs on two free-text extraction and six binary classification
tasks across various prompting strategies. GPT-4o's with 10-shot prompting
achieved the highest performance in all tasks, accompanied by Claude-3.5-Sonnet
in a subset of tasks. GPT-4o achieved an accuracy of 97% in identifying generic
route names, 82% for generic drug names, and 100% in performing binary
classification of antibiotics. While EHRmonize significantly enhances
efficiency, reducing annotation time by an estimated 60%, we emphasize that
clinician oversight remains essential. Our framework, available as a Python
package, offers a promising tool to assist clinicians in EHR data abstraction,
potentially accelerating healthcare research and improving data harmonization
processes.
",2024-06-28 21:39:20+00:00,cs.CL
Text2Robot: Evolutionary Robot Design from Text Descriptions,"  Robot design has traditionally been costly and labor-intensive. Despite
advancements in automated processes, it remains challenging to navigate a vast
design space while producing physically manufacturable robots. We introduce
Text2Robot, a framework that converts user text specifications and performance
preferences into physical quadrupedal robots. Within minutes, Text2Robot can
use text-to-3D models to provide strong initializations of diverse
morphologies. Within a day, our geometric processing algorithms and
body-control co-optimization produce a walking robot by explicitly considering
real-world electronics and manufacturability. Text2Robot enables rapid
prototyping and opens new opportunities for robot design with generative
models.
",2024-06-28 14:51:01+00:00,cs.RO
ACES: Automatic Cohort Extraction System for Event-Stream Datasets,"  Reproducibility remains a significant challenge in machine learning (ML) for
healthcare. In this field, datasets, model pipelines, and even task/cohort
definitions are often private, leading to a significant barrier in sharing,
iterating, and understanding ML results on electronic health record (EHR)
datasets. In this paper, we address a significant part of this problem by
introducing the Automatic Cohort Extraction System for Event-Stream Datasets
(ACES). This tool is designed to simultaneously simplify the development of
task/cohorts for ML in healthcare and enable the reproduction of these cohorts,
both at an exact level for single datasets and at a conceptual level across
datasets. To accomplish this, ACES provides (1) a highly intuitive and
expressive configuration language for defining both dataset-specific concepts
and dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to
automatically extract patient records that meet these defined criteria from
real-world data. ACES can be automatically applied to any dataset in either the
Medical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to
*any* dataset for which the necessary task-specific predicates can be extracted
in an event-stream form. ACES has the potential to significantly lower the
barrier to entry for defining ML tasks, redefine the way researchers interact
with EHR datasets, and significantly improve the state of reproducibility for
ML studies in this modality. ACES is available at
https://github.com/justin13601/aces.
",2024-06-28 04:48:05+00:00,cs.LG
"FedMLP: Federated Multi-Label Medical Image Classification under Task
  Heterogeneity","  Cross-silo federated learning (FL) enables decentralized organizations to
collaboratively train models while preserving data privacy and has made
significant progress in medical image classification. One common assumption is
task homogeneity where each client has access to all classes during training.
However, in clinical practice, given a multi-label classification task,
constrained by the level of medical knowledge and the prevalence of diseases,
each institution may diagnose only partial categories, resulting in task
heterogeneity. How to pursue effective multi-label medical image classification
under task heterogeneity is under-explored. In this paper, we first formulate
such a realistic label missing setting in the multi-label FL domain and propose
a two-stage method FedMLP to combat class missing from two aspects: pseudo
label tagging and global knowledge learning. The former utilizes a warmed-up
model to generate class prototypes and select samples with high confidence to
supplement missing labels, while the latter uses a global model as a teacher
for consistency regularization to prevent forgetting missing class knowledge.
Experiments on two publicly-available medical datasets validate the superiority
of FedMLP against the state-of-the-art both federated semi-supervised and noisy
label learning approaches under task heterogeneity. Code is available at
https://github.com/szbonaldo/FedMLP.
",2024-06-27 08:36:43+00:00,cs.LG
"The Impact of Feature Representation on the Accuracy of Photonic Neural
  Networks","  Photonic Neural Networks (PNNs) are gaining significant interest in the
research community due to their potential for high parallelization, low
latency, and energy efficiency. PNNs compute using light, which leads to
several differences in implementation when compared to electronics, such as the
need to represent input features in the photonic domain before feeding them
into the network. In this encoding process, it is common to combine multiple
features into a single input to reduce the number of inputs and associated
devices, leading to smaller and more energy-efficient PNNs. Although this
alters the network's handling of input data, its impact on PNNs remains
understudied. This paper addresses this open question, investigating the effect
of commonly used encoding strategies that combine features on the performance
and learning capabilities of PNNs. Here, using the concept of feature
importance, we develop a mathematical methodology for analyzing feature
combination. Through this methodology, we demonstrate that encoding multiple
features together in a single input determines their relative importance, thus
limiting the network's ability to learn from the data. Given some prior
knowledge of the data, however, this can also be leveraged for higher accuracy.
By selecting an optimal encoding method, we achieve up to a 12.3% improvement
in accuracy of PNNs trained on the Iris dataset compared to other encoding
techniques, surpassing the performance of networks where features are not
combined. These findings highlight the importance of carefully choosing the
encoding to the accuracy and decision-making strategies of PNNs, particularly
in size or power constrained applications.
",2024-06-26 20:55:26+00:00,cs.ET
"Shimo Lab at ""Discharge Me!"": Discharge Summarization by Prompt-Driven
  Concatenation of Electronic Health Record Sections","  In this paper, we present our approach to the shared task ""Discharge Me!"" at
the BioNLP Workshop 2024. The primary goal of this task is to reduce the time
and effort clinicians spend on writing detailed notes in the electronic health
record (EHR). Participants develop a pipeline to generate the ""Brief Hospital
Course"" and ""Discharge Instructions"" sections from the EHR. Our approach
involves a first step of extracting the relevant sections from the EHR. We then
add explanatory prompts to these sections and concatenate them with separate
tokens to create the input text. To train a text generation model, we perform
LoRA fine-tuning on the ClinicalT5-large model. On the final test data, our
approach achieved a ROUGE-1 score of $0.394$, which is comparable to the top
solutions.
",2024-06-26 06:10:20+00:00,cs.CL
"EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction
  Using Large Language Multimodal Models","  Traditional diagnosis of chronic diseases involves in-person consultations
with physicians to identify the disease. However, there is a lack of research
focused on predicting and developing application systems using clinical notes
and blood test values. We collected five years of Electronic Health Records
(EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database.
Furthermore, we developed an EHR-based chronic disease prediction platform
utilizing Large Language Multimodal Models (LLMMs), successfully integrating
with frontend web and mobile applications for prediction. This prediction
platform can also connect to the hospital's backend database, providing
physicians with real-time risk assessment diagnostics. The demonstration link
can be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.
",2024-06-26 05:51:08+00:00,cs.SE
"Hot-Distance: Combining One-Hot and Signed Distance Embeddings for
  Segmentation","  Machine learning models are only as good as the data to which they are fit.
As such, it is always preferable to use as much data as possible in training
models. What data can be used for fitting a model depends a lot on the
formulation of the task. We introduce Hot-Distance, a novel segmentation target
that incorporates the strength of signed boundary distance prediction with the
flexibility of one-hot encoding, to increase the amount of usable training data
for segmentation of subcellular structures in focused ion beam scanning
electron microscopy (FIB-SEM).
",2024-06-25 20:56:41+00:00,cs.CV
A Recursive Encoding for Cuneiform Signs,"  One of the most significant problems in cuneiform pedagogy is the process of
looking up unknown signs, which often involves a tedious page-by-page search
through a sign list. This paper proposes a new ""recursive encoding"" for signs,
which represents the arrangement of strokes in a way a computer can process. A
series of new algorithms then offers students a new way to look up signs by any
distinctive component, as well as providing new ways to render signs and
tablets electronically.
",2024-06-25 05:18:12+00:00,cs.CL
"Vox-UDA: Voxel-wise Unsupervised Domain Adaptation for Cryo-Electron
  Subtomogram Segmentation with Denoised Pseudo Labeling","  Cryo-Electron Tomography (cryo-ET) is a 3D imaging technology facilitating
the study of macromolecular structures at near-atomic resolution. Recent
volumetric segmentation approaches on cryo-ET images have drawn widespread
interest in biological sector. However, existing methods heavily rely on
manually labeled data, which requires highly professional skills, thereby
hindering the adoption of fully-supervised approaches for cryo-ET images. Some
unsupervised domain adaptation (UDA) approaches have been designed to enhance
the segmentation network performance using unlabeled data. However, applying
these methods directly to cryo-ET images segmentation tasks remains challenging
due to two main issues: 1) the source data, usually obtained through
simulation, contain a certain level of noise, while the target data, directly
collected from raw-data from real-world scenario, have unpredictable noise
levels. 2) the source data used for training typically consists of known
macromoleculars, while the target domain data are often unknown, causing the
model's segmenter to be biased towards these known macromolecules, leading to a
domain shift problem. To address these challenges, in this work, we introduce
the first voxel-wise unsupervised domain adaptation approach, termed Vox-UDA,
specifically for cryo-ET subtomogram segmentation. Vox-UDA incorporates a noise
generation module to simulate target-like noises in the source dataset for
cross-noise level adaptation. Additionally, we propose a denoised
pseudo-labeling strategy based on improved Bilateral Filter to alleviate the
domain shift problem. Experimental results on both simulated and real cryo-ET
subtomogram datasets demonstrate the superiority of our proposed approach
compared to state-of-the-art UDA methods.
",2024-06-25 00:16:57+00:00,cs.CV
"Virtual Mines -- Component-level recycling of printed circuit boards
  using deep learning","  This contribution gives an overview of an ongoing project using machine
learning and computer vision components for improving the electronic waste
recycling process. In circular economy, the ""virtual mines"" concept refers to
production cycles where interesting raw materials are reclaimed in an efficient
and cost-effective manner from end-of-life items. In particular, the growth of
e-waste, due to the increasingly shorter life cycle of hi-tech goods, is a
global problem. In this paper, we describe a pipeline based on deep learning
model to recycle printed circuit boards at the component level. A pre-trained
YOLOv5 model is used to analyze the results of the locally developed dataset.
With a different distribution of class instances, YOLOv5 managed to achieve
satisfactory precision and recall, with the ability to optimize with large
component instances.
",2024-06-24 22:29:30+00:00,cs.CV
"LLM-Aided Testbench Generation and Bug Detection for Finite-State
  Machines","  This work investigates the potential of tailoring Large Language Models
(LLMs), specifically GPT3.5 and GPT4, for the domain of chip testing. A key
aspect of chip design is functional testing, which relies on testbenches to
evaluate the functionality and coverage of Register-Transfer Level (RTL)
designs. We aim to enhance testbench generation by incorporating feedback from
commercial-grade Electronic Design Automation (EDA) tools into LLMs. Through
iterative feedback from these tools, we refine the testbenches to achieve
improved test coverage. Our case studies present promising results,
demonstrating that this approach can effectively enhance test coverage. By
integrating EDA tool feedback, the generated testbenches become more accurate
in identifying potential issues in the RTL design. Furthermore, we extended our
study to use this enhanced test coverage framework for detecting bugs in the
RTL implementations
",2024-06-24 20:42:40+00:00,cs.AR
"Assessing the role of clinical summarization and patient chart review
  within communications, medical management, and diagnostics","  Effective summarization of unstructured patient data in electronic health
records (EHRs) is crucial for accurate diagnosis and efficient patient care,
yet clinicians often struggle with information overload and time constraints.
This review dives into recent literature and case studies on both the
significant impacts and outstanding issues of patient chart review on
communications, diagnostics, and management. It also discusses recent efforts
to integrate artificial intelligence (AI) into clinical summarization tasks,
and its transformative impact on the clinician's potential, including but not
limited to reductions of administrative burden and improved patient-centered
care.
",2024-06-24 15:31:24+00:00,cs.CY
"Measuring the Recyclability of Electronic Components to Assist Automatic
  Disassembly and Sorting Waste Printed Circuit Boards","  The waste of electrical and electronic equipment has been increased due to
the fast evolution of technology products and competition of many IT sectors.
Every year millions of tons of electronic waste are thrown into the environment
which causes high consequences for human health. Therefore, it is crucial to
control this waste flow using technology, especially using Artificial
Intelligence but also reclamation of critical raw materials for new production
processes. In this paper, we focused on the measurement of recyclability of
waste electronic components (WECs) from waste printed circuit boards (WPCBs)
using mathematical innovation model. This innovative approach evaluates both
the recyclability and recycling difficulties of WECs, integrating an AI model
for improved disassembly and sorting. Assessing the recyclability of individual
electronic components present on WPCBs provides insight into the recovery
potential of valuable materials and indicates the level of complexity involved
in recycling in terms of economic worth and production utility. This novel
measurement approach helps AI models in accurately determining the number of
classes to be identified and sorted during the automated disassembly of
discarded PCBs. It also facilitates the model in iterative training and
validation of individual electronic components.
",2024-06-24 12:33:56+00:00,cs.CV
"Machine Learning with Real-time and Small Footprint Anomaly Detection
  System for In-Vehicle Gateway","  Anomaly Detection System (ADS) is an essential part of a modern gateway
Electronic Control Unit (ECU) to detect abnormal behaviors and attacks in
vehicles. Among the existing attacks, ``one-time`` attack is the most
challenging to be detected, together with the strict gateway ECU constraints of
both microsecond or even nanosecond level real-time budget and limited
footprint of code. To address the challenges, we propose to use the
self-information theory to generate values for training and testing models,
aiming to achieve real-time detection performance for the ``one-time`` attack
that has not been well studied in the past. Second, the generation of
self-information is based on logarithm calculation, which leads to the smallest
footprint to reduce the cost in Gateway. Finally, our proposed method uses an
unsupervised model without the need of training data for anomalies or attacks.
We have compared different machine learning methods ranging from typical
machine learning models to deep learning models, e.g., Hidden Markov Model
(HMM), Support Vector Data Description (SVDD), and Long Short Term Memory
(LSTM). Experimental results show that our proposed method achieves 8.7 times
lower False Positive Rate (FPR), 1.77 times faster testing time, and 4.88 times
smaller footprint.
",2024-06-24 07:23:52+00:00,cs.CR
"EHRCon: Dataset for Checking Consistency between Unstructured Notes and
  Structured Tables in Electronic Health Records","  Electronic Health Records (EHRs) are integral for storing comprehensive
patient medical records, combining structured data (e.g., medications) with
detailed clinical notes (e.g., physician notes). These elements are essential
for straightforward data retrieval and provide deep, contextual insights into
patient care. However, they often suffer from discrepancies due to unintuitive
EHR system designs and human errors, posing serious risks to patient safety. To
address this, we developed EHRCon, a new dataset and task specifically designed
to ensure data consistency between structured tables and unstructured notes in
EHRs. EHRCon was crafted in collaboration with healthcare professionals using
the MIMIC-III EHR dataset, and includes manual annotations of 3,943 entities
across 105 clinical notes checked against database entries for consistency.
EHRCon has two versions, one using the original MIMIC-III schema, and another
using the OMOP CDM schema, in order to increase its applicability and
generalizability. Furthermore, leveraging the capabilities of large language
models, we introduce CheckEHR, a novel framework for verifying the consistency
between clinical notes and database tables. CheckEHR utilizes an eight-stage
process and shows promising results in both few-shot and zero-shot settings.
The code is available at https://github.com/dustn1259/EHRCon.
",2024-06-24 06:26:50+00:00,cs.CL
"Feature-prompting GBMSeg: One-Shot Reference Guided Training-Free Prompt
  Engineering for Glomerular Basement Membrane Segmentation","  Assessment of the glomerular basement membrane (GBM) in transmission electron
microscopy (TEM) is crucial for diagnosing chronic kidney disease (CKD). The
lack of domain-independent automatic segmentation tools for the GBM
necessitates an AI-based solution to automate the process. In this study, we
introduce GBMSeg, a training-free framework designed to automatically segment
the GBM in TEM images guided only by a one-shot annotated reference.
Specifically, GBMSeg first exploits the robust feature matching capabilities of
the pretrained foundation model to generate initial prompt points, then
introduces a series of novel automatic prompt engineering techniques across the
feature and physical space to optimize the prompt scheme. Finally, GBMSeg
employs a class-agnostic foundation segmentation model with the generated
prompt scheme to obtain accurate segmentation results. Experimental results on
our collected 2538 TEM images confirm that GBMSeg achieves superior
segmentation performance with a Dice similarity coefficient (DSC) of 87.27%
using only one labeled reference image in a training-free manner, outperforming
recently proposed one-shot or few-shot methods. In summary, GBMSeg introduces a
distinctive automatic prompt framework that facilitates robust
domain-independent segmentation performance without training, particularly
advancing the automatic prompting of foundation segmentation models for medical
images. Future work involves automating the thickness measurement of segmented
GBM and quantifying pathological indicators, holding significant potential for
advancing pathology assessments in clinical applications. The source code is
available on https://github.com/SnowRain510/GBMSeg
",2024-06-24 02:33:46+00:00,cs.CV
"Effectiveness of ChatGPT in explaining complex medical reports to
  patients","  Electronic health records contain detailed information about the medical
condition of patients, but they are difficult for patients to understand even
if they have access to them. We explore whether ChatGPT (GPT 4) can help
explain multidisciplinary team (MDT) reports to colorectal and prostate cancer
patients. These reports are written in dense medical language and assume
clinical knowledge, so they are a good test of the ability of ChatGPT to
explain complex medical reports to patients. We asked clinicians and lay people
(not patients) to review explanations and responses of ChatGPT. We also ran
three focus groups (including cancer patients, caregivers, computer scientists,
and clinicians) to discuss output of ChatGPT. Our studies highlighted issues
with inaccurate information, inappropriate language, limited personalization,
AI distrust, and challenges integrating large language models (LLMs) into
clinical workflow. These issues will need to be resolved before LLMs can be
used to explain complex personal medical information to patients.
",2024-06-23 00:04:07+00:00,cs.HC
"Privacy Preserving Machine Learning for Electronic Health Records using
  Federated Learning and Differential Privacy","  An Electronic Health Record (EHR) is an electronic database used by
healthcare providers to store patients' medical records which may include
diagnoses, treatments, costs, and other personal information. Machine learning
(ML) algorithms can be used to extract and analyze patient data to improve
patient care. Patient records contain highly sensitive information, such as
social security numbers (SSNs) and residential addresses, which introduces a
need to apply privacy-preserving techniques for these ML models using federated
learning and differential privacy.
",2024-06-23 00:01:03+00:00,cs.LG
"Impact on clinical guideline adherence of Orient-COVID, a CDSS based on
  dynamic medical decision trees for COVID19 management: a randomized
  simulation trial","  Background: The adherence of clinicians to clinical practice guidelines is
known to be low, including for the management of COVID-19, due to their
difficult use at the point of care and their complexity. Clinical decision
support systems have been proposed to implement guidelines and improve
adherence. One approach is to permit the navigation inside the recommendations,
presented as a decision tree, but the size of the tree often limits this
approach and may cause erroneous navigation, especially when it does not fit in
a single screen. Methods: We proposed an innovative visual interface to allow
clinicians easily navigating inside decision trees for the management of
COVID-19 patients. It associates a multi-path tree model with the use of the
fisheye visual technique, allowing the visualization of large decision trees in
a single screen. To evaluate the impact of this tool on guideline adherence, we
conducted a randomized controlled trial in a near-real simulation setting,
comparing the decisions taken by medical students using Orient-COVID with those
taken with paper guidelines or without guidance, when performing on six
realistic clinical cases. Results: The results show that paper guidelines had
no impact (p=0.97), while Orient-COVID significantly improved the guideline
adherence compared to both other groups (p<0.0003). A significant impact of
Orient-COVID was identified on several key points during the management of
COVID-19: ordering troponin lab tests, prescribing anticoagulant and oxygen
therapy. A multifactor analysis showed no difference between male and female
participants. Conclusions: The use of an interactive decision tree for the
management of COVID-19 significantly improved the clinician adherence to
guidelines. Future works will focus on the integration of the system to
electronic health records and on the adaptation of the system to other clinical
conditions.
",2024-06-21 11:50:50+00:00,cs.HC
"A Biomechatronic Approach to Evaluating the Security of Wearable Devices
  in the Internet of Medical Things","  The Internet of Medical Things (IoMT) has the potential to revolutionize
healthcare by reducing human error and improving patient health. For instance,
wearable smart infusion pumps can accurately administer medication and
integrate with electronic health records. These pumps can alert healthcare
professionals or remote servers when an operation fails, preventing distressing
incidents. However, as the number of connected medical devices increases, so
does the risk of cyber threats. Wearable medication devices based on IoT
attached to patients' bodies are particularly vulnerable to significant cyber
threats. Since they are connected to the internet, these devices can be exposed
to potential harm, which can disrupt or degrade device performance and harm
patients. Therefore, it is crucial to establish secure data authentication for
internet-connected medical devices to ensure patient safety and well-being. It
is also important to note that the wearability option of such devices might
downgrade the computational resources, making them more susceptible to security
risks. We propose implementing a security approach for a wearable infusion pump
to mitigate cyber threats. We evaluated the proposed architecture with 20, 50,
and 100 users for 10 minutes and repeated the evaluation 10 times with two
infusion settings, each repeated five times. The desired volumes and rates for
the two settings were 2 ml and 4 ml/hr and 5 ml and 5 ml/hr, respectively. The
maximum error in infusion rate was measured to be 2.5%. We discuss the
practical challenges of implementing such a security-enabled device and suggest
initial solutions.
",2024-06-21 09:17:51+00:00,cs.CR
DN-CL: Deep Symbolic Regression against Noise via Contrastive Learning,"  Noise ubiquitously exists in signals due to numerous factors including
physical, electronic, and environmental effects. Traditional methods of
symbolic regression, such as genetic programming or deep learning models, aim
to find the most fitting expressions for these signals. However, these methods
often overlook the noise present in real-world data, leading to reduced fitting
accuracy. To tackle this issue, we propose \textit{\textbf{D}eep Symbolic
Regression against \textbf{N}oise via \textbf{C}ontrastive \textbf{L}earning
(DN-CL)}. DN-CL employs two parameter-sharing encoders to embed data points
from various data transformations into feature shields against noise. This
model treats noisy data and clean data as different views of the ground-truth
mathematical expressions. Distances between these features are minimized,
utilizing contrastive learning to distinguish between 'positive'
noise-corrected pairs and 'negative' contrasting pairs. Our experiments
indicate that DN-CL demonstrates superior performance in handling both noisy
and clean data, presenting a promising method of symbolic regression.
",2024-06-21 03:13:40+00:00,cs.LG
ACR: A Benchmark for Automatic Cohort Retrieval,"  Identifying patient cohorts is fundamental to numerous healthcare tasks,
including clinical trial recruitment and retrospective studies. Current cohort
retrieval methods in healthcare organizations rely on automated queries of
structured data combined with manual curation, which are time-consuming,
labor-intensive, and often yield low-quality results. Recent advancements in
large language models (LLMs) and information retrieval (IR) offer promising
avenues to revolutionize these systems. Major challenges include managing
extensive eligibility criteria and handling the longitudinal nature of
unstructured Electronic Medical Records (EMRs) while ensuring that the solution
remains cost-effective for real-world application. This paper introduces a new
task, Automatic Cohort Retrieval (ACR), and evaluates the performance of LLMs
and commercial, domain-specific neuro-symbolic approaches. We provide a
benchmark task, a query dataset, an EMR dataset, and an evaluation framework.
Our findings underscore the necessity for efficient, high-quality ACR systems
capable of longitudinal reasoning across extensive patient databases.
",2024-06-20 23:04:06+00:00,cs.AI
"A Large Language Model Outperforms Other Computational Approaches to the
  High-Throughput Phenotyping of Physician Notes","  High-throughput phenotyping, the automated mapping of patient signs and
symptoms to standardized ontology concepts, is essential to gaining value from
electronic health records (EHR) in the support of precision medicine. Despite
technological advances, high-throughput phenotyping remains a challenge. This
study compares three computational approaches to high-throughput phenotyping: a
Large Language Model (LLM) incorporating generative AI, a Natural Language
Processing (NLP) approach utilizing deep learning for span categorization, and
a hybrid approach combining word vectors with machine learning. The approach
that implemented GPT-4 (a Large Language Model) demonstrated superior
performance, suggesting that Large Language Models are poised to be the
preferred method for high-throughput phenotyping of physician notes.
",2024-06-20 22:05:34+00:00,cs.AI
"medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced
  Clinical Diagnosis on EMRs","  Electronic Medical Records (EMRs), while integral to modern healthcare,
present challenges for clinical reasoning and diagnosis due to their complexity
and information redundancy. To address this, we proposed medIKAL (Integrating
Knowledge Graphs as Assistants of LLMs), a framework that combines Large
Language Models (LLMs) with knowledge graphs (KGs) to enhance diagnostic
capabilities. medIKAL assigns weighted importance to entities in medical
records based on their type, enabling precise localization of candidate
diseases within KGs. It innovatively employs a residual network-like approach,
allowing initial diagnosis by the LLM to be merged into KG search results.
Through a path-based reranking algorithm and a fill-in-the-blank style prompt
template, it further refined the diagnostic process. We validated medIKAL's
effectiveness through extensive experiments on a newly introduced open-sourced
Chinese EMR dataset, demonstrating its potential to improve clinical diagnosis
in real-world settings.
",2024-06-20 13:56:52+00:00,cs.CL
"Synthesizing Multimodal Electronic Health Records via Predictive
  Diffusion Models","  Synthesizing electronic health records (EHR) data has become a preferred
strategy to address data scarcity, improve data quality, and model fairness in
healthcare. However, existing approaches for EHR data generation predominantly
rely on state-of-the-art generative techniques like generative adversarial
networks, variational autoencoders, and language models. These methods
typically replicate input visits, resulting in inadequate modeling of temporal
dependencies between visits and overlooking the generation of time information,
a crucial element in EHR data. Moreover, their ability to learn visit
representations is limited due to simple linear mapping functions, thus
compromising generation quality. To address these limitations, we propose a
novel EHR data generation model called EHRPD. It is a diffusion-based model
designed to predict the next visit based on the current one while also
incorporating time interval estimation. To enhance generation quality and
diversity, we introduce a novel time-aware visit embedding module and a
pioneering predictive denoising diffusion probabilistic model (PDDPM).
Additionally, we devise a predictive U-Net (PU-Net) to optimize P-DDPM.We
conduct experiments on two public datasets and evaluate EHRPD from fidelity,
privacy, and utility perspectives. The experimental results demonstrate the
efficacy and utility of the proposed EHRPD in addressing the aforementioned
limitations and advancing EHR data generation.
",2024-06-20 02:20:23+00:00,cs.LG
"Can Low-Rank Knowledge Distillation in LLMs be Useful for
  Microelectronic Reasoning?","  In this work, we present empirical results regarding the feasibility of using
offline large language models (LLMs) in the context of electronic design
automation (EDA). The goal is to investigate and evaluate a contemporary
language model's (Llama-2-7B) ability to function as a microelectronic Q & A
expert as well as its reasoning, and generation capabilities in solving
microelectronic-related problems. Llama-2-7B was tested across a variety of
adaptation methods, including introducing a novel low-rank knowledge
distillation (LoRA-KD) scheme. Our experiments produce both qualitative and
quantitative results.
",2024-06-19 20:14:39+00:00,cs.LG
"Transferable Tactile Transformers for Representation Learning Across
  Diverse Sensors and Tasks","  This paper presents T3: Transferable Tactile Transformers, a framework for
tactile representation learning that scales across multi-sensors and
multi-tasks. T3 is designed to overcome the contemporary issue that
camera-based tactile sensing is extremely heterogeneous, i.e. sensors are built
into different form factors, and existing datasets were collected for disparate
tasks. T3 captures the shared latent information across different sensor-task
pairings by constructing a shared trunk transformer with sensor-specific
encoders and task-specific decoders. The pre-training of T3 utilizes a novel
Foundation Tactile (FoTa) dataset, which is aggregated from several
open-sourced datasets and it contains over 3 million data points gathered from
13 sensors and 11 tasks. FoTa is the largest and most diverse dataset in
tactile sensing to date and it is made publicly available in a unified format.
Across various sensors and tasks, experiments show that T3 pre-trained with
FoTa achieved zero-shot transferability in certain sensor-task pairings, can be
further fine-tuned with small amounts of domain-specific data, and its
performance scales with bigger network sizes. T3 is also effective as a tactile
encoder for long horizon contact-rich manipulation. Results from sub-millimeter
multi-pin electronics insertion tasks show that T3 achieved a task success rate
25% higher than that of policies trained with tactile encoders trained from
scratch, or 53% higher than without tactile sensing. Data, code, and model
checkpoints are open-sourced at https://t3.alanz.info.
",2024-06-19 15:39:27+00:00,cs.RO
"Automatic generation of insights from workers' actions in industrial
  workflows with explainable Machine Learning","  New technologies such as Machine Learning (ML) gave great potential for
evaluating industry workflows and automatically generating key performance
indicators (KPIs). However, despite established standards for measuring the
efficiency of industrial machinery, there is no precise equivalent for workers'
productivity, which would be highly desirable given the lack of a skilled
workforce for the next generation of industry workflows. Therefore, an ML
solution combining data from manufacturing processes and workers' performance
for that goal is required. Additionally, in recent times intense effort has
been devoted to explainable ML approaches that can automatically explain their
decisions to a human operator, thus increasing their trustworthiness. We
propose to apply explainable ML solutions to differentiate between expert and
inexpert workers in industrial workflows, which we validate at a quality
assessment industrial workstation. Regarding the methodology used, input data
are captured by a manufacturing machine and stored in a NoSQL database. Data
are processed to engineer features used in automatic classification and to
compute workers' KPIs to predict their level of expertise (with all
classification metrics exceeding 90 %). These KPIs, and the relevant features
in the decisions are textually explained by natural language expansion on an
explainability dashboard. These automatic explanations made it possible to
infer knowledge from expert workers for inexpert workers. The latter
illustrates the interest of research in self-explainable ML for automatically
generating insights to improve productivity in industrial workflows.
",2024-06-18 15:55:11+00:00,cs.AI
"Systematic equation formulation for simulation of power electronic
  circuits using explicit methods","  Use of explicit integration methods for power electronic circuits with ideal
switch models significantly improves simulation speed. The PLECS package [1]
has effectively used this idea; however, the implementation details involved in
PLECS are not available in the public domain. Recently, a basic framework,
called the ``ELEX"" scheme, for implementing explicit methods has been described
[2]. A few modifications of the ELEX scheme for efficient handling of inductors
and switches have been presented in [3]. In this paper, the approach presented
in [3] is further augmented with robust schemes that enable systematic equation
formulation for circuits involving switches, inductors, and transformers.
Several examples are presented to illustrate the proposed schemes.
",2024-06-18 14:49:48+00:00,cs.CE
"Towards the Certification of Hybrid Architectures: Analysing
  Interference on Hardware Accelerators through PML","  The emergence of Deep Neural Network (DNN) and machine learning-based
applications paved the way for a new generation of hybrid hardware platforms.
Hybrid platforms embed several cores and accelerators in a small package.
However, in order to satisfy the Size, Weight and Power (SWaP) constraints,
limited and shared resources are integrated. This paper presents an overview of
the standards applicable to the certification of hybrid platforms and an early
mapping of their objectives to said platforms. In particular, we consider how
the classification of AMC20-152A for airborne electronic hardware applies to
hybrid platforms. We also consider AMC20-193 for multi-core platforms, and how
this standard fits different types of accelerators.
",2024-06-18 07:26:17+00:00,cs.AR
"Time Series Modeling for Heart Rate Prediction: From ARIMA to
  Transformers","  Cardiovascular disease (CVD) is a leading cause of death globally,
necessitating precise forecasting models for monitoring vital signs like heart
rate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,
are limited by their need for manual parameter tuning and challenges in
handling noisy, sparse, and highly variable medical data. This study
investigates advanced deep learning models, including LSTM, and
transformer-based architectures, for predicting heart rate time series from the
MIT-BIH Database. Results demonstrate that deep learning models, particularly
PatchTST, significantly outperform traditional models across multiple metrics,
capturing complex patterns and dependencies more effectively. This research
underscores the potential of deep learning to enhance patient monitoring and
CVD management, suggesting substantial clinical benefits. Future work should
extend these findings to larger, more diverse datasets and real-world clinical
applications to further validate and optimize model performance.
",2024-06-18 01:55:37+00:00,cs.LG
"FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal
  Healthcare Prediction","  Multimodal electronic health record (EHR) data can offer a holistic
assessment of a patient's health status, supporting various predictive
healthcare tasks. Recently, several studies have embraced the multitask
learning approach in the healthcare domain, exploiting the inherent
correlations among clinical tasks to predict multiple outcomes simultaneously.
However, existing methods necessitate samples to possess complete labels for
all tasks, which places heavy demands on the data and restricts the flexibility
of the model. Meanwhile, within a multitask framework with multimodal inputs,
how to comprehensively consider the information disparity among modalities and
among tasks still remains a challenging problem. To tackle these issues, a
unified healthcare prediction model, also named by \textbf{FlexCare}, is
proposed to flexibly accommodate incomplete multimodal inputs, promoting the
adaption to multiple healthcare tasks. The proposed model breaks the
conventional paradigm of parallel multitask prediction by decomposing it into a
series of asynchronous single-task prediction. Specifically, a task-agnostic
multimodal information extraction module is presented to capture decorrelated
representations of diverse intra- and inter-modality patterns. Taking full
account of the information disparities between different modalities and
different tasks, we present a task-guided hierarchical multimodal fusion module
that integrates the refined modality-level representations into an individual
patient-level representation. Experimental results on multiple tasks from
MIMIC-IV/MIMIC-CXR/MIMIC-NOTE datasets demonstrate the effectiveness of the
proposed method. Additionally, further analysis underscores the feasibility and
potential of employing such a multitask strategy in the healthcare domain. The
source code is available at https://github.com/mhxu1998/FlexCare.
",2024-06-17 12:03:10+00:00,cs.LG
"Management Decisions in Manufacturing using Causal Machine Learning --
  To Rework, or not to Rework?","  In this paper, we present a data-driven model for estimating optimal rework
policies in manufacturing systems. We consider a single production stage within
a multistage, lot-based system that allows for optional rework steps. While the
rework decision depends on an intermediate state of the lot and system, the
final product inspection, and thus the assessment of the actual yield, is
delayed until production is complete. Repair steps are applied uniformly to the
lot, potentially improving some of the individual items while degrading others.
The challenge is thus to balance potential yield improvement with the rework
costs incurred. Given the inherently causal nature of this decision problem, we
propose a causal model to estimate yield improvement. We apply methods from
causal machine learning, in particular double/debiased machine learning (DML)
techniques, to estimate conditional treatment effects from data and derive
policies for rework decisions. We validate our decision model using real-world
data from opto-electronic semiconductor manufacturing, achieving a yield
improvement of 2 - 3% during the color-conversion process of white
light-emitting diodes (LEDs).
",2024-06-17 08:14:40+00:00,cs.LG
"Daedalus 2: Autorotation Entry, Descent and Landing Experiment on
  REXUS29","  In recent years, interplanetary exploration has gained significant momentum,
leading to a focus on the development of launch vehicles. However, the critical
technology of edl mechanisms has not received the same level of attention and
remains less mature and capable. To address this gap, we took advantage of the
REXUS program to develop a pioneering edl mechanism. We propose an alternative
to conventional, parachute based landing vehicles by utilizing autorotation.
Our approach enables future additions such as steerability, controllability,
and the possibility of a soft landing. To validate the technique and our
specific implementation, we conducted a sounding rocket experiment on REXUS29.
The systems design is outlined with relevant design decisions and constraints,
covering software, mechanics, electronics and control systems. Furthermore, an
emphasis will also be the organization and setup of the team entirely made up
and executed by students. The flight results on REXUS itself are presented,
including the most important outcomes and possible reasons for mission failure.
We have not archived an autorotation based landing, but provide a reliable way
of building and operating such vehicles. Ultimately, future works and
possibilities for improvements are outlined. The research presented in this
paper highlights the need for continued exploration and development of edl
mechanisms for future interplanetary missions. By discussing our results, we
hope to inspire further research in this area and contribute to the advancement
of space exploration technology.
",2024-06-17 07:54:33+00:00,cs.RO
"Large Reasoning Models for 3D Floorplanning in EDA: Learning from
  Imperfections","  In this paper, we introduce Dreamweaver, which belongs to a new class of
auto-regressive decision-making models known as large reasoning models (LRMs).
Dreamweaver is designed to improve 3D floorplanning in electronic design
automation (EDA) via an architecture that melds advancements in
sequence-to-sequence reinforcement learning algorithms. A significant advantage
of our approach is its ability to effectively reason over large discrete action
spaces, which is essential for handling the numerous potential positions for
various functional blocks in floorplanning. Additionally, Dreamweaver
demonstrates strong performance even when trained on entirely random
trajectories, showcasing its capacity to leverage sub-optimal or non-expert
trajectories to enhance its results. This innovative approach contributes to
streamlining the integrated circuit (IC) design flow and reducing the high
computational costs typically associated with floorplanning. We evaluate its
performance against a current state-of-the-art method, highlighting notable
improvements.
",2024-06-15 07:41:16+00:00,cs.LG
"Improving Ab-Initio Cryo-EM Reconstruction with Semi-Amortized Pose
  Inference","  Cryo-Electron Microscopy (cryo-EM) is an increasingly popular experimental
technique for estimating the 3D structure of macromolecular complexes such as
proteins based on 2D images. These images are notoriously noisy, and the pose
of the structure in each image is unknown \textit{a priori}. Ab-initio 3D
reconstruction from 2D images entails estimating the pose in addition to the
structure. In this work, we propose a new approach to this problem. We first
adopt a multi-head architecture as a pose encoder to infer multiple plausible
poses per-image in an amortized fashion. This approach mitigates the high
uncertainty in pose estimation by encouraging exploration of pose space early
in reconstruction. Once uncertainty is reduced, we refine poses in an
auto-decoding fashion. In particular, we initialize with the most likely pose
and iteratively update it for individual images using stochastic gradient
descent (SGD). Through evaluation on synthetic datasets, we demonstrate that
our method is able to handle multi-modal pose distributions during the
amortized inference stage, while the later, more flexible stage of direct pose
optimization yields faster and more accurate convergence of poses compared to
baselines. Finally, on experimental data, we show that our approach is faster
than state-of-the-art cryoAI and achieves higher-resolution reconstruction.
",2024-06-15 00:44:32+00:00,cs.CV
"CMDS: Cross-layer Dataflow Optimization for DNN Accelerators Exploiting
  Multi-bank Memories","  Deep neural networks (DNN) use a wide range of network topologies to achieve
high accuracy within diverse applications. This model diversity makes it
impossible to identify a single ""dataflow"" (execution schedule) to perform
optimally across all possible layers and network topologies. Several frameworks
support the exploration of the best dataflow for a given DNN layer and
hardware. However, switching the dataflow from one layer to the next layer
within one DNN model can result in hardware inefficiencies stemming from memory
data layout mismatch among the layers. Unfortunately, all existing frameworks
treat each layer independently and typically model memories as black boxes (one
large monolithic wide memory), which ignores the data layout and can not deal
with the data layout dependencies of sequential layers. These frameworks are
not capable of doing dataflow cross-layer optimization. This work, hence, aims
at cross-layer dataflow optimization, taking the data dependency and data
layout reshuffling overheads among layers into account. Additionally, we
propose to exploit the multibank memories typically present in modern DNN
accelerators towards efficiently reshuffling data to support more dataflow at
low overhead. These innovations are supported through the Cross-layer
Memory-aware Dataflow Scheduler (CMDS). CMDS can model DNN execution
energy/latency while considering the different data layout requirements due to
the varied optimal dataflow of layers. Compared with the state-of-the-art
(SOTA), which performs layer-optimized memory-unaware scheduling, CMDS achieves
up to 5.5X energy reduction and 1.35X latency reduction with negligible
hardware cost.
",2024-06-14 14:45:31+00:00,cs.AR
"TACCO: Task-guided Co-clustering of Clinical Concepts and Patient Visits
  for Disease Subtyping based on EHR Data","  The growing availability of well-organized Electronic Health Records (EHR)
data has enabled the development of various machine learning models towards
disease risk prediction. However, existing risk prediction methods overlook the
heterogeneity of complex diseases, failing to model the potential disease
subtypes regarding their corresponding patient visits and clinical concept
subgroups. In this work, we introduce TACCO, a novel framework that jointly
discovers clusters of clinical concepts and patient visits based on a
hypergraph modeling of EHR data. Specifically, we develop a novel
self-supervised co-clustering framework that can be guided by the risk
prediction task of specific diseases. Furthermore, we enhance the hypergraph
model of EHR data with textual embeddings and enforce the alignment between the
clusters of clinical concepts and patient visits through a contrastive
objective. Comprehensive experiments conducted on the public MIMIC-III dataset
and Emory internal CRADLE dataset over the downstream clinical tasks of
phenotype classification and cardiovascular risk prediction demonstrate an
average 31.25% performance improvement compared to traditional ML baselines and
a 5.26% improvement on top of the vanilla hypergraph model without our
co-clustering mechanism. In-depth model analysis, clustering results analysis,
and clinical case studies further validate the improved utilities and
insightful interpretations delivered by TACCO. Code is available at
https://github.com/PericlesHat/TACCO.
",2024-06-14 14:18:38+00:00,cs.LG
"Recy-ctronics: Designing Fully Recyclable Electronics With Varied Form
  Factors","  For today's electronics manufacturing process, the emphasis on stable
functionality, durability, and fixed physical forms is designed to ensure
long-term usability. However, this focus on robustness and permanence
complicates the disassembly and recycling processes, leading to significant
environmental repercussions. In this paper, we present three approaches that
leverage easily recyclable materials-specifically, polyvinyl alcohol (PVA) and
liquid metal (LM)-alongside accessible manufacturing techniques to produce
electronic components and systems with versatile form factors. Our work centers
on the development of recyclable electronics through three methods: 1) creating
sheet electronics by screen printing LM traces on PVA substrates; 2) developing
foam-based electronics by immersing mechanically stirred PVA foam into an LM
solution; and 3) fabricating recyclable electronic tubes by injecting LM into
mold cast PVA tubes, which can then be woven into various structures. To
further assess the sustainability of our proposed methods, we conducted a life
cycle assessment (LCA) to evaluate the environmental impact of our recyclable
electronics in comparison to their conventional counterparts.
",2024-06-13 22:43:47+00:00,cs.HC
"Cross-Modality Program Representation Learning for Electronic Design
  Automation with High-Level Synthesis","  In recent years, domain-specific accelerators (DSAs) have gained popularity
for applications such as deep learning and autonomous driving. To facilitate
DSA designs, programmers use high-level synthesis (HLS) to compile a high-level
description written in C/C++ into a design with low-level hardware description
languages that eventually synthesize DSAs on circuits. However, creating a
high-quality HLS design still demands significant domain knowledge,
particularly in microarchitecture decisions expressed as \textit{pragmas}.
Thus, it is desirable to automate such decisions with the help of machine
learning for predicting the quality of HLS designs, requiring a deeper
understanding of the program that consists of original code and pragmas.
Naturally, these programs can be considered as sequence data. In addition,
these programs can be compiled and converted into a control data flow graph
(CDFG). But existing works either fail to leverage both modalities or combine
the two in shallow or coarse ways. We propose ProgSG, a model that allows
interaction between the source code sequence modality and the graph modality in
a deep and fine-grained way. To alleviate the scarcity of labeled designs, a
pre-training method is proposed based on a suite of compiler's data flow
analysis tasks. Experimental results show that ProgSG reduces the RMSE of
design performance predictions by up to $22\%$, and identifies designs with an
average of $1.10\times$ and $1.26\times$ (up to $8.17\times$ and $13.31\times$)
performance improvement in design space exploration (DSE) task compared to HARP
and AutoDSE, respectively.
",2024-06-13 22:34:58+00:00,cs.LG
A tutorial on fairness in machine learning in healthcare,"  $\textbf{OBJECTIVE}$: Ensuring that machine learning (ML) algorithms are safe
and effective within all patient groups, and do not disadvantage particular
patients, is essential to clinical decision making and preventing the
reinforcement of existing healthcare inequities. The objective of this tutorial
is to introduce the medical informatics community to the common notions of
fairness within ML, focusing on clinical applications and implementation in
practice.
  $\textbf{TARGET AUDIENCE}$: As gaps in fairness arise in a variety of
healthcare applications, this tutorial is designed to provide an understanding
of fairness, without assuming prior knowledge, to researchers and clinicians
who make use of modern clinical data.
  $\textbf{SCOPE}$: We describe the fundamental concepts and methods used to
define fairness in ML, including an overview of why models in healthcare may be
unfair, a summary and comparison of the metrics used to quantify fairness, and
a discussion of some ongoing research. We illustrate some of the fairness
methods introduced through a case study of mortality prediction in a publicly
available electronic health record dataset. Finally, we provide a user-friendly
R package for comprehensive group fairness evaluation, enabling researchers and
clinicians to assess fairness in their own ML work.
",2024-06-13 16:41:30+00:00,cs.LG
"High-Resolution, Multi-Channel FPGA-Based Time-to-Digital Converter","  In this paper we present a novel high-resolution multi-channel FPGA-based
time-to-digital converter (TDC). We designed and implemented a complex
electronic circuit on the FPGA, whose overall accuracy is several orders of
magnitude greater than the accuracy of the FPGA used in digital mode. Our
sensor device contains simple circuit elements that are cheap and easily
accessible (Xilinx Spartan 3 and Spartan 6). Using our design, many channels
(80-100 channels) can be implemented on a larger FPGA. The prototype of our TDC
has been implemented and functionally verified by experiments and measurements.
By a certified pulse generator 20 ps precision has been measured over the range
of 3 ns. Using more precise clock signal this range may be extended. The
achieved resolution is 5 ps. Its resolution, channel number and range can be
configured dynamically, which makes it suitable for effective use in industrial
purposes.
",2024-06-13 16:40:54+00:00,cs.AR
RH-SQL: Refined Schema and Hardness Prompt for Text-to-SQL,"  Text-to-SQL is a technology that converts natural language queries into the
structured query language SQL. A novel research approach that has recently
gained attention focuses on methods based on the complexity of SQL queries,
achieving notable performance improvements. However, existing methods entail
significant storage and training costs, which hampers their practical
application. To address this issue, this paper introduces a method for
Text-to-SQL based on Refined Schema and Hardness Prompt. By filtering out
low-relevance schema information with a refined schema and identifying query
hardness through a Language Model (LM) to form prompts, this method reduces
storage and training costs while maintaining performance. It's worth mentioning
that this method is applicable to any sequence-to-sequence (seq2seq) LM. Our
experiments on the Spider dataset, specifically with large-scale LMs, achieved
an exceptional Execution accuracy (EX) of 82.6%, demonstrating the
effectiveness and greater suitability of our method for real-world
applications.
",2024-06-13 14:04:34+00:00,cs.CL
"An Unsupervised Approach to Achieve Supervised-Level Explainability in
  Healthcare Records","  Electronic healthcare records are vital for patient safety as they document
conditions, plans, and procedures in both free text and medical codes. Language
models have significantly enhanced the processing of such records, streamlining
workflows and reducing manual data entry, thereby saving healthcare providers
significant resources. However, the black-box nature of these models often
leaves healthcare professionals hesitant to trust them. State-of-the-art
explainability methods increase model transparency but rely on human-annotated
evidence spans, which are costly. In this study, we propose an approach to
produce plausible and faithful explanations without needing such annotations.
We demonstrate on the automated medical coding task that adversarial robustness
training improves explanation plausibility and introduce AttInGrad, a new
explanation method superior to previous ones. By combining both contributions
in a fully unsupervised setup, we produce explanations of comparable quality,
or better, to that of a supervised approach. We release our code and model
weights.
",2024-06-13 09:36:27+00:00,cs.LG
"Inverse Probability of Treatment Weighting with Deep Sequence Models
  Enables Accurate treatment effect Estimation from Electronic Health Records","  Observational data have been actively used to estimate treatment effect,
driven by the growing availability of electronic health records (EHRs).
However, EHRs typically consist of longitudinal records, often introducing
time-dependent confoundings that hinder the unbiased estimation of treatment
effect. Inverse probability of treatment weighting (IPTW) is a widely used
propensity score method since it provides unbiased treatment effect estimation
and its derivation is straightforward. In this study, we aim to utilize IPTW to
estimate treatment effect in the presence of time-dependent confounding using
claims records. Previous studies have utilized propensity score methods with
features derived from claims records through feature processing, which
generally requires domain knowledge and additional resources to extract
information to accurately estimate propensity scores. Deep sequence models,
particularly recurrent neural networks and self-attention-based architectures,
have demonstrated good performance in modeling EHRs for various downstream
tasks. We propose that these deep sequence models can provide accurate IPTW
estimation of treatment effect by directly estimating the propensity scores
from claims records without the need for feature processing. We empirically
demonstrate this by conducting comprehensive evaluations using synthetic and
semi-synthetic datasets.
",2024-06-13 06:29:16+00:00,cs.LG
UruBots Autonomous Cars Team One Description Paper for FIRA 2024,"  This document presents the design of an autonomous car developed by the
UruBots team for the 2024 FIRA Autonomous Cars Race Challenge. The project
involves creating an RC-car sized electric vehicle capable of navigating race
tracks with in an autonomous manner. It integrates mechanical and electronic
systems alongside artificial intelligence based algorithms for the navigation
and real-time decision-making. The core of our project include the utilization
of an AI-based algorithm to learn information from a camera and act in the
robot to perform the navigation. We show that by creating a dataset with more
than five thousand samples and a five-layered CNN we managed to achieve
promissing performance we our proposed hardware setup. Overall, this paper aims
to demonstrate the autonomous capabilities of our car, highlighting its
readiness for the 2024 FIRA challenge, helping to contribute to the field of
autonomous vehicle research.
",2024-06-13 02:07:06+00:00,cs.RO
Explainable AI improves task performance in human-AI collaboration,"  Artificial intelligence (AI) provides considerable opportunities to assist
human work. However, one crucial challenge of human-AI collaboration is that
many AI algorithms operate in a black-box manner where the way how the AI makes
predictions remains opaque. This makes it difficult for humans to validate a
prediction made by AI against their own domain knowledge. For this reason, we
hypothesize that augmenting humans with explainable AI as a decision aid
improves task performance in human-AI collaboration. To test this hypothesis,
we analyze the effect of augmenting domain experts with explainable AI in the
form of visual heatmaps. We then compare participants that were either
supported by (a) black-box AI or (b) explainable AI, where the latter supports
them to follow AI predictions when the AI is accurate or overrule the AI when
the AI predictions are wrong. We conducted two preregistered experiments with
representative, real-world visual inspection tasks from manufacturing and
medicine. The first experiment was conducted with factory workers from an
electronics factory, who performed $N=9,600$ assessments of whether electronic
products have defects. The second experiment was conducted with radiologists,
who performed $N=5,650$ assessments of chest X-ray images to identify lung
lesions. The results of our experiments with domain experts performing
real-world tasks show that task performance improves when participants are
supported by explainable AI instead of black-box AI. For example, in the
manufacturing setting, we find that augmenting participants with explainable AI
(as opposed to black-box AI) leads to a five-fold decrease in the median error
rate of human decisions, which gives a significant improvement in task
performance.
",2024-06-12 14:36:22+00:00,cs.HC
A Labeled Array Distance Metric for Measuring Image Segmentation Quality,"  This work introduces two new distance metrics for comparing labeled arrays,
which are common outputs of image segmentation algorithms. Each pixel in an
image is assigned a label, with binary segmentation providing only two labels
('foreground' and 'background'). These can be represented by a simple binary
matrix and compared using pixel differences. However, many segmentation
algorithms output multiple regions in a labeled array. We propose two distance
metrics, named LAD and MADLAD, that calculate the distance between two labeled
images. By doing so, the accuracy of different image segmentation algorithms
can be evaluated by measuring their outputs against a 'ground truth' labeling.
Both proposed metrics, operating with a complexity of $O(N)$ for images with
$N$ pixels, are designed to quickly identify similar labeled arrays, even when
different labeling methods are used. Comparisons are made between images
labeled manually and those labeled by segmentation algorithms. This evaluation
is crucial when searching through a space of segmentation algorithms and their
hyperparameters via a genetic algorithm to identify the optimal solution for
automated segmentation, which is the goal in our lab, SEE-Insight. By measuring
the distance from the ground truth, these metrics help determine which
algorithm provides the most accurate segmentation.
",2024-06-12 03:39:16+00:00,cs.CV
Merlin: A Vision Language Foundation Model for 3D Computed Tomography,"  Over 85 million computed tomography (CT) scans are performed annually in the
US, of which approximately one quarter focus on the abdomen. Given the current
radiologist shortage, there is a large impetus to use artificial intelligence
to alleviate the burden of interpreting these complex imaging studies. Prior
state-of-the-art approaches for automated medical image interpretation leverage
vision language models (VLMs). However, current medical VLMs are generally
limited to 2D images and short reports, and do not leverage electronic health
record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train
using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes
(1.8+ million codes), and radiology reports (6+ million tokens). We evaluate
Merlin on 6 task types and 752 individual tasks. The non-adapted
(off-the-shelf) tasks include zero-shot findings classification (31 findings),
phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval
(image to findings and image to impressions), while model adapted tasks include
5-year disease prediction (6 diseases), radiology report generation, and 3D
semantic segmentation (20 organs). We perform internal validation on a test set
of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public
CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant
evaluations, we assess the efficacy of various network architectures and
training strategies to depict that Merlin has favorable performance to existing
task-specific baselines. We derive data scaling laws to empirically assess
training data needs for requisite downstream task performance. Furthermore,
unlike conventional VLMs that require hundreds of GPUs for training, we perform
all training on a single GPU.
",2024-06-10 17:53:01+00:00,cs.CV
"The Evolution of Applications, Hardware Design, and Channel Modeling for
  Terahertz (THz) Band Communications and Sensing: Ready for 6G?","  For decades, the terahertz (THz) frequency band had been primarily explored
in the context of radar, imaging, and spectroscopy, where multi-gigahertz (GHz)
and even THz-wide channels and the properties of terahertz photons offered
attractive target accuracy, resolution, and classification capabilities.
Meanwhile, the exploitation of the terahertz band for wireless communication
had originally been limited due to several reasons, including (i) no immediate
need for such high data rates available via terahertz bands and (ii) challenges
in designing sufficiently high power terahertz systems at reasonable cost and
efficiency, leading to what was often referred to as ""the terahertz gap"". This
roadmap paper first reviews the evolution of the hardware design approaches for
terahertz systems, including electronic, photonic, and plasmonic approaches,
and the understanding of the terahertz channel itself, in diverse scenarios,
ranging from common indoors and outdoors scenarios to intra-body and
outer-space environments. The article then summarizes the lessons learned
during this multi-decade process and the cutting-edge state-of-the-art
findings, including novel methods to quantify power efficiency, which will
become more important in making design choices. Finally, the manuscript
presents the authors' perspective and insights on how the evolution of
terahertz systems design will continue toward enabling efficient terahertz
communications and sensing solutions as an integral part of next-generation
wireless systems.
",2024-06-10 08:40:11+00:00,cs.NI
"Thanking the World: Exploring Gender-Based Differences in Acknowledgment
  Patterns and Support Systems in Theses","  Research on acknowledgment sections of scientific papers has gained
significant attention, but there remains a dearth of studies examining
acknowledgments in the context of Electronic Theses and Dissertations. This
paper addresses this gap by investigating the sources of support for male and
female researchers in completing their master's or doctoral theses, focusing on
the discipline of Library and Information Science. We utilize a novel method of
extracting the various types of support systems that are acknowledged in 1252
ETDs using RoBERTa-based models. The most prominent forms of support
acknowledged by researchers are academic, moral, financial, and religious
support. While there are no significant gender-based differences in religious
and financial support, the ratio of academic to moral support acknowledged by
researchers shows strong gender-based variation. Additionally, advisors display
a preference for supervising same-gender researchers. By comprehending the
nuances of support systems and the unique challenges faced by researchers of
different genders, we can foster a more inclusive and supportive academic
environment. The insights gained from this research have implications for
improving mentoring practices and promoting gender equality in academia.
",2024-06-10 04:06:55+00:00,cs.DL
"From Basic to Extra Features: Hypergraph Transformer
  Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR","  Electronic Health Records (EHRs) contain rich patient information and are
crucial for clinical research and practice. In recent years, deep learning
models have been applied to EHRs, but they often rely on massive features,
which may not be readily available for all patients. We propose HTP-Star, which
leverages hypergraph structures with a pretrain-then-finetune framework for
modeling EHR data, enabling seamless integration of additional features.
Additionally, we design two techniques, namely (1) Smoothness-inducing
Regularization and (2) Group-balanced Reweighting, to enhance the model's
robustness during fine-tuning. Through experiments conducted on two real EHR
datasets, we demonstrate that HTP-Star consistently outperforms various
baselines while striking a balance between patients with basic and extra
features.
",2024-06-09 07:41:03+00:00,cs.LG
Solving Inverse Problems in Protein Space Using Diffusion-Based Priors,"  The interaction of a protein with its environment can be understood and
controlled via its 3D structure. Experimental methods for protein structure
determination, such as X-ray crystallography or cryogenic electron microscopy,
shed light on biological processes but introduce challenging inverse problems.
Learning-based approaches have emerged as accurate and efficient methods to
solve these inverse problems for 3D structure determination, but are
specialized for a predefined type of measurement. Here, we introduce a
versatile framework to turn raw biophysical measurements of varying types into
3D atomic models. Our method combines a physics-based forward model of the
measurement process with a pretrained generative model providing a
task-agnostic, data-driven prior. Our method outperforms posterior sampling
baselines on both linear and non-linear inverse problems. In particular, it is
the first diffusion-based method for refining atomic models from cryo-EM
density maps.
",2024-06-06 16:38:53+00:00,cs.LG
$i$Trust: Trust-Region Optimisation with Ising Machines,"  In this work, we present a heretofore unseen application of Ising machines to
perform trust region-based optimisation with box constraints. This is done by
considering a specific form of opto-electronic oscillator-based coherent Ising
machines with clipped transfer functions, and proposing appropriate
modifications to facilitate trust-region optimisation. The enhancements include
the inclusion of non-symmetric coupling and linear terms, modulation of noise,
and compatibility with convex-projections to improve its convergence. The
convergence of the modified Ising machine has been shown under the reasonable
assumptions of convexity or invexity. The mathematical structures of the
modified Ising machine and trust-region methods have been exploited to design a
new trust-region method to effectively solve unconstrained optimisation
problems in many scenarios, such as machine learning and optimisation of
parameters in variational quantum algorithms. Hence, the proposition is useful
for both classical and quantum-classical hybrid scenarios. Finally, the
convergence of the Ising machine-based trust-region method, has also been
proven analytically, establishing the feasibility of the technique.
",2024-06-06 14:25:59+00:00,cs.ET
"From operculum and body tail movements to different coupling of physical
  activity and respiratory frequency in farmed gilthead sea bream and European
  sea bass. Insights on aquaculture biosensing","  The AEFishBIT tri-axial accelerometer was externally attached to the
operculum to assess the divergent activity and respiratory patterns of two
marine farmed fish, the gilthead sea bream (Sparus aurata) and European sea
bass (Dicentrarchus labrax). Analysis of raw data from exercised fish
highlighted the large amplitude of operculum aperture and body tail movements
in European sea bass, which were overall more stable at low-medium exercise
intensity levels. Cosinor analysis in free-swimming fish (on-board data
processing) highlighted a pronounced daily rhythmicity of locomotor activity
and respiratory frequency in both gilthead sea bream and European sea bass.
Acrophases of activity and respiration were coupled in gilthead sea bream,
acting feeding time (once daily at 11:00 h) as a main synchronizing factor. By
contrast, locomotor activity and respiratory frequency were out of phase in
European sea bass with activity acrophase on early morning and respiration
acrophase on the afternoon. The daily range of activity and respiration
variation was also higher in European sea bass, probably as part of the
adaptation of this fish species to act as a fast swimming predator. In any
case, lower locomotor activity and enhanced respiration were associated with
larger body weight in both fish species. This agrees with the notion that
selection for fast growth in farming conditions is accompanied by a lower
activity profile, which may favor an efficient feed conversion for growth
purposes. Therefore, the use of behavioral monitoring is becoming a reliable
and large-scale promising tool for selecting more efficient farmed fish,
allowing researchers and farmers to establish stricter criteria of welfare for
more sustainable and ethical fish production.
",2024-06-06 08:46:00+00:00,cs.CV
"CIRCUITSYNTH: Leveraging Large Language Models for Circuit Topology
  Synthesis","  Circuit topology generation plays a crucial role in the design of electronic
circuits, influencing the fundamental functionality of the circuit. In this
paper, we introduce CIRCUITSYNTH, a novel approach that harnesses LLMs to
facilitate the automated synthesis of valid circuit topologies. With a dataset
comprising both valid and invalid circuit configurations, CIRCUITSYNTH employs
a sophisticated two-phase methodology, comprising Circuit Topology Generation
and Circuit Topology Refinement. Experimental results demonstrate the
effectiveness of CIRCUITSYNTH compared to various fine-tuned LLM variants. Our
approach lays the foundation for future research aimed at enhancing circuit
efficiency and specifying output voltage, thus enabling the automated
generation of circuit topologies with improved performance and adherence to
design requirements.
",2024-06-06 01:59:59+00:00,cs.LG
The Logarithmic Memristor-Based Bayesian Machine,"  The demand for explainable and energy-efficient artificial intelligence (AI)
systems for edge computing has led to significant interest in electronic
systems dedicated to Bayesian inference. Traditional designs of such systems
often rely on stochastic computing, which offers high energy efficiency but
suffers from latency issues and struggles with low-probability values. In this
paper, we introduce the logarithmic memristor-based Bayesian machine, an
innovative design that leverages the unique properties of memristors and
logarithmic computing as an alternative to stochastic computing. We present a
prototype machine fabricated in a hybrid CMOS/hafnium-oxide memristor process.
We validate the versatility and robustness of our system through experimental
validation and extensive simulations in two distinct applications: gesture
recognition and sleep stage classification. The logarithmic approach simplifies
the computational model by converting multiplications into additions and
enhances the handling of low-probability events, which are crucial in
time-dependent tasks. Our results demonstrate that the logarithmic Bayesian
machine achieves superior performance in terms of accuracy and energy
efficiency compared to its stochastic counterpart, particularly in scenarios
involving complex probabilistic models. This work paves the way for the
deployment of advanced AI capabilities in edge devices, where power efficiency
and reliability are paramount.
",2024-06-05 17:57:58+00:00,cs.ET
Using GNN property predictors as molecule generators,"  Graph neural networks (GNNs) have emerged as powerful tools to accurately
predict materials and molecular properties in computational discovery
pipelines. In this article, we exploit the invertible nature of these neural
networks to directly generate molecular structures with desired electronic
properties. Starting from a random graph or an existing molecule, we perform a
gradient ascent while holding the GNN weights fixed in order to optimize its
input, the molecular graph, towards the target property. Valence rules are
enforced strictly through a judicious graph construction. The method relies
entirely on the property predictor; no additional training is required on
molecular structures. We demonstrate the application of this method by
generating molecules with specific DFT-verified energy gaps and octanol-water
partition coefficients (logP). Our approach hits target properties with rates
comparable to or better than state-of-the-art generative models while
consistently generating more diverse molecules.
",2024-06-05 13:53:47+00:00,cs.LG
MESS: Modern Electronic Structure Simulations,"  Electronic structure simulation (ESS) has been used for decades to provide
quantitative scientific insights on an atomistic scale, enabling advances in
chemistry, biology, and materials science, among other disciplines. Following
standard practice in scientific computing, the software packages driving these
studies have been implemented in compiled languages such as FORTRAN and C.
However, the recent introduction of machine learning (ML) into these domains
has meant that ML models must be coded in these languages, or that complex
software bridges have to be built between ML models in Python and these large
compiled software systems. This is in contrast with recent progress in modern
ML frameworks which aim to optimise both ease of use and high performance by
harnessing hardware acceleration of tensor programs defined in Python. We
introduce MESS: a modern electronic structure simulation package implemented in
JAX; porting the ESS code to the ML world. We outline the costs and benefits of
following the software development practices used in ML for this important
scientific workload. MESS shows significant speedups n widely available
hardware accelerators and simultaneously opens a clear pathway towards
combining ESS with ML. MESS is available at
https://github.com/graphcore-research/mess.
",2024-06-05 10:15:16+00:00,cs.LG
16-channel Photonic Solver for Optimization Problems on a Silicon Chip,"  In this article, we proposed a programmable 16-channel photonic solver for
quadratic unconstrained binary optimization (QUBO) problems. The solver is
based on a hybrid optoelectronic scheme including a photonic chip and the
corresponding electronic driving circuit. The photonic chip is fabricated on
silicon on insulator (SOI) substrate and integrates high-speed electro-optic
modulators, thermo-optic phase shifters and photodetectors to conduct the
16-dimensional optical vector-matrix multiplication (OVMM). Due to the parallel
and low latency propagation of lightwave, the calculation of the QUBO cost
function can be accelerated. Besides, the electronic processor is employed to
run the heuristic algorithm to search the optimal solution. In the experiment,
two 16-dimensional randomly generated QUBO problems are solved with high
successful probabilities. To our knowledge, it is the largest scale of
programmable and on-chip photonic solver ever reported. Moreover, the computing
speed of the OVMM on photonic chip is ~2 TFLOP/s. It shows the potential of
fast solving such optimization problems with integrated photonic systems.
",2024-06-05 08:48:16+00:00,cs.ET
"TD-MQTT: Transparent Distributed MQTT Brokers for Horizontal IoT
  Applications","  MQTT (Message Queuing Telemetry Transport) has become the perfect messaging
protocol for IoT (Internet of Things) systems since it is the lightest protocol
designed for low bandwidth, high-latency, unreliable networks. Today, the
strategy of distributing several MQTT brokers on the networks is widely used
because the strategy of using a single broker is no longer efficient. However,
in the distributing architectures of MQTT brokers, a subscriber should have
prior knowledge about the address of the broker that publishes the data on the
topics of interest. In this paper, we tackle this challenge by proposing a
mechanism that connects the subscribers to the brokers in a transparent way.
The proposed approach, known as TD-MQTT (Transparent Distributed MQTT brokers),
requires no prior knowledge of the brokers by the subscribers. The data will be
carried automatically from brokers that can change their configuration and
location. The transparency will help to use IoT data without worrying about
their location and dynamic configuration changes. To evaluate our approach, we
compared it with the basic distributed MQTT and the EMMA (MQTT Middle-ware for
Edge Computing Applications) approach. The results of the evaluation show that
TD-MQTT is much better than the standard MQTT, especially in terms of response
time.
",2024-06-04 19:16:44+00:00,cs.NI
"Fairness-Optimized Synthetic EHR Generation for Arbitrary Downstream
  Predictive Tasks","  Among various aspects of ensuring the responsible design of AI tools for
healthcare applications, addressing fairness concerns has been a key focus
area. Specifically, given the wide spread of electronic health record (EHR)
data and their huge potential to inform a wide range of clinical decision
support tasks, improving fairness in this category of health AI tools is of key
importance. While such a broad problem (that is, mitigating fairness in
EHR-based AI models) has been tackled using various methods, task- and
model-agnostic methods are noticeably rare. In this study, we aimed to target
this gap by presenting a new pipeline that generates synthetic EHR data, which
is not only consistent with (faithful to) the real EHR data but also can reduce
the fairness concerns (defined by the end-user) in the downstream tasks, when
combined with the real data. We demonstrate the effectiveness of our proposed
pipeline across various downstream tasks and two different EHR datasets. Our
proposed pipeline can add a widely applicable and complementary tool to the
existing toolbox of methods to address fairness in health AI applications such
as those modifying the design of a downstream model. The codebase for our
project is available at https://github.com/healthylaife/FairSynth
",2024-06-04 17:29:21+00:00,cs.LG
"Towards an Extensible Model-Based Digital Twin Framework for Space
  Launch Vehicles","  The concept of Digital Twin (DT) is increasingly applied to systems on
different levels of abstraction across domains, to support monitoring,
analysis, diagnosis, decision making and automated control. Whilst the interest
in applying DT is growing, the definition of DT is unclear, neither is there a
clear pathway to develop DT to fully realise its capacities. In this paper, we
revise the concept of DT and its categorisation. We propose a DT maturity
matrix, based on which we propose a model-based DT development methodology. We
also discuss how model-based tools can be used to support the methodology and
present our own supporting tool. We report our preliminary findings with a
discussion on a case study, in which we use our proposed methodology and our
supporting tool to develop an extensible DT platform for the assurance of
Electrical and Electronics systems of space launch vehicles.
",2024-06-04 11:31:00+00:00,cs.SE
"A Novel Paradigm Shift for Next-Generation: Symbiotic Backscatter
  Rate-Splitting Multiple Access Systems","  Next-generation wireless networks are projected to empower a broad range of
Internet-of-things (IoT) applications and services with extreme data rates,
posing new challenges in delivering large-scale connectivity at a low cost to
current communication paradigms. Rate-splitting multiple access (RSMA) is one
of the most spotlight nominees, conceived to address spectrum scarcity while
reaching massive connectivity. Meanwhile, symbiotic communication is said to be
an inexpensive way to realize future IoT on a large scale. To reach the goal of
spectrum efficiency improvement and low energy consumption, we merge these
advances by means of introducing a novel paradigm shift, called symbiotic
backscatter RSMA, for the next generation. Specifically, we first establish the
way to operate the symbiotic system to assist the readers in apprehending the
proposed paradigm, then guide detailed design in beamforming weights with four
potential gain-control (GC) strategies for enhancing symbiotic communication,
and finally provide an information-theoretic framework using a new metric,
called symbiotic outage probability (SOP) to characterize the proposed system
performance. Through numerical result experiments, we show that the developed
framework can accurately predict the actual SOP and the efficacy of the
proposed GC strategies in improving the SOP performance.
",2024-06-04 03:06:17+00:00,cs.IT
"AI-based Classification of Customer Support Tickets: State of the Art
  and Implementation with AutoML","  Automation of support ticket classification is crucial to improve customer
support performance and shortening resolution time for customer inquiries. This
research aims to test the applicability of automated machine learning (AutoML)
as a technology to train a machine learning model (ML model) that can classify
support tickets. The model evaluation conducted in this research shows that
AutoML can be used to train ML models with good classification performance.
Moreover, this paper fills a research gap by providing new insights into
developing AI solutions without a dedicated professional by utilizing AutoML,
which makes this technology more accessible for companies without specialized
AI departments and staff.
",2024-06-03 21:13:02+00:00,cs.LG
"Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and
  Abbreviation De-hallucination","  Electronic design engineers are challenged to find relevant information
efficiently for a myriad of tasks within design construction, verification and
technology development. Large language models (LLM) have the potential to help
improve productivity by serving as conversational agents that effectively
function as subject-matter experts. In this paper we demonstrate Ask-EDA, a
chat agent designed to serve as a 24x7 expert available to provide guidance to
design engineers. Ask-EDA leverages LLM, hybrid retrieval augmented generation
(RAG) and abbreviation de-hallucination (ADH) techniques to deliver more
relevant and accurate responses. We curated three evaluation datasets, namely
q2a-100, cmds-100 and abbr-100. Each dataset is tailored to assess a distinct
aspect: general design question answering, design command handling and
abbreviation resolution. We demonstrated that hybrid RAG offers over a 40%
improvement in Recall on the q2a-100 dataset and over a 60% improvement on the
cmds-100 dataset compared to not using RAG, while ADH yields over a 70%
enhancement in Recall on the abbr-100 dataset. The evaluation results show that
Ask-EDA can effectively respond to design-related inquiries.
",2024-06-03 19:40:28+00:00,cs.CL
"Design of a High-Performance Tomographic Tactile Sensor by Manipulating
  the Detector Conductivity","  Recent advancements in soft robots, human-machine interfaces, and wearable
electronics have led to an increased demand for high-performance soft tactile
sensors. Tomographic tactile sensor based on resistive coupling is a novel
contact pressure imaging method that allows the use of an arbitrary conductive
material in a detector. However, the influence of material properties on the
sensing performance remains unclear and the efficient and appropriate selection
of materials is difficult. In this study, the relationship between the
conductivity distribution of the material used as a detector and the sensing
performance including sensitivity, force range, spatial resolution, and
position accuracy is clarified to develop a high-performance tomographic
tactile sensor. The performance maps reveal that a material with a conductivity
of approximately 0.2 S/m can serve as an effective detector for touch
interactions involving a force range of several Newtons. Additionally,
incorporating gradient conductivity in the cross-section of the detector and
multi-layer conductive porous media with anisotropic conductive bonding can
help expand the design flexibility for enhanced performance. Based on these
findings, various tomographic tactile sensors for soft grippers, tangible input
interfaces, flexible touch displays, and wearable electronics are demonstrated
by using a conductive porous media.
",2024-06-03 04:17:32+00:00,cs.HC
"Bringing active learning, experimentation, and student-created videos in
  engineering: A study about teaching electronics and physical computing
  integrating online and mobile learning","  Active Learning (AL) is a well-known teaching method in engineering because
it allows to foster learning and critical thinking of the students by employing
debate, hands-on activities, and experimentation. However, most educational
results of this instructional method have been achieved in face-to-face
educational settings and less has been said about how to promote AL and
experimentation for online engineering education. Then, the main aim of this
study was to create an AL methodology to learn electronics, physical computing
(PhyC), programming, and basic robotics in engineering through hands-on
activities and active experimentation in online environments. N=56 students of
two engineering programs (Technology in Electronics and Industrial Engineering)
participated in the methodology that was conceived using the guidelines of the
Integrated Course Design Model (ICDM) and in some courses combining mobile and
online learning with an Android app. The methodology gathered three main
components: (1) In-home laboratories performed through low-cost hardware
devices, (2) Student-created videos and blogs to evidence the development of
skills, and (3) Teacher support and feedback. Data in the courses were
collected through surveys, evaluation rubrics, semi-structured interviews, and
students grades and were analyzed through a mixed approach. The outcomes
indicate a good perception of the PhyC and programming activities by the
students and suggest that these influence motivation, self-efficacy, reduction
of anxiety, and improvement of academic performance in the courses. The
methodology and previous results can be useful for researchers and
practitioners interested in developing AL methodologies or strategies in
engineering with online, mobile, or blended learning modalities.
",2024-06-02 23:26:27+00:00,cs.CY
"Research on Image Processing and Vectorization Storage Based on Garage
  Electronic Maps","  For the purpose of achieving a more precise definition and data analysis of
images, this study conducted a research on vectorization and rasterization
storage of electronic maps, focusing on a large underground parking garage map.
During the research, image processing, vectorization and rasterization storage
were performed. The paper proposed a method for the vectorization
classification storage of indoor two-dimensional map raster data. This method
involves converting raster data into vector data and classifying elements such
as parking spaces, pathways, and obstacles based on their coordinate positions
with the grid indexing method, thereby facilitating efficient storage and rapid
querying of indoor maps. Additionally, interpolation algorithms were employed
to extract vector data and convert it into raster data. Navigation testing was
conducted to validate the accuracy and reliability of the map model under this
method, providing effective technical support for the digital storage and
navigation of garage maps.
",2024-06-02 07:23:46+00:00,cs.CV
"Chiplets on Wheels: Review Paper on Holistic Chiplet Solutions for
  Autonomous Vehicles","  On the advent of the slow death of Moore's law, the silicon industry is
moving towards a new era of chiplets. The automotive industry is experiencing a
profound transformation towards software-defined vehicles, fueled by the
surging demand for automotive compute chips, expected to reach 20-22 billion by
2030. High-performance compute (HPC) chips become instrumental in meeting the
soaring demand for computational power. Various strategies, including
centralized electrical and electronic architecture and the innovative Chiplet
Systems, are under exploration. The latter, breaking down System-on-Chips
(SoCs) into functional units, offers unparalleled customization and integration
possibilities. The research accentuates the crucial open Chiplet ecosystem,
fostering collaboration and enhancing supply chain resilience. In this paper,
we address the unique challenges that arise when attempting to leverage
chiplet-based architecture to design a holistic silicon solution for the
automotive industry. We propose a throughput-oriented micro-architecture for
ADAS and infotainment systems alongside a novel methodology to evaluate chiplet
architectures. Further, we develop in-house simulation tools leveraging the
gem5 framework to simulate latency and throughput. Finally, we perform an
extensive design of thermally-aware chiplet placement and develop a
micro-fluids-based cooling design.
",2024-05-31 20:18:35+00:00,cs.AR
"G-Transformer for Conditional Average Potential Outcome Estimation over
  Time","  Estimating potential outcomes for treatments over time based on observational
data is important for personalized decision-making in medicine. Yet, existing
neural methods for this task suffer from either (a) bias or (b) large variance.
In order to address both limitations, we introduce the G-transformer (GT). Our
GT is a novel, neural end-to-end model designed for unbiased, low-variance
estimation of conditional average potential outcomes (CAPOs) over time.
Specifically, our GT is the first neural model to perform regression-based
iterative G-computation for CAPOs in the time-varying setting. We evaluate the
effectiveness of our GT across various experiments. In sum, this work
represents a significant step towards personalized decision-making from
electronic health records.
",2024-05-31 16:52:51+00:00,cs.LG
Multistable Physical Neural Networks,"  Artificial neural networks (ANNs), which are inspired by the brain, are a
central pillar in the ongoing breakthrough in artificial intelligence. In
recent years, researchers have examined mechanical implementations of ANNs,
denoted as Physical Neural Networks (PNNs). PNNs offer the opportunity to view
common materials and physical phenomena as networks, and to associate
computational power with them. In this work, we incorporated mechanical
bistability into PNNs, enabling memory and a direct link between computation
and physical action. To achieve this, we consider an interconnected network of
bistable liquid-filled chambers. We first map all possible equilibrium
configurations or steady states, and then examine their stability. Building on
these maps, both global and local algorithms for training multistable PNNs are
implemented. These algorithms enable us to systematically examine the network's
capability to achieve stable output states and thus the network's ability to
perform computational tasks. By incorporating PNNs and multistability, we can
design structures that mechanically perform tasks typically associated with
electronic neural networks, while directly obtaining physical actuation. The
insights gained from our study pave the way for the implementation of
intelligent structures in smart tech, metamaterials, medical devices, soft
robotics, and other fields.
",2024-05-31 13:24:39+00:00,cs.NE
"GAMedX: Generative AI-based Medical Entity Data Extractor Using Large
  Language Models","  In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.
",2024-05-31 02:53:22+00:00,cs.CL
"Enhancing Antibiotic Stewardship using a Natural Language Approach for
  Better Feature Representation","  The rapid emergence of antibiotic-resistant bacteria is recognized as a
global healthcare crisis, undermining the efficacy of life-saving antibiotics.
This crisis is driven by the improper and overuse of antibiotics, which
escalates bacterial resistance. In response, this study explores the use of
clinical decision support systems, enhanced through the integration of
electronic health records (EHRs), to improve antibiotic stewardship. However,
EHR systems present numerous data-level challenges, complicating the effective
synthesis and utilization of data. In this work, we transform EHR data into a
serialized textual representation and employ pretrained foundation models to
demonstrate how this enhanced feature representation can aid in antibiotic
susceptibility predictions. Our results suggest that this text representation,
combined with foundation models, provides a valuable tool to increase
interpretability and support antibiotic stewardship efforts.
",2024-05-30 18:53:53+00:00,cs.LG
"Autonomous programmable microscopic electronic lablets optimized with
  digital control","  Lablets are autonomous microscopic particles with programmable CMOS
electronics that can control electrokinetic phenomena and electrochemical
reactions in solution via actuator and sensor microelectrodes. In this paper,
we describe the design and fabrication of optimized singulated lablets (CMOS3)
with dimensions 140x140x50 micrometers carrying an integrated coplanar
encapsulated supercapacitor as a rechargeable power supply. The lablets are
designed to allow docking to one another or to a smart surface for interchange
of energy, electronic information, and chemicals. The paper focusses on the
digital and analog design of the lablets to allow significant programmable
functionality in a microscopic footprint, including the control of autonomous
actuation and sensing up to the level of being able to support a complete
lablet self-reproduction life cycle, although experimentally this remains to be
proven. The potential of lablets in autonomous sensing and control and for
evolutionary experimentation are discussed.
",2024-05-30 14:47:34+00:00,cs.RO
Deep Reinforcement Learning for Intrusion Detection in IoT: A Survey,"  The rise of new complex attacks scenarios in Internet of things (IoT)
environments necessitate more advanced and intelligent cyber defense techniques
such as various Intrusion Detection Systems (IDSs) which are responsible for
detecting and mitigating malicious activities in IoT networks without human
intervention. To address this issue, deep reinforcement learning (DRL) has been
proposed in recent years, to automatically tackle intrusions/attacks. In this
paper, a comprehensive survey of DRL-based IDS on IoT is presented.
Furthermore, in this survey, the state-of-the-art DRL-based IDS methods have
been classified into five categories including wireless sensor network (WSN),
deep Q-network (DQN), healthcare, hybrid, and other techniques. In addition,
the most crucial performance metrics, namely accuracy, recall, precision, false
negative rate (FNR), false positive rate (FPR), and F-measure, are detailed, in
order to evaluate the performance of each proposed method. The paper provides a
summary of datasets utilized in the studies as well.
",2024-05-30 13:19:23+00:00,cs.CR
"Leveraging Open-Source Large Language Models for encoding Social
  Determinants of Health using an Intelligent Router","  Social Determinants of Health (SDOH) play a significant role in patient
health outcomes. The Center of Disease Control (CDC) introduced a subset of
ICD-10 codes called Z-codes in an attempt to officially recognize and measure
SDOH in the health care system. However, these codes are rarely annotated in a
patient's Electronic Health Record (EHR), and instead, in many cases, need to
be inferred from clinical notes. Previous research has shown that large
language models (LLMs) show promise on extracting unstructured data from EHRs.
However, with thousands of models to choose from with unique architectures and
training sets, it's difficult to choose one model that performs the best on
coding tasks. Further, clinical notes contain trusted health information making
the use of closed-source language models from commercial vendors difficult, so
the identification of open source LLMs that can be run within health
organizations and exhibits high performance on SDOH tasks is an urgent problem.
Here, we introduce an intelligent routing system for SDOH coding that uses a
language model router to direct medical record data to open source LLMs that
demonstrate optimal performance on specific SDOH codes. The intelligent routing
system exhibits state of the art performance of 97.4% accuracy averaged across
5 codes, including homelessness and food insecurity, on par with closed models
such as GPT-4o. In order to train the routing system and validate models, we
also introduce a synthetic data generation and validation paradigm to increase
the scale of training data without needing privacy protected medical records.
Together, we demonstrate an architecture for intelligent routing of inputs to
task-optimal language models to achieve high performance across a set of
medical coding sub-tasks.
",2024-05-30 02:33:28+00:00,cs.AI
"Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in
  eDiscovery","  Electronic Discovery (eDiscovery) involves identifying relevant documents
from a vast collection based on legal production requests. The integration of
artificial intelligence (AI) and natural language processing (NLP) has
transformed this process, helping document review and enhance efficiency and
cost-effectiveness. Although traditional approaches like BM25 or fine-tuned
pre-trained models are common in eDiscovery, they face performance,
computational, and interpretability challenges. In contrast, Large Language
Model (LLM)-based methods prioritize interpretability but sacrifice performance
and throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid
approach that combines the strengths of two worlds: a heterogeneous graph-based
method for accurate document relevance prediction and subsequent LLM-driven
approach for reasoning. Graph representational learning generates embeddings
and predicts links, ranking the corpus for a given request, and the LLMs
provide reasoning for document relevance. Our approach handles datasets with
balanced and imbalanced distributions, outperforming baselines in F1-score,
precision, and recall by an average of 12%, 3%, and 16%, respectively. In an
enterprise context, our approach drastically reduces document review costs by
99.9% compared to manual processes and by 95% compared to LLM-based
classification methods
",2024-05-29 15:08:55+00:00,cs.AI
"Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding
  Recommendation","  The International Classification of Diseases (ICD) serves as a definitive
medical classification system encompassing a wide range of diseases and
conditions. The primary objective of ICD indexing is to allocate a subset of
ICD codes to a medical record, which facilitates standardized documentation and
management of various health conditions. Most existing approaches have suffered
from selecting the proper label subsets from an extremely large ICD collection
with a heavy long-tailed label distribution. In this paper, we leverage a
multi-stage ``retrieve and re-rank'' framework as a novel solution to ICD
indexing, via a hybrid discrete retrieval method, and re-rank retrieved
candidates with contrastive learning that allows the model to make more
accurate predictions from a simplified label space. The retrieval model is a
hybrid of auxiliary knowledge of the electronic health records (EHR) and a
discrete retrieval method (BM25), which efficiently collects high-quality
candidates. In the last stage, we propose a label co-occurrence guided
contrastive re-ranking model, which re-ranks the candidate labels by pulling
together the clinical notes with positive ICD codes. Experimental results show
the proposed method achieves state-of-the-art performance on a number of
measures on the MIMIC-III benchmark.
",2024-05-29 13:54:30+00:00,cs.CL
"Visual Servoing Based on 3D Features: Design and Implementation for
  Robotic Insertion Tasks","  This paper proposes a feature-based Visual Servoing (VS) method for insertion
task skills. A camera mounted on the robot's end-effector provides the pose
relative to a cylinder (hole), allowing a contact-free and damage-free search
of the hole and avoiding uncertainties emerging when the pose is computed via
robot kinematics. Two points located on the hole's principal axis and three
mutually orthogonal planes defining the flange's reference frame are associated
with the pose of the hole and the flange, respectively. The proposed VS drives
to zero the distance between the two points and the three planes aligning the
robot's flange with the hole's direction. Compared with conventional VS where
the Jacobian is difficult to compute in practice, the proposed featured-based
uses a Jacobian easily calculated from the measured hole pose. Furthermore, the
feature-based VS design considers the robot's maximum cartesian velocity. The
VS method is implemented in an industrial robot and the experimental results
support its usefulness.
",2024-05-29 07:19:44+00:00,cs.RO
MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction,"  Objective. Active adverse event surveillance monitors Adverse Drug Events
(ADE) from different data sources, such as electronic health records, medical
literature, social media and search engine logs. Over years, many datasets are
created, and shared tasks are organised to facilitate active adverse event
surveillance. However, most-if not all-datasets or shared tasks focus on
extracting ADEs from a particular type of text. Domain generalisation-the
ability of a machine learning model to perform well on new, unseen domains
(text types)-is under-explored. Given the rapid advancements in natural
language processing, one unanswered question is how far we are from having a
single ADE extraction model that are effective on various types of text, such
as scientific literature and social media posts}. Methods. We contribute to
answering this question by building a multi-domain benchmark for adverse drug
event extraction, which we named MultiADE. The new benchmark comprises several
existing datasets sampled from different text types and our newly created
dataset-CADECv2, which is an extension of CADEC (Karimi, et al., 2015),
covering online posts regarding more diverse drugs than CADEC. Our new dataset
is carefully annotated by human annotators following detailed annotation
guidelines. Conclusion. Our benchmark results show that the generalisation of
the trained models is far from perfect, making it infeasible to be deployed to
process different types of text. In addition, although intermediate transfer
learning is a promising approach to utilising existing resources, further
investigation is needed on methods of domain adaptation, particularly
cost-effective methods to select useful training instances.
",2024-05-28 09:57:28+00:00,cs.CL
EMERGE: Integrating RAG for Improved Multimodal EHR Predictive Modeling,"  The integration of multimodal Electronic Health Records (EHR) data has
notably advanced clinical predictive capabilities. However, current models that
utilize clinical notes and multivariate time-series EHR data often lack the
necessary medical context for precise clinical tasks. Previous methods using
knowledge graphs (KGs) primarily focus on structured knowledge extraction. To
address this, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven
framework aimed at enhancing multimodal EHR predictive modeling. Our approach
extracts entities from both time-series data and clinical notes by prompting
Large Language Models (LLMs) and aligns them with professional PrimeKG to
ensure consistency. Beyond triplet relationships, we include entities'
definitions and descriptions to provide richer semantics. The extracted
knowledge is then used to generate task-relevant summaries of patients' health
statuses. These summaries are fused with other modalities utilizing an adaptive
multimodal fusion network with cross-attention. Extensive experiments on the
MIMIC-III and MIMIC-IV datasets for in-hospital mortality and 30-day
readmission tasks demonstrate the superior performance of the EMERGE framework
compared to baseline models. Comprehensive ablation studies and analyses
underscore the efficacy of each designed module and the framework's robustness
to data sparsity. EMERGE significantly enhances the use of multimodal EHR data
in healthcare, bridging the gap with nuanced medical contexts crucial for
informed clinical predictions.
",2024-05-27 10:53:15+00:00,cs.CL
"TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture
  Token Prediction","  Autoregressive next-token prediction is a standard pretraining method for
large-scale language models, but its application to vision tasks is hindered by
the non-sequential nature of image data, leading to cumulative errors. Most
vision models employ masked autoencoder (MAE) based pretraining, which faces
scalability issues. To address these challenges, we introduce
\textbf{TokenUnify}, a novel pretraining method that integrates random token
prediction, next-token prediction, and next-all token prediction. We provide
theoretical evidence demonstrating that TokenUnify mitigates cumulative errors
in visual autoregression. Cooperated with TokenUnify, we have assembled a
large-scale electron microscopy (EM) image dataset with ultra-high resolution,
ideal for creating spatially correlated long sequences. This dataset includes
over 120 million annotated voxels, making it the largest neuron segmentation
dataset to date and providing a unified benchmark for experimental validation.
Leveraging the Mamba network inherently suited for long-sequence modeling on
this dataset, TokenUnify not only reduces the computational complexity but also
leads to a significant 45\% improvement in segmentation performance on
downstream EM neuron segmentation tasks compared to existing methods.
Furthermore, TokenUnify demonstrates superior scalability over MAE and
traditional autoregressive methods, effectively bridging the gap between
pretraining strategies for language and vision models. Code is available at
\url{https://github.com/ydchen0806/TokenUnify}.
",2024-05-27 05:45:51+00:00,cs.CV
"Scalable Numerical Embeddings for Multivariate Time Series: Enhancing
  Healthcare Data Representation Learning","  Multivariate time series (MTS) data, when sampled irregularly and
asynchronously, often present extensive missing values. Conventional
methodologies for MTS analysis tend to rely on temporal embeddings based on
timestamps that necessitate subsequent imputations, yet these imputed values
frequently deviate substantially from their actual counterparts, thereby
compromising prediction accuracy. Furthermore, these methods typically fail to
provide robust initial embeddings for values infrequently observed or even
absent within the training set, posing significant challenges to model
generalizability. In response to these challenges, we propose SCAlable
Numerical Embedding (SCANE), a novel framework that treats each feature value
as an independent token, effectively bypassing the need for imputation. SCANE
regularizes the traits of distinct feature embeddings and enhances
representational learning through a scalable embedding mechanism. Coupling
SCANE with the Transformer Encoder architecture, we develop the Scalable
nUMerical eMbeddIng Transformer (SUMMIT), which is engineered to deliver
precise predictive outputs for MTS characterized by prevalent missing entries.
Our experimental validation, conducted across three disparate electronic health
record (EHR) datasets marked by elevated missing value frequencies, confirms
the superior performance of SUMMIT over contemporary state-of-the-art
approaches addressing similar challenges. These results substantiate the
efficacy of SCANE and SUMMIT, underscoring their potential applicability across
a broad spectrum of MTS data analytical tasks.
",2024-05-26 13:06:45+00:00,cs.LG
"Augmented Risk Prediction for the Onset of Alzheimer's Disease from
  Electronic Health Records with Large Language Models","  Alzheimer's disease (AD) is the fifth-leading cause of death among Americans
aged 65 and older. Screening and early detection of AD and related dementias
(ADRD) are critical for timely intervention and for identifying clinical trial
participants. The widespread adoption of electronic health records (EHRs)
offers an important resource for developing ADRD screening tools such as
machine learning based predictive models. Recent advancements in large language
models (LLMs) demonstrate their unprecedented capability of encoding knowledge
and performing reasoning, which offers them strong potential for enhancing risk
prediction. This paper proposes a novel pipeline that augments risk prediction
by leveraging the few-shot inference power of LLMs to make predictions on cases
where traditional supervised learning methods (SLs) may not excel.
Specifically, we develop a collaborative pipeline that combines SLs and LLMs
via a confidence-driven decision-making mechanism, leveraging the strengths of
SLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this
pipeline using a real-world EHR data warehouse from Oregon Health \& Science
University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients
and more than 20 million patient encounters. Our results show that our proposed
approach effectively combines the power of SLs and LLMs, offering significant
improvements in predictive performance. This advancement holds promise for
revolutionizing ADRD screening and early detection practices, with potential
implications for better strategies of patient management and thus improving
healthcare.
",2024-05-26 03:05:10+00:00,cs.AI
"Risk Factor Identification In Osteoporosis Using Unsupervised Machine
  Learning Techniques","  In this study, the reliability of identified risk factors associated with
osteoporosis is investigated using a new clustering-based method on electronic
medical records. This study proposes utilizing a new CLustering Iterations
Framework (CLIF) that includes an iterative clustering framework that can adapt
any of the following three components: clustering, feature selection, and
principal feature identification. The study proposes using Wasserstein distance
to identify principal features, borrowing concepts from the optimal transport
theory. The study also suggests using a combination of ANOVA and ablation tests
to select influential features from a data set. Some risk factors presented in
existing works are endorsed by our identified significant clusters, while the
reliability of some other risk factors is weakened.
",2024-05-24 18:53:28+00:00,cs.LG
"Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus
  Creation and Model Development","  The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,
enhancing patient safety by identifying potential risks associated with
medications, facilitating early detection of adverse events, and guiding
regulatory decision-making. Traditional ADE detection methods are reliable but
slow, not easily adaptable to large-scale operations, and offer limited
information. With the exponential increase in data sources like social media
content, biomedical literature, and Electronic Medical Records (EMR),
extracting relevant ADE-related information from these unstructured texts is
imperative. Previous ADE mining studies have focused on text-based
methodologies, overlooking visual cues, limiting contextual comprehension, and
hindering accurate interpretation. To address this gap, we present a MultiModal
Adverse Drug Event (MMADE) detection dataset, merging ADE-related textual
information with visual aids. Additionally, we introduce a framework that
leverages the capabilities of LLMs and VLMs for ADE detection by generating
detailed descriptions of medical images depicting ADEs, aiding healthcare
professionals in visually identifying adverse events. Using our MMADE dataset,
we showcase the significance of integrating visual cues from images to enhance
overall performance. This approach holds promise for patient safety, ADE
awareness, and healthcare accessibility, paving the way for further exploration
in personalized healthcare.
",2024-05-24 17:58:42+00:00,cs.AI
"ChiBench: a Benchmark Suite for Testing Electronic Design Automation
  Tools","  Electronic Design Automation (EDA) tools are software applications used by
engineers in the design, development, simulation, and verification of
electronic systems and integrated circuits. These tools typically process
specifications written in a Hardware Description Language (HDL), such as
Verilog, SystemVerilog or VHDL. Thus, effective testing of these tools requires
benchmark suites written in these languages. However, while there exist some
open benchmark suites for these languages, they tend to consist of only a
handful of specifications. This paper, in contrast, presents ChiBench, a
comprehensive suite comprising 50 thousand Verilog programs. These programs
were sourced from GitHub repositories and curated using Verible's syntactic
analyzer and Jasper(TM)'s HDL semantic analyzer. Since its inception, ChiBench
has already revealed bugs in public tools like Verible's obfuscator and parser.
In addition to explaining some of these case studies, this paper demonstrates
how ChiBench can be used to evaluate the asymptotic complexity and code
coverage of typical electronic design automation tools.
",2024-05-24 17:45:09+00:00,cs.AR
"Design and fabrication of autonomous electronic lablets for chemical
  control","  Lablets are autonomous microscopic particles with programmable CMOS
electronics that canvcontrol electrokinetic phenomena and electrochemical
reactions in solution via actuator and sensor microelectrodes. The lablets are
designed to be rechargeable using an integrated supercapacitor, and to allow
docking to one another or to a smart surface for interchange of energy,
electronic information and chemicals. In this paper, we describe the design and
fabrication of singulated lablets (CMOS2) at the scale of 100 by 200 {\mu}m,
with the supercap adjacent to the functional lablet and occupying half the
space. In other works, we have characterized the supercap and described the
electronic design and proven functionality using arrays of these lablets. Here
we present fabrication details for integrating functional coatings and the
supercap and demonstrate electronic functionality of the lablets following
singulation.
",2024-05-24 14:47:59+00:00,cs.RO
"Heterogeneous virus classification using a functional deep learning
  model based on transmission electron microscopy images (Preprint)","  Viruses are submicroscopic agents that can infect all kinds of lifeforms and
use their hosts' living cells to replicate themselves. Despite having some of
the simplest genetic structures among all living beings, viruses are highly
adaptable, resilient, and given the right conditions, are capable of causing
unforeseen complications in their hosts' bodies. Due to their multiple
transmission pathways, high contagion rate, and lethality, viruses are the
biggest biological threat faced by animal and plant species. It is often
challenging to promptly detect the presence of a virus in a possible host's
body and accurately determine its type using manual examination techniques;
however, it can be done using computer-based automatic diagnosis methods. Most
notably, the analysis of Transmission Electron Microscopy (TEM) images has been
proven to be quite successful in instant virus identification. Using TEM images
collected from a recently published dataset, this article proposes a deep
learning-based classification model to identify the type of virus within those
images correctly. The methodology of this study includes two coherent image
processing techniques to reduce the noise present in the raw microscopy images.
Experimental results show that it can differentiate among the 14 types of
viruses present in the dataset with a maximum of 97.44% classification accuracy
and F1-score, which asserts the effectiveness and reliability of the proposed
method. Implementing this scheme will impart a fast and dependable way of virus
identification subsidiary to the thorough diagnostic procedures.
",2024-05-24 13:52:14+00:00,cs.CV
"CowScreeningDB: A public benchmark dataset for lameness detection in
  dairy cows","  Lameness is one of the costliest pathological problems affecting dairy
animals. It is usually assessed by trained veterinary clinicians who observe
features such as gait symmetry or gait parameters as step counts in real-time.
With the development of artificial intelligence, various modular systems have
been proposed to minimize subjectivity in lameness assessment. However, the
major limitation in their development is the unavailability of a public dataset
which is currently either commercial or privately held. To tackle this
limitation, we have introduced CowScreeningDB which was created using sensory
data. This dataset was sourced from 43 cows at a dairy located in Gran Canaria,
Spain. It consists of a multi-sensor dataset built on data collected using an
Apple Watch 6 during the normal daily routine of a dairy cow. Thanks to the
collection environment, sampling technique, information regarding the sensors,
the applications used for data conversion and storage make the dataset a
transparent one. This transparency of data can thus be used for further
development of techniques for lameness detection for dairy cows which can be
objectively compared. Aside from the public sharing of the dataset, we have
also shared a machine-learning technique which classifies the caws in healthy
and lame by using the raw sensory data. Hence validating the major objective
which is to establish the relationship between sensor data and lameness.
",2024-05-24 13:36:00+00:00,cs.CV
Resilience-by-Design Concepts for 6G Communication Networks,"  The sixth generation (6G) mobile communication networks are expected to
intelligently integrate into various aspects of modern digital society,
including smart cities, homes, healthcare, transportation, and factories. While
offering a multitude of services, it is likely that societies become
increasingly reliant on 6G infrastructure. Any disruption to these digital
services, whether due to human or technical failures, natural disasters, or
terrorism, would significantly impact citizens' daily lives. Hence, 6G networks
need not only to provide high-performance services but also to be resilient in
maintaining essential services in the face of potentially unknown challenges.
This paper introduces a comprehensive concept for designing resilient 6G
communication networks, summarizing our initial studies within the German
Open6GHub project. Adopting an interdisciplinary approach, we propose to embed
physical and cyber resilience across all communication system layers,
addressing electronics, physical channel, network components and functions,
networks, services, and cross-layer and cross-infrastructure considerations.
After reviewing the background on resilience concepts, definitions, and
approaches, we introduce the proposed resilience-by-design (RBD) concept for 6G
communication networks. We further elaborate on the proposed RBD concept along
with selected 6G use-cases and present various open problems for future
research on 6G resilience.
",2024-05-24 10:24:49+00:00,cs.NI
Neural Pfaffians: Solving Many Many-Electron Schrödinger Equations,"  Neural wave functions accomplished unprecedented accuracies in approximating
the ground state of many-electron systems, though at a high computational cost.
Recent works proposed amortizing the cost by learning generalized wave
functions across different structures and compounds instead of solving each
problem independently. Enforcing the permutation antisymmetry of electrons in
such generalized neural wave functions remained challenging as existing methods
require discrete orbital selection via non-learnable hand-crafted algorithms.
This work tackles the problem by defining overparametrized, fully learnable
neural wave functions suitable for generalization across molecules. We achieve
this by relying on Pfaffians rather than Slater determinants. The Pfaffian
allows us to enforce the antisymmetry on arbitrary electronic systems without
any constraint on electronic spin configurations or molecular structure. Our
empirical evaluation finds that a single neural Pfaffian calculates the ground
state and ionization energies with chemical accuracy across various systems. On
the TinyMol dataset, we outperform the `gold-standard' CCSD(T) CBS reference
energies by 1.9m$E_h$ and reduce energy errors compared to previous generalized
neural wave functions by up to an order of magnitude.
",2024-05-23 16:30:51+00:00,cs.LG
"EHRMamba: Towards Generalizable and Scalable Foundation Models for
  Electronic Health Records","  Transformers have significantly advanced the modeling of Electronic Health
Records (EHR), yet their deployment in real-world healthcare is limited by
several key challenges. Firstly, the quadratic computational cost and
insufficient context length of these models pose significant obstacles for
hospitals in processing the extensive medical histories typical in EHR data.
Additionally, existing models employ separate finetuning for each clinical
task, complicating maintenance in healthcare environments. Moreover, these
models focus exclusively on either clinical prediction or EHR forecasting,
lacking the flexibility to perform well across both. To overcome these
limitations, we introduce EHRMamba, a robust foundation model built on the
Mamba architecture. EHRMamba can process sequences up to four times longer than
previous models due to its linear computational cost. We also introduce a novel
approach to Multitask Prompted Finetuning (MTF) for EHR data, which enables
EHRMamba to simultaneously learn multiple clinical tasks in a single finetuning
phase, significantly enhancing deployment and cross-task generalization.
Furthermore, our model leverages the HL7 FHIR data standard to simplify
integration into existing hospital systems. Alongside EHRMamba, we open-source
Odyssey, a toolkit designed to support the development and deployment of EHR
foundation models, with an emphasis on data standardization and
interpretability. Our evaluations on the MIMIC-IV dataset demonstrate that
EHRMamba advances state-of-the-art performance across 6 major clinical tasks
and excels in EHR forecasting, marking a significant leap forward in the field.
",2024-05-23 13:43:29+00:00,cs.LG
"EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively
  Exploring Electronic Health Records","  In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL
dataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to
address critical yet underexplored aspects in text-to-SQL parsing:
interactivity, compositionality, and efficiency. To the best of our knowledge,
EHR-SeqSQL is not only the largest but also the first medical text-to-SQL
dataset benchmark to include sequential and contextual questions. We provide a
data split and the new test set designed to assess compositional generalization
ability. Our experiments demonstrate the superiority of a multi-turn approach
over a single-turn approach in learning compositionality. Additionally, our
dataset integrates specially crafted tokens into SQL queries to improve
execution efficiency. With EHR-SeqSQL, we aim to bridge the gap between
practical needs and academic research in the text-to-SQL domain. EHR-SeqSQL is
available at https://github.com/seonhee99/EHR-SeqSQL.
",2024-05-23 07:14:21+00:00,cs.CL
"From the evolution of public data ecosystems to the evolving horizons of
  the forward-looking intelligent public data ecosystem empowered by emerging
  technologies","  Public data ecosystems (PDEs) represent complex socio-technical systems
crucial for optimizing data use in the public sector and outside it.
Recognizing their multifaceted nature, previous research pro-posed a
six-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed
as a result of a systematic literature review on the topic spanning three
decade, this model, while theoretically robust, necessitates empirical
validation to enhance its practical applicability. This study addresses this
gap by validating the theoretical model through a real-life examination in five
European countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This
empirical validation provides insights into PDEs dynamics and variations of
implementations across contexts, particularly focusing on the 6th generation of
forward-looking PDE generation named ""Intelligent Public Data Generation"" that
represents a paradigm shift driven by emerging technologies such as cloud
computing, Artificial Intelligence, Natural Language Processing tools,
Generative AI, and Large Language Models (LLM) with potential to contribute to
both automation and augmentation of business processes within these ecosystems.
By transcending their traditional status as a mere component, evolving into
both an actor and a stakeholder simultaneously, these technologies catalyze
innovation and progress, enhancing PDE management strategies to align with
societal, regulatory, and technical imperatives in the digital era.
",2024-05-22 12:58:02+00:00,cs.CY
"Optimizing Search Advertising Strategies: Integrating Reinforcement
  Learning with Generalized Second-Price Auctions for Enhanced Ad Ranking and
  Bidding","  This paper explores the integration of strategic optimization methods in
search advertising, focusing on ad ranking and bidding mechanisms within
E-commerce platforms. By employing a combination of reinforcement learning and
evolutionary strategies, we propose a dynamic model that adjusts to varying
user interactions and optimizes the balance between advertiser cost, user
relevance, and platform revenue. Our results suggest significant improvements
in ad placement accuracy and cost efficiency, demonstrating the model's
applicability in real-world scenarios.
",2024-05-22 06:30:55+00:00,cs.LG
"Cyberbullying Detection: Exploring Datasets, Technologies, and
  Approaches on Social Media Platforms","  Cyberbullying has been a significant challenge in the digital era world,
given the huge number of people, especially adolescents, who use social media
platforms to communicate and share information. Some individuals exploit these
platforms to embarrass others through direct messages, electronic mail, speech,
and public posts. This behavior has direct psychological and physical impacts
on victims of bullying. While several studies have been conducted in this field
and various solutions proposed to detect, prevent, and monitor cyberbullying
instances on social media platforms, the problem continues. Therefore, it is
necessary to conduct intensive studies and provide effective solutions to
address the situation. These solutions should be based on detection,
prevention, and prediction criteria methods. This paper presents a
comprehensive systematic review of studies conducted on cyberbullying
detection. It explores existing studies, proposed solutions, identified gaps,
datasets, technologies, approaches, challenges, and recommendations, and then
proposes effective solutions to address research gaps in future studies.
",2024-05-22 04:58:20+00:00,cs.CY
"KU-DMIS at EHRSQL 2024:Generating SQL query via question templatization
  in EHR","  Transforming natural language questions into SQL queries is crucial for
precise data retrieval from electronic health record (EHR) databases. A
significant challenge in this process is detecting and rejecting unanswerable
questions that request information beyond the database's scope or exceed the
system's capabilities. In this paper, we introduce a novel text-to-SQL
framework that robustly handles out-of-domain questions and verifies the
generated queries with query execution.Our framework begins by standardizing
the structure of questions into a templated format. We use a powerful large
language model (LLM), fine-tuned GPT-3.5 with detailed prompts involving the
table schemas of the EHR database system. Our experimental results demonstrate
the effectiveness of our framework on the EHRSQL-2024 benchmark benchmark, a
shared task in the ClinicalNLP workshop. Although a straightforward fine-tuning
of GPT shows promising results on the development set, it struggled with the
out-of-domain questions in the test set. With our framework, we improve our
system's adaptability and achieve competitive performances in the official
leaderboard of the EHRSQL-2024 challenge.
",2024-05-22 02:15:57+00:00,cs.DB
Performance Comparison of Various Modes of Advanced Encryption Standard,"  With the maturation of quantum computing technology, many cryptographic
methods are gradually facing threats from quantum computing. Although the
Grover algorithm can accelerate search speeds, current research indicates that
the Advanced Encryption Standard (AES) method can still enhance security by
increasing the length of the secret key. However, the AES method involves
multiple modes in implementation, and not all modes are secure. Therefore, this
study proposes a normalized Gini impurity (NGI) to verify the security of each
mode, using encrypted images as a case study for empirical analysis.
Furthermore, this study primarily compares the Electronic Codebook (ECB) mode,
Cipher Block Chaining (CBC) mode, Counter (CTR) mode, Counter with CBC-Message
Authentication Code (MAC) (CCM) mode, and Galois Counter Mode (GCM).
",2024-05-22 01:09:49+00:00,cs.CR
Robust portfolio optimization model for electronic coupon allocation,"  Currently, many e-commerce websites issue online/electronic coupons as an
effective tool for promoting sales of various products and services. We focus
on the problem of optimally allocating coupons to customers subject to a budget
constraint on an e-commerce website. We apply a robust portfolio optimization
model based on customer segmentation to the coupon allocation problem. We also
validate the efficacy of our method through numerical experiments using actual
data from randomly distributed coupons. Main contributions of our research are
twofold. First, we handle six types of coupons, thereby making it extremely
difficult to accurately estimate the difference in the effects of various
coupons. Second, we demonstrate from detailed numerical results that the robust
optimization model achieved larger uplifts of sales than did the commonly-used
multiple-choice knapsack model and the conventional mean-variance optimization
model. Our results open up great potential for robust portfolio optimization as
an effective tool for practical coupon allocation.
",2024-05-21 15:30:25+00:00,cs.IR
"Continuous Predictive Modeling of Clinical Notes and ICD Codes in
  Patient Health Records","  Electronic Health Records (EHR) serve as a valuable source of patient
information, offering insights into medical histories, treatments, and
outcomes. Previous research has developed systems for detecting applicable ICD
codes that should be assigned while writing a given EHR document, mainly
focusing on discharge summaries written at the end of a hospital stay. In this
work, we investigate the potential of predicting these codes for the whole
patient stay at different time points during their stay, even before they are
officially assigned by clinicians. The development of methods to predict
diagnoses and treatments earlier in advance could open opportunities for
predictive medicine, such as identifying disease risks sooner, suggesting
treatments, and optimizing resource allocation. Our experiments show that
predictions regarding final ICD codes can be made already two days after
admission and we propose a custom model that improves performance on this early
prediction task.
",2024-05-19 17:23:04+00:00,cs.CL
"WisPerMed at ""Discharge Me!"": Advancing Text Generation in Healthcare
  with Large Language Models, Dynamic Expert Selection, and Priming Techniques
  on MIMIC-IV","  This study aims to leverage state of the art language models to automate
generating the ""Brief Hospital Course"" and ""Discharge Instructions"" sections of
Discharge Summaries from the MIMIC-IV dataset, reducing clinicians'
administrative workload. We investigate how automation can improve
documentation accuracy, alleviate clinician burnout, and enhance operational
efficacy in healthcare facilities. This research was conducted within our
participation in the Shared Task Discharge Me! at BioNLP @ ACL 2024. Various
strategies were employed, including few-shot learning, instruction tuning, and
Dynamic Expert Selection (DES), to develop models capable of generating the
required text sections. Notably, utilizing an additional clinical
domain-specific dataset demonstrated substantial potential to enhance clinical
language processing. The DES method, which optimizes the selection of text
outputs from multiple predictions, proved to be especially effective. It
achieved the highest overall score of 0.332 in the competition, surpassing
single-model outputs. This finding suggests that advanced deep learning methods
in combination with DES can effectively automate parts of electronic health
record documentation. These advancements could enhance patient care by freeing
clinician time for patient interactions. The integration of text selection
strategies represents a promising avenue for further research.
",2024-05-18 10:56:45+00:00,cs.CL
"LG AI Research & KAIST at EHRSQL 2024: Self-Training Large Language
  Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL
  System on EHRs","  Text-to-SQL models are pivotal for making Electronic Health Records (EHRs)
accessible to healthcare professionals without SQL knowledge. With the
advancements in large language models, these systems have become more adept at
translating complex questions into SQL queries. Nonetheless, the critical need
for reliability in healthcare necessitates these models to accurately identify
unanswerable questions or uncertain predictions, preventing misinformation. To
address this problem, we present a self-training strategy using pseudo-labeled
unanswerable questions to enhance the reliability of text-to-SQL models for
EHRs. This approach includes a two-stage training process followed by a
filtering method based on the token entropy and query execution. Our
methodology's effectiveness is validated by our top performance in the EHRSQL
2024 shared task, showcasing the potential to improve healthcare
decision-making through more reliable text-to-SQL systems.
",2024-05-18 03:25:44+00:00,cs.CL
"Air Signing and Privacy-Preserving Signature Verification for Digital
  Documents","  This paper presents a novel approach to the digital signing of electronic
documents through the use of a camera-based interaction system, single-finger
tracking for sign recognition, and multi commands executing hand gestures. The
proposed solution, referred to as ""Air Signature,"" involves writing the
signature in front of the camera, rather than relying on traditional methods
such as mouse drawing or physically signing on paper and showing it to a web
camera. The goal is to develop a state-of-the-art method for detecting and
tracking gestures and objects in real-time. The proposed methods include
applying existing gesture recognition and object tracking systems, improving
accuracy through smoothing and line drawing, and maintaining continuity during
fast finger movements. An evaluation of the fingertip detection, sketching, and
overall signing process is performed to assess the effectiveness of the
proposed solution. The secondary objective of this research is to develop a
model that can effectively recognize the unique signature of a user. This type
of signature can be verified by neural cores that analyze the movement, speed,
and stroke pixels of the signing in real time. The neural cores use machine
learning algorithms to match air signatures to the individual's stored
signatures, providing a secure and efficient method of verification. Our
proposed System does not require sensors or any hardware other than the camera.
",2024-05-17 16:00:10+00:00,cs.CV
"Dual-band feature selection for maturity classification of specialty
  crops by hyperspectral imaging","  The maturity classification of specialty crops such as strawberries and
tomatoes is an essential agricultural downstream activity for selective
harvesting and quality control (QC) at production and packaging sites. Recent
advancements in Deep Learning (DL) have produced encouraging results in color
images for maturity classification applications. However, hyperspectral imaging
(HSI) outperforms methods based on color vision. Multivariate analysis methods
and Convolutional Neural Networks (CNN) deliver promising results; however, a
large amount of input data and the associated preprocessing requirements cause
hindrances in practical application. Conventionally, the reflectance intensity
in a given electromagnetic spectrum is employed in estimating fruit maturity.
We present a feature extraction method to empirically demonstrate that the peak
reflectance in subbands such as 500-670 nm (pigment band) and the wavelength of
the peak position, and contrarily, the trough reflectance and its corresponding
wavelength within 671-790 nm (chlorophyll band) are convenient to compute yet
distinctive features for the maturity classification. The proposed feature
selection method is beneficial because preprocessing, such as dimensionality
reduction, is avoided before every prediction. The feature set is designed to
capture these traits. The best SOTA methods, among 3D-CNN, 1D-CNN, and SVM,
achieve at most 90.0 % accuracy for strawberries and 92.0 % for tomatoes on our
dataset. Results show that the proposed method outperforms the SOTA as it
yields an accuracy above 98.0 % in strawberry and 96.0 % in tomato
classification. A comparative analysis of the time efficiency of these methods
is also conducted, which shows the proposed method performs prediction at 13
Frames Per Second (FPS) compared to the maximum 1.16 FPS attained by the
full-spectrum SVM classifier.
",2024-05-16 10:01:16+00:00,cs.CV
"AD-Aligning: Emulating Human-like Generalization for Cognitive Domain
  Adaptation in Deep Learning","  Domain adaptation is pivotal for enabling deep learning models to generalize
across diverse domains, a task complicated by variations in presentation and
cognitive nuances. In this paper, we introduce AD-Aligning, a novel approach
that combines adversarial training with source-target domain alignment to
enhance generalization capabilities. By pretraining with Coral loss and
standard loss, AD-Aligning aligns target domain statistics with those of the
pretrained encoder, preserving robustness while accommodating domain shifts.
Through extensive experiments on diverse datasets and domain shift scenarios,
including noise-induced shifts and cognitive domain adaptation tasks, we
demonstrate AD-Aligning's superior performance compared to existing methods
such as Deep Coral and ADDA. Our findings highlight AD-Aligning's ability to
emulate the nuanced cognitive processes inherent in human perception, making it
a promising solution for real-world applications requiring adaptable and robust
domain adaptation strategies.
",2024-05-15 02:34:06+00:00,cs.CV
"SMART: Towards Pre-trained Missing-Aware Model for Patient Health Status
  Prediction","  Electronic health record (EHR) data has emerged as a valuable resource for
analyzing patient health status. However, the prevalence of missing data in EHR
poses significant challenges to existing methods, leading to spurious
correlations and suboptimal predictions. While various imputation techniques
have been developed to address this issue, they often obsess unnecessary
details and may introduce additional noise when making clinical predictions. To
tackle this problem, we propose SMART, a Self-Supervised Missing-Aware
RepresenTation Learning approach for patient health status prediction, which
encodes missing information via elaborated attentions and learns to impute
missing values through a novel self-supervised pre-training approach that
reconstructs missing data representations in the latent space. By adopting
missing-aware attentions and focusing on learning higher-order representations,
SMART promotes better generalization and robustness to missing data. We
validate the effectiveness of SMART through extensive experiments on six EHR
tasks, demonstrating its superiority over state-of-the-art methods.
",2024-05-15 02:19:34+00:00,cs.LG
"Realtime Global Optimization of a Fail-Safe Emergency Stop Maneuver for
  Arbitrary Electrical / Electronical Failures in Automated Driving","  In the event of a critical system failures in auto-mated vehicles,
fail-operational or fail-safe measures provide minimum guarantees for the
vehicle's performance, depending on which of its subsystems remain operational.
Various such methods have been proposed which, upon failure, use different
remaining sets of operational subsystems to execute maneuvers that bring the
vehicle into a safe state under different environmental conditions. One
particular such method proposes a fail-safe emergency stop system that requires
no particular electric or electronic subsystem to be available after failure,
and still provides a basic situation-dependent emergency stop maneuver. This is
achieved by preemptively setting parameters to a hydraulic / mechanical system
prior to failure, which after failure executes the preset maneuver ""blindly"".
The focus of this paper is the particular challenge of implementing a
lightweight planning algorithm that can cope with the complex uncertainties of
the given task while still providing a globally optimal solution at regular
intervals, based on the perceived and predicted environment of the automated
vehicle.
",2024-05-14 07:55:34+00:00,cs.RO
"PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation
  using Ensemble LLMs","  This paper presents our approach to the EHRSQL-2024 shared task, which aims
to develop a reliable Text-to-SQL system for electronic health records. We
propose two approaches that leverage large language models (LLMs) for prompting
and fine-tuning to generate EHRSQL queries. In both techniques, we concentrate
on bridging the gap between the real-world knowledge on which LLMs are trained
and the domain specific knowledge required for the task. The paper provides the
results of each approach individually, demonstrating that they achieve high
execution accuracy. Additionally, we show that an ensemble approach further
enhances generation reliability by reducing errors. This approach secured us
2nd place in the shared task competition. The methodologies outlined in this
paper are designed to be transferable to domain-specific Text-to-SQL problems
that emphasize both accuracy and reliability.
",2024-05-14 07:16:56+00:00,cs.DB
"LLMs and the Future of Chip Design: Unveiling Security Risks and
  Building Trust","  Chip design is about to be revolutionized by the integration of large
language, multimodal, and circuit models (collectively LxMs). While exploring
this exciting frontier with tremendous potential, the community must also
carefully consider the related security risks and the need for building trust
into using LxMs for chip design. First, we review the recent surge of using
LxMs for chip design in general. We cover state-of-the-art works for the
automation of hardware description language code generation and for scripting
and guidance of essential but cumbersome tasks for electronic design automation
tools, e.g., design-space exploration, tuning, or designer training. Second, we
raise and provide initial answers to novel research questions on critical
issues for security and trustworthiness of LxM-powered chip design from both
the attack and defense perspectives.
",2024-05-11 17:27:41+00:00,cs.LG
"Towards an Accessible and Rapidly Trainable Rhythm Sequencer Using a
  Generative Stacked Autoencoder","  Neural networks and deep learning are often deployed for the sake of the most
comprehensive music generation with as little involvement as possible from the
human musician. Implementations in aid of, or being a tool for, music
practitioners are sparse. This paper proposes the integration of generative
stacked autoencoder structures for rhythm generation, within a conventional
melodic step-sequencer. It further aims to work towards its implementation
being accessible to the average electronic music practitioner. Several model
architectures have been trained and tested for their creative potential. While
the currently implementations do display limitations, they do represent viable
creative solutions for music practitioners.
",2024-05-11 15:17:27+00:00,cs.SD
"PIPE: Process Informed Parameter Estimation, a learning based approach
  to task generalized system identification","  We address the problem of robot guided assembly tasks, by using a
learning-based approach to identify contact model parameters for known and
novel parts. First, a Variational Autoencoder (VAE) is used to extract
geometric features of assembly parts. Then, we combine the extracted features
with physical knowledge to derive the parameters of a contact model using our
newly proposed neural network structure. The measured force from real
experiments is used to supervise the predicted forces, thus avoiding the need
for ground truth model parameters. Although trained only on a small set of
assembly parts, good contact model estimation for unknown objects were
achieved. Our main contribution is the network structure that allows us to
estimate contact models of assembly tasks depending on the geometry of the part
to be joined. Where current system identification processes have to record new
data for a new assembly process, our method only requires the 3D model of the
assembly part. We evaluate our method by estimating contact models for
robot-guided assembly tasks of pin connectors as well as electronic plugs and
compare the results with real experiments.
",2024-05-11 11:45:19+00:00,cs.RO
Intelligent Reflecting Surface-Aided Radar Spoofing,"  Electronic countermeasure (ECM) technology plays a critical role in modern
electronic warfare, which can interfere with enemy radar detection systems by
noise or deceptive signals. However, the conventional active jamming strategy
incurs additional hardware and power costs and has the potential threat of
exposing the target itself. To tackle the above challenges, we propose a new
intelligent reflecting surface (IRS)-aided radar spoofing strategy in this
letter, where IRS is deployed on the surface of a target to help eliminate the
signals reflected towards the hostile radar to shield the target, while
simultaneously redirecting its reflected signal towards a surrounding clutter
to generate deceptive angle-of-arrival (AoA) sensing information for the radar.
We optimize the IRS's reflection to maximize the received signal power at the
radar from the direction of the selected clutter subject to the constraint that
its received power from the direction of the target is lower than a given
detection threshold. We first solve this non-convex optimization problem using
the semidefinite relaxation (SDR) method and further propose a lower-complexity
solution for real-time implementation. Simulation results validate the efficacy
of our proposed IRS-aided spoofing system as compared to various benchmark
schemes.
",2024-05-11 08:20:06+00:00,cs.IT
"A Framework of SO(3)-equivariant Non-linear Representation Learning and
  its Application to Electronic-Structure Hamiltonian Prediction","  We present both a theoretical and a methodological framework that addresses a
critical challenge in applying deep learning to physical systems: the
reconciliation of non-linear expressiveness with SO(3)-equivariance in
predictions of SO(3)-equivariant quantities. Inspired by covariant theory in
physics, we address this problem by exploring the mathematical relationships
between SO(3)-invariant and SO(3)-equivariant quantities and their
representations. We first construct theoretical SO(3)-invariant quantities
derived from the SO(3)-equivariant regression targets, and use these invariant
quantities as supervisory labels to guide the learning of high-quality
SO(3)-invariant features. Given that SO(3)-invariance is preserved under
non-linear operations, the encoding process for invariant features can
extensively utilize non-linear mappings, thereby fully capturing the non-linear
patterns inherent in physical systems. Building on this foundation, we propose
a gradient-based mechanism to induce SO(3)-equivariant encodings of various
degrees from the learned SO(3)-invariant features. This mechanism can
incorporate non-linear expressive capabilities into SO(3)-equivariant
representations, while theoretically preserving their equivariant properties as
we prove. We apply our theory and method to the electronic-structure
Hamiltonian prediction tasks, experimental results on eight benchmark databases
covering multiple types of elements and challenging scenarios show dramatic
breakthroughs on the state-of-the-art prediction accuracy, with improvements of
up to 40% in predicting Hamiltonians and up to 76% in predicting downstream
physical quantities such as occupied orbital energy. Our approach goes beyond
handling physical systems and offers a promising general solution to the
critical dilemma between equivariance and non-linear expressiveness for the
deep learning paradigm.
",2024-05-09 12:34:45+00:00,cs.LG
"Intelligent EC Rearview Mirror: Enhancing Driver Safety with Dynamic
  Glare Mitigation via Cloud Edge Collaboration","  Sudden glare from trailing vehicles significantly increases driving safety
risks. Existing anti-glare technologies such as electronic, manually-adjusted,
and electrochromic rearview mirrors, are expensive and lack effective
adaptability in different lighting conditions. To address these issues, our
research introduces an intelligent rearview mirror system utilizing novel
all-liquid electrochromic technology. This system integrates IoT with ensemble
and federated learning within a cloud edge collaboration framework, dynamically
controlling voltage to effectively eliminate glare and maintain clear
visibility. Utilizing an ensemble learning model, it automatically adjusts
mirror transmittance based on light intensity, achieving a low RMSE of 0.109 on
the test set. Furthermore, the system leverages federated learning for
distributed data training across devices, which enhances privacy and updates
the cloud model continuously. Distinct from conventional methods, our
experiment utilizes the Schmidt-Clausen and Bindels de Boer 9-point scale with
TOPSIS for comprehensive evaluation of rearview mirror glare. Designed to be
convenient and costeffective, this system demonstrates how IoT and AI can
significantly enhance rearview mirror anti-glare performance.
",2024-05-09 07:10:47+00:00,cs.HC
"Precision Rehabilitation for Patients Post-Stroke based on Electronic
  Health Records and Machine Learning","  In this study, we utilized statistical analysis and machine learning methods
to examine whether rehabilitation exercises can improve patients post-stroke
functional abilities, as well as forecast the improvement in functional
abilities. Our dataset is patients' rehabilitation exercises and demographic
information recorded in the unstructured electronic health records (EHRs) data
and free-text rehabilitation procedure notes. We collected data for 265 stroke
patients from the University of Pittsburgh Medical Center. We employed a
pre-existing natural language processing (NLP) algorithm to extract data on
rehabilitation exercises and developed a rule-based NLP algorithm to extract
Activity Measure for Post-Acute Care (AM-PAC) scores, covering basic mobility
(BM) and applied cognitive (AC) domains, from procedure notes. Changes in
AM-PAC scores were classified based on the minimal clinically important
difference (MCID), and significance was assessed using Friedman and Wilcoxon
tests. To identify impactful exercises, we used Chi-square tests, Fisher's
exact tests, and logistic regression for odds ratios. Additionally, we
developed five machine learning models-logistic regression (LR), Adaboost
(ADB), support vector machine (SVM), gradient boosting (GB), and random forest
(RF)-to predict outcomes in functional ability. Statistical analyses revealed
significant associations between functional improvements and specific
exercises. The RF model achieved the best performance in predicting functional
outcomes. In this study, we identified three rehabilitation exercises that
significantly contributed to patient post-stroke functional ability improvement
in the first two months. Additionally, the successful application of a machine
learning model to predict patient-specific functional outcomes underscores the
potential for precision rehabilitation.
",2024-05-09 04:06:44+00:00,cs.LG
Analysis and prevention of AI-based phishing email attacks,"  Phishing email attacks are among the most common and most harmful
cybersecurity attacks. With the emergence of generative AI, phishing attacks
can be based on emails generated automatically, making it more difficult to
detect them. That is, instead of a single email format sent to a large number
of recipients, generative AI can be used to send each potential victim a
different email, making it more difficult for cybersecurity systems to identify
the scam email before it reaches the recipient. Here we describe a corpus of
AI-generated phishing emails. We also use different machine learning tools to
test the ability of automatic text analysis to identify AI-generated phishing
emails. The results are encouraging, and show that machine learning tools can
identify an AI-generated phishing email with high accuracy compared to regular
emails or human-generated scam email. By applying descriptive analytic, the
specific differences between AI-generated emails and manually crafted scam
emails are profiled, and show that AI-generated emails are different in their
style from human-generated phishing email scams. Therefore, automatic
identification tools can be used as a warning for the user. The paper also
describes the corpus of AI-generated phishing emails that is made open to the
public, and can be used for consequent studies. While the ability of machine
learning to detect AI-generated phishing email is encouraging, AI-generated
phishing emails are different from regular phishing emails, and therefore it is
important to train machine learning systems also with AI-generated emails in
order to repel future phishing attacks that are powered by generative AI.
",2024-05-08 21:40:49+00:00,cs.CR
"myAURA: Personalized health library for epilepsy management via
  knowledge graph sparsification and visualization","  Objective: We report the development of the patient-centered myAURA
application and suite of methods designed to aid epilepsy patients, caregivers,
and researchers in making decisions about care and self-management.
  Materials and Methods: myAURA rests on the federation of an unprecedented
collection of heterogeneous data resources relevant to epilepsy, such as
biomedical databases, social media, and electronic health records. A
generalizable, open-source methodology was developed to compute a multi-layer
knowledge graph linking all this heterogeneous data via the terms of a
human-centered biomedical dictionary.
  Results: The power of the approach is first exemplified in the study of the
drug-drug interaction phenomenon. Furthermore, we employ a novel network
sparsification methodology using the metric backbone of weighted graphs, which
reveals the most important edges for inference, recommendation, and
visualization, such as pharmacology factors patients discuss on social media.
The network sparsification approach also allows us to extract focused digital
cohorts from social media whose discourse is more relevant to epilepsy or other
biomedical problems. Finally, we present our patient-centered design and
pilot-testing of myAURA, including its user interface, based on focus groups
and other stakeholder input.
  Discussion: The ability to search and explore myAURA's heterogeneous data
sources via a sparsified multi-layer knowledge graph, as well as the
combination of those layers in a single map, are useful features for
integrating relevant information for epilepsy.
  Conclusion: Our stakeholder-driven, scalable approach to integrate
traditional and non-traditional data sources, enables biomedical discovery and
data-powered patient self-management in epilepsy, and is generalizable to other
chronic conditions.
",2024-05-08 17:24:24+00:00,cs.IR
"CARE-SD: Classifier-based analysis for recognizing and eliminating
  stigmatizing and doubt marker labels in electronic health records: model
  development and validation","  Objective: To detect and classify features of stigmatizing and biased
language in intensive care electronic health records (EHRs) using natural
language processing techniques. Materials and Methods: We first created a
lexicon and regular expression lists from literature-driven stem words for
linguistic features of stigmatizing patient labels, doubt markers, and scare
quotes within EHRs. The lexicon was further extended using Word2Vec and GPT
3.5, and refined through human evaluation. These lexicons were used to search
for matches across 18 million sentences from the de-identified Medical
Information Mart for Intensive Care-III (MIMIC-III) dataset. For each
linguistic bias feature, 1000 sentence matches were sampled, labeled by expert
clinical and public health annotators, and used to supervised learning
classifiers. Results: Lexicon development from expanded literature stem-word
lists resulted in a doubt marker lexicon containing 58 expressions, and a
stigmatizing labels lexicon containing 127 expressions. Classifiers for doubt
markers and stigmatizing labels had the highest performance, with macro
F1-scores of .84 and .79, positive-label recall and precision values ranging
from .71 to .86, and accuracies aligning closely with human annotator agreement
(.87). Discussion: This study demonstrated the feasibility of supervised
classifiers in automatically identifying stigmatizing labels and doubt markers
in medical text, and identified trends in stigmatizing language use in an EHR
setting. Additional labeled data may help improve lower scare quote model
performance. Conclusions: Classifiers developed in this study showed high model
performance and can be applied to identify patterns and target interventions to
reduce stigmatizing labels and doubt markers in healthcare systems.
",2024-05-08 16:40:18+00:00,cs.CL
"Insights from Basilisk: Are Open-Source EDA Tools Ready for a
  Multi-Million-Gate, Linux-Booting RV64 SoC Design?","  Designing complex, multi-million-gate application-specific integrated
circuits requires robust and mature electronic design automation (EDA) tools.
We describe our efforts in enhancing the open-source Yosys+Openroad EDA flow to
implement Basilisk, a fully open-source, Linux-booting RV64GC system-on-chip
(SoC) design. We analyze the quality-of-results impact of our enhancements to
synthesis tools, interfaces between EDA tools, logic optimization scripts, and
a newly open-sourced library of optimized arithmetic macro-operators. We also
introduce a streamlined physical design flow with an improved power grid and
cell placement integration. Our Basilisk SoC design was taped out in IHP's open
130 nm technology. It achieves an operating frequency of 77 MHz (51 logic
levels) under typical conditions, a 2.3x improvement compared to the baseline
open-source EDA flow, while also reducing logic area by 1.6x. Furthermore, tool
runtime was reduced by 2.5x, and peak RAM usage decreased by 2.9x. Through
collaboration with EDA tool developers and domain experts, Basilisk establishes
solid ""proof of existence"" for a fully open-source EDA flow used in designing a
competitive multi-million-gate digital SoC.
",2024-05-07 12:17:58+00:00,cs.AR
Gas Source Localization Using physics Guided Neural Networks,"  This work discusses a novel method for estimating the location of a gas
source based on spatially distributed concentration measurements taken, e.g.,
by a mobile robot or flying platform that follows a predefined trajectory to
collect samples. The proposed approach uses a Physics-Guided Neural Network to
approximate the gas dispersion with the source location as an additional
network input. After an initial offline training phase, the neural network can
be used to efficiently solve the inverse problem of localizing the gas source
based on measurements. The proposed approach allows avoiding rather costly
numerical simulations of gas physics needed for solving inverse problems. Our
experiments show that the method localizes the source well, even when dealing
with measurements affected by noise.
",2024-05-07 09:41:39+00:00,cs.LG
"Comparative Study of Recurrent Neural Networks for Virtual Analog Audio
  Effects Modeling","  Analog electronic circuits are at the core of an important category of
musical devices. The nonlinear features of their electronic components give
analog musical devices a distinctive timbre and sound quality, making them
highly desirable. Artificial neural networks have rapidly gained popularity for
the emulation of analog audio effects circuits, particularly recurrent
networks. While neural approaches have been successful in accurately modeling
distortion circuits, they require architectural improvements that account for
parameter conditioning and low latency response. In this article, we explore
the application of recent machine learning advancements for virtual analog
modeling. We compare State Space models and Linear Recurrent Units against the
more common Long Short Term Memory networks. These have shown promising ability
in sequence to sequence modeling tasks, showing a notable improvement in signal
history encoding. Our comparative study uses these black box neural modeling
techniques with a variety of audio effects. We evaluate the performance and
limitations using multiple metrics aiming to assess the models' ability to
accurately replicate energy envelopes, frequency contents, and transients in
the audio signal. To incorporate control parameters we employ the Feature wise
Linear Modulation method. Long Short Term Memory networks exhibit better
accuracy in emulating distortions and equalizers, while the State Space model,
followed by Long Short Term Memory networks when integrated in an encoder
decoder structure, outperforms others in emulating saturation and compression.
When considering long time variant characteristics, the State Space model
demonstrates the greatest accuracy. The Long Short Term Memory and, in
particular, Linear Recurrent Unit networks present more tendency to introduce
audio artifacts.
",2024-05-07 08:47:40+00:00,cs.SD
Joint Identity Verification and Pose Alignment for Partial Fingerprints,"  Currently, portable electronic devices are becoming more and more popular.
For lightweight considerations, their fingerprint recognition modules usually
use limited-size sensors. However, partial fingerprints have few matchable
features, especially when there are differences in finger pressing posture or
image quality, which makes partial fingerprint verification challenging. Most
existing methods regard fingerprint position rectification and identity
verification as independent tasks, ignoring the coupling relationship between
them -- relative pose estimation typically relies on paired features as
anchors, and authentication accuracy tends to improve with more precise pose
alignment. In this paper, we propose a novel framework for joint identity
verification and pose alignment of partial fingerprint pairs, aiming to
leverage their inherent correlation to improve each other. To achieve this, we
present a multi-task CNN (Convolutional Neural Network)-Transformer hybrid
network, and design a pre-training task to enhance the feature extraction
capability. Experiments on multiple public datasets (NIST SD14, FVC2002 DB1A &
DB3A, FVC2004 DB1A & DB2A, FVC2006 DB1A) and an in-house dataset show that our
method achieves state-of-the-art performance in both partial fingerprint
verification and relative pose estimation, while being more efficient than
previous methods.
",2024-05-07 02:45:50+00:00,cs.CV
"Predictive Modeling with Temporal Graphical Representation on Electronic
  Health Records","  Deep learning-based predictive models, leveraging Electronic Health Records
(EHR), are receiving increasing attention in healthcare. An effective
representation of a patient's EHR should hierarchically encompass both the
temporal relationships between historical visits and medical events, and the
inherent structural information within these elements. Existing patient
representation methods can be roughly categorized into sequential
representation and graphical representation. The sequential representation
methods focus only on the temporal relationships among longitudinal visits. On
the other hand, the graphical representation approaches, while adept at
extracting the graph-structured relationships between various medical events,
fall short in effectively integrate temporal information. To capture both types
of information, we model a patient's EHR as a novel temporal heterogeneous
graph. This graph includes historical visits nodes and medical events nodes. It
propagates structured information from medical event nodes to visit nodes and
utilizes time-aware visit nodes to capture changes in the patient's health
status. Furthermore, we introduce a novel temporal graph transformer (TRANS)
that integrates temporal edge features, global positional encoding, and local
structural encoding into heterogeneous graph convolution, capturing both
temporal and structural information. We validate the effectiveness of TRANS
through extensive experiments on three real-world datasets. The results show
that our proposed approach achieves state-of-the-art performance.
",2024-05-07 02:05:30+00:00,cs.LG
"Basilisk: Achieving Competitive Performance with Open EDA Tools on an
  Open-Source Linux-Capable RISC-V SoC","  We introduce Basilisk, an optimized application-specific integrated circuit
(ASIC) implementation and design flow building on the end-to-end open-source
Iguana system-on-chip (SoC). We present enhancements to synthesis tools and
logic optimization scripts improving quality of results (QoR), as well as an
optimized physical design with an improved power grid and cell placement
integration enabling a higher core utilization. The tapeout-ready version of
Basilisk implemented in IHP's open 130 nm technology achieves an operation
frequency of 77 MHz (51 logic levels) under typical conditions, a 2.3x
improvement compared to the baseline open-source EDA design flow presented in
Iguana, and a higher 55 % core utilization compared to 50 % in the baseline
design. Through collaboration with EDA tool developers and domain experts,
Basilisk exemplifies a synergistic effort towards competitive open-source
electronic design automation (EDA) tools for research and industry
applications.
",2024-05-06 14:40:44+00:00,cs.AR
"A scoping review of using Large Language Models (LLMs) to investigate
  Electronic Health Records (EHRs)","  Electronic Health Records (EHRs) play an important role in the healthcare
system. However, their complexity and vast volume pose significant challenges
to data interpretation and analysis. Recent advancements in Artificial
Intelligence (AI), particularly the development of Large Language Models
(LLMs), open up new opportunities for researchers in this domain. Although
prior studies have demonstrated their potential in language understanding and
processing in the context of EHRs, a comprehensive scoping review is lacking.
This study aims to bridge this research gap by conducting a scoping review
based on 329 related papers collected from OpenAlex. We first performed a
bibliometric analysis to examine paper trends, model applications, and
collaboration networks. Next, we manually reviewed and categorized each paper
into one of the seven identified topics: named entity recognition, information
extraction, text similarity, text summarization, text classification, dialogue
system, and diagnosis and prediction. For each topic, we discussed the unique
capabilities of LLMs, such as their ability to understand context, capture
semantic relations, and generate human-like text. Finally, we highlighted
several implications for researchers from the perspectives of data resources,
prompt engineering, fine-tuning, performance measures, and ethical concerns. In
conclusion, this study provides valuable insights into the potential of LLMs to
transform EHR research and discusses their applications and ethical
considerations.
",2024-05-05 22:21:15+00:00,cs.ET
"Overview of the EHRSQL 2024 Shared Task on Reliable Text-to-SQL Modeling
  on Electronic Health Records","  Electronic Health Records (EHRs) are relational databases that store the
entire medical histories of patients within hospitals. They record numerous
aspects of patients' medical care, from hospital admission and diagnosis to
treatment and discharge. While EHRs are vital sources of clinical data,
exploring them beyond a predefined set of queries requires skills in query
languages like SQL. To make information retrieval more accessible, one strategy
is to build a question-answering system, possibly leveraging text-to-SQL models
that can automatically translate natural language questions into corresponding
SQL queries and use these queries to retrieve the answers. The EHRSQL 2024
shared task aims to advance and promote research in developing a
question-answering system for EHRs using text-to-SQL modeling, capable of
reliably providing requested answers to various healthcare professionals to
improve their clinical work processes and satisfy their needs. Among more than
100 participants who applied to the shared task, eight teams were formed and
completed the entire shared task requirement and demonstrated a wide range of
methods to effectively solve this task. In this paper, we describe the task of
reliable text-to-SQL modeling, the dataset, and the methods and results of the
participants. We hope this shared task will spur further research and insights
into developing reliable question-answering systems for EHRs.
",2024-05-04 04:12:18+00:00,cs.CL
"Transimpedance Amplifier with Automatic Gain Control Based on Memristors
  for Optical Signal Acquisition","  Transimpedance amplifiers (TIA) play a crucial role in various electronic
systems, especially in optical signal acquisition. However, their performance
is often hampered by saturation issues due to high input currents, leading to
prolonged recovery times. This paper addresses this challenge by introducing a
novel approach utilizing a memristive automatic gain control (AGC) to adjust
the TIA's gain and enhance its dynamic range. We replace the typical feedback
resistor of a TIA with a valence-change mechanism (VCM) memristor. This
substitution enables the TIA to adapt to a broader range of input signals,
leveraging the substantial OFF/ON resistance ratio of the memristor. This paper
also presents the reading and resetting sub-circuits essential for monitoring
and controling the memristor's state. The proposed circuit is evaluated through
SPICE simulations. Furthermore, we extend our evaluation to practical testing
using a printed circuit board (PCB) integrating the TIA and memristor. We show
a remarkable 40 dB increase in the dynamic range of our TIA memristor circuit
compared to traditional resistor-based TIAs.
",2024-05-03 15:18:30+00:00,cs.AR
Towards Sustainable Low Carbon Emission Mini Data Centres,"  Mini data centres have become increasingly prevalent in diverse organizations
in recent years. They can be easily deployed at large scale, with high
resilience. They are also cost-effective and provide highsecurity protection.
On the other hand, IT technologies have resulted in the development of ever
more energy-efficient servers, leading to the periodic replacement of
older-generation servers in mini data centres. However, the disposal of older
servers has resulted in electronic waste that further aggravates the already
critical e-waste problem. Furthermore, despite the shift towards more
energy-efficient servers, many mini data centres still rely heavily on
high-carbon energy sources. This contributes to data centres' overall carbon
footprint. All these issues are concerns for sustainability. In order to
address this sustainability issue, this paper proposes an approach to extend
the lifespan of older-generation servers in mini data centres. This is made
possible thanks to a novel solar-powered computing technology, named Genesis,
that compensates for the energy overhead generated by older servers. As a
result, electronic waste can be reduced while improving system sustainability
by reusing functional server hardware. Moreover, Genesis does not require
server cooling, which reduces energy and water requirements. Analytical
reasoning is applied to compare the efficiency of typical conventional mini
data centre designs against alternative Genesis-based designs, in terms of
energy, carbon emissions and exploitation costs.
",2024-05-03 08:04:18+00:00,cs.AR
"Natural Language to Verilog: Design of a Recurrent Spiking Neural
  Network using Large Language Models and ChatGPT","  This paper investigates the use of Large Language Models (LLMs) for
automating the generation of hardware description code, aiming to explore their
potential in supporting and enhancing the development of efficient neuromorphic
computing architectures. Building on our prior work, we employ OpenAI's
ChatGPT4 and natural language prompts to synthesize a RTL Verilog module of a
programmable recurrent spiking neural network, while also generating test
benches to assess the system's correctness. The resultant design was validated
in three case studies, the exclusive OR,the IRIS flower classification and the
MNIST hand-written digit classification, achieving accuracies of up to 96.6%.
To verify its synthesizability and implementability, the design was prototyped
on a field-programmable gate array and implemented on SkyWater 130 nm
technology by using an open-source electronic design automation flow.
Additionally, we have submitted it to Tiny Tapeout 6 chip fabrication program
to further evaluate the system on-chip performance in the future.
",2024-05-02 16:08:08+00:00,cs.AR
GAIA: A General AI Assistant for Intelligent Accelerator Operations,"  Large-scale machines like particle accelerators are usually run by a team of
experienced operators. In case of a particle accelerator, these operators
possess suitable background knowledge on both accelerator physics and the
technology comprising the machine. Due to the complexity of the machine,
particular subsystems of the machine are taken care of by experts, who the
operators can turn to. In this work the reasoning and action (ReAct) prompting
paradigm is used to couple an open-weights large language model (LLM) with a
high-level machine control system framework and other tools, e.g. the
electronic logbook or machine design documentation. By doing so, a multi-expert
retrieval augmented generation (RAG) system is implemented, which assists
operators in knowledge retrieval tasks, interacts with the machine directly if
needed, or writes high level control system scripts. This consolidation of
expert knowledge and machine interaction can simplify and speed up machine
operation tasks for both new and experienced human operators.
",2024-05-02 15:06:18+00:00,cs.CL
"ICU Bloodstream Infection Prediction: A Transformer-Based Approach for
  EHR Analysis","  We introduce RatchetEHR, a novel transformer-based framework designed for the
predictive analysis of electronic health records (EHR) data in intensive care
unit (ICU) settings, with a specific focus on bloodstream infection (BSI)
prediction. Leveraging the MIMIC-IV dataset, RatchetEHR demonstrates superior
predictive performance compared to other methods, including RNN, LSTM, and
XGBoost, particularly due to its advanced handling of sequential and temporal
EHR data. A key innovation in RatchetEHR is the integration of the Graph
Convolutional Transformer (GCT) component, which significantly enhances the
ability to identify hidden structural relationships within EHR data, resulting
in more accurate clinical predictions. Through SHAP value analysis, we provide
insights into influential features for BSI prediction. RatchetEHR integrates
multiple advancements in deep learning which together provide accurate
predictions even with a relatively small sample size and highly imbalanced
dataset. This study contributes to medical informatics by showcasing the
application of advanced AI techniques in healthcare and sets a foundation for
further research to optimize these capabilities in EHR data analysis.
",2024-05-01 19:00:30+00:00,cs.LG
"Adapting Pretrained Networks for Image Quality Assessment on High
  Dynamic Range Displays","  Conventional image quality metrics (IQMs), such as PSNR and SSIM, are
designed for perceptually uniform gamma-encoded pixel values and cannot be
directly applied to perceptually non-uniform linear high-dynamic-range (HDR)
colors. Similarly, most of the available datasets consist of
standard-dynamic-range (SDR) images collected in standard and possibly
uncontrolled viewing conditions. Popular pre-trained neural networks are
likewise intended for SDR inputs, restricting their direct application to HDR
content. On the other hand, training HDR models from scratch is challenging due
to limited available HDR data. In this work, we explore more effective
approaches for training deep learning-based models for image quality assessment
(IQA) on HDR data. We leverage networks pre-trained on SDR data (source domain)
and re-target these models to HDR (target domain) with additional fine-tuning
and domain adaptation. We validate our methods on the available HDR IQA
datasets, demonstrating that models trained with our combined recipe outperform
previous baselines, converge much quicker, and reliably generalize to HDR
inputs.
",2024-05-01 17:57:12+00:00,cs.CV
"Modeling Linear and Non-linear Layers: An MILP Approach Towards Finding
  Differential and Impossible Differential Propagations","  Symmetric key cryptography stands as a fundamental cornerstone in ensuring
security within contemporary electronic communication frameworks. The
cryptanalysis of classical symmetric key ciphers involves traditional methods
and techniques aimed at breaking or analyzing these cryptographic systems. In
the evaluation of new ciphers, the resistance against linear and differential
cryptanalysis is commonly a key design criterion. The wide trail design
technique for block ciphers facilitates the demonstration of security against
linear and differential cryptanalysis. Assessing the scheme's security against
differential attacks often involves determining the minimum number of active
SBoxes for all rounds of a cipher. The propagation characteristics of a
cryptographic component, such as an SBox, can be expressed using Boolean
functions. Mixed Integer Linear Programming (MILP) proves to be a valuable
technique for solving Boolean functions. We formulate a set of inequalities to
model a Boolean function, which is subsequently solved by an MILP solver. To
efficiently model a Boolean function and select a minimal set of inequalities,
two key challenges must be addressed. We propose algorithms to address the
second challenge, aiming to find more optimized linear and non-linear
components. Our approaches are applied to modeling SBoxes (up to six bits) and
EXOR operations with any number of inputs. Additionally, we introduce an
MILP-based automatic tool for exploring differential and impossible
differential propagations within a cipher. The tool is successfully applied to
five lightweight block ciphers: Lilliput, GIFT64, SKINNY64, Klein, and MIBS.
",2024-05-01 10:48:23+00:00,cs.CR
Towards Green AI: Current status and future research,"  The immense technological progress in artificial intelligence research and
applications is increasingly drawing attention to the environmental
sustainability of such systems, a field that has been termed Green AI. With
this contribution we aim to broaden the discourse on Green AI by investigating
the current status of approaches to both environmental assessment and ecodesign
of AI systems. We propose a life-cycle-based system thinking approach that
accounts for the four key elements of these software-hardware-systems: model,
data, server, and cloud. We conduct an exemplary estimation of the carbon
footprint of relevant compute hardware and highlight the need to further
investigate methods for Green AI and ways to facilitate wide-spread adoption of
its principles. We envision that AI could be leveraged to mitigate its own
environmental challenges, which we denote as AI4greenAI.
",2024-05-01 08:10:01+00:00,cs.CY
Web3 and the State: Indian state's redescription of blockchain,"  The article does a close reading of a discussion paper by NITI Aayog and a
strategy paper by the Ministry of Electronics and Information Technology
(MeitY) advocating non-financial use cases of blockchain in India. By noting
the discursive shift from transparency to trust that grounds these two
documents and consequently Indian state's redescription of blockchain, the
paper foregrounds how governance by infrastructure is at the heart of new forms
of governance and how blockchain systems are being designated as decentral by
states to have recentralizing effects. The papers highlight how a mapping of
discursive shifts of notions such as trust, transparency, (de)centralization
and (dis)intermediation can be a potent site to investigate redescriptions of
emerging sociotechnical systems.
",2024-05-01 04:57:25+00:00,cs.HC
Almanac Copilot: Towards Autonomous Electronic Health Record Navigation,"  Clinicians spend large amounts of time on clinical documentation, and
inefficiencies impact quality of care and increase clinician burnout. Despite
the promise of electronic medical records (EMR), the transition from
paper-based records has been negatively associated with clinician wellness, in
part due to poor user experience, increased burden of documentation, and alert
fatigue. In this study, we present Almanac Copilot, an autonomous agent capable
of assisting clinicians with EMR-specific tasks such as information retrieval
and order placement. On EHR-QA, a synthetic evaluation dataset of 300 common
EHR queries based on real patient data, Almanac Copilot obtains a successful
task completion rate of 74% (n = 221 tasks) with a mean score of 2.45 over 3
(95% CI:2.34-2.56). By automating routine tasks and streamlining the
documentation process, our findings highlight the significant potential of
autonomous agents to mitigate the cognitive load imposed on clinicians by
current EMR systems.
",2024-04-30 22:55:27+00:00,cs.AI
"VISION: Toward a Standardized Process for Radiology Image Management at
  the National Level","  The compilation and analysis of radiological images poses numerous challenges
for researchers. The sheer volume of data as well as the computational needs of
algorithms capable of operating on images are extensive. Additionally, the
assembly of these images alone is difficult, as these exams may differ widely
in terms of clinical context, structured annotation available for model
training, modality, and patient identifiers. In this paper, we describe our
experiences and challenges in establishing a trusted collection of radiology
images linked to the United States Department of Veterans Affairs (VA)
electronic health record database. We also discuss implications in making this
repository research-ready for medical investigators. Key insights include
uncovering the specific procedures required for transferring images from a
clinical to a research-ready environment, as well as roadblocks and bottlenecks
in this process that may hinder future efforts at automation.
",2024-04-29 16:30:24+00:00,cs.CV
Computational Job Market Analysis with Natural Language Processing,"  [Abridged Abstract]
  Recent technological advances underscore labor market dynamics, yielding
significant consequences for employment prospects and increasing job vacancy
data across platforms and languages. Aggregating such data holds potential for
valuable insights into labor market demands, new skills emergence, and
facilitating job matching for various stakeholders. However, despite prevalent
insights in the private sector, transparent language technology systems and
data for this domain are lacking. This thesis investigates Natural Language
Processing (NLP) technology for extracting relevant information from job
descriptions, identifying challenges including scarcity of training data, lack
of standardized annotation guidelines, and shortage of effective extraction
methods from job ads. We frame the problem, obtaining annotated data, and
introducing extraction methodologies. Our contributions include job description
datasets, a de-identification dataset, and a novel active learning algorithm
for efficient model training. We propose skill extraction using weak
supervision, a taxonomy-aware pre-training methodology adapting multilingual
language models to the job market domain, and a retrieval-augmented model
leveraging multiple skill extraction datasets to enhance overall performance.
Finally, we ground extracted information within a designated taxonomy.
",2024-04-29 14:52:38+00:00,cs.CL
"Enhancing Boundary Segmentation for Topological Accuracy with
  Skeleton-based Methods","  Topological consistency plays a crucial role in the task of boundary
segmentation for reticular images, such as cell membrane segmentation in neuron
electron microscopic images, grain boundary segmentation in material
microscopic images and road segmentation in aerial images. In these fields,
topological changes in segmentation results have a serious impact on the
downstream tasks, which can even exceed the misalignment of the boundary
itself. To enhance the topology accuracy in segmentation results, we propose
the Skea-Topo Aware loss, which is a novel loss function that takes into
account the shape of each object and topological significance of the pixels. It
consists of two components. First, a skeleton-aware weighted loss improves the
segmentation accuracy by better modeling the object geometry with skeletons.
Second, a boundary rectified term effectively identifies and emphasizes
topological critical pixels in the prediction errors using both foreground and
background skeletons in the ground truth and predictions. Experiments prove
that our method improves topological consistency by up to 7 points in VI
compared to 13 state-of-art methods, based on objective and subjective
assessments across three different boundary segmentation datasets. The code is
available at https://github.com/clovermini/Skea_topo.
",2024-04-29 09:27:31+00:00,cs.CV
"Demand Analysis and Customized Product Offering Design on E-Commerce
  Platform","  It can be observed that the purchasing decision of an individual consumer in
an electronic marketplace is determined by a set of factors, such as personal
characteristics of the consumer, product pricing, minimum price-quantity
combination offered, decision-making space, and underlying motivation of the
consumer. These factors are combined to form a consumer's choice problem
domain, which plays a pivotal role in the product offering. In this study, we
attempt to focus on how the products? Offered can be customized by
incorporating the quantity and pack size of the products along with the factors
above to form a more extensive domain for examining the combined effects of all
of these factors on demand. Accordingly, the demand function is defined by a
novel method invoking the extended domain of choice problem in the electronic
marketplace. Consequently, the predictable uncertainty associated with the
consumer's demand function may disappear, increase the likelihood of earning
optimum revenue through customized combinations of the components of the
extended domain of choice problem, and improve the understanding of the
fluctuations in consumer demand. Finally, we propose a generalized price
response function with standard properties applicable to E-Commerce.
",2024-04-29 07:16:53+00:00,cs.GT
"Pragmatic Formal Verification of Sequential Error Detection and
  Correction Codes (ECCs) used in Safety-Critical Design","  Error Detection and Correction Codes (ECCs) are often used in digital designs
to protect data integrity. Especially in safety-critical systems such as
automotive electronics, ECCs are widely used and the verification of such
complex logic becomes more critical considering the ISO 26262 safety standards.
Exhaustive verification of ECC using formal methods has been a challenge given
the high number of data bits to protect. As an example, for an ECC of 128 data
bits with a possibility to detect up to four-bit errors, the combination of bit
errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7. This vast
analysis space often leads to bounded proof results. Moreover, the complexity
and state-space increase further if the ECC has sequential encoding and
decoding stages. To overcome such problems and sign-off the design with
confidence within reasonable proof time, we present a pragmatic formal
verification approach of complex ECC cores with several complexity reduction
techniques and know-how that were learnt during the course of verification. We
discuss using the linearity of the syndrome generator as a helper assertion,
using the abstract model as glue logic to compare the RTL with the sequential
version of the circuit, k-induction-based model checking and using mathematical
relations captured as properties to simplify the verification in order to get
an unbounded proof result within 24 hours of proof runtime.
",2024-04-28 18:31:09+00:00,cs.AI
Learning Visuotactile Skills with Two Multifingered Hands,"  Aiming to replicate human-like dexterity, perceptual experiences, and motion
patterns, we explore learning from human demonstrations using a bimanual system
with multifingered hands and visuotactile data. Two significant challenges
exist: the lack of an affordable and accessible teleoperation system suitable
for a dual-arm setup with multifingered hands, and the scarcity of
multifingered hand hardware equipped with touch sensing. To tackle the first
challenge, we develop HATO, a low-cost hands-arms teleoperation system that
leverages off-the-shelf electronics, complemented with a software suite that
enables efficient data collection; the comprehensive software suite also
supports multimodal data processing, scalable policy learning, and smooth
policy deployment. To tackle the latter challenge, we introduce a novel
hardware adaptation by repurposing two prosthetic hands equipped with touch
sensors for research. Using visuotactile data collected from our system, we
learn skills to complete long-horizon, high-precision tasks which are difficult
to achieve without multifingered dexterity and touch feedback. Furthermore, we
empirically investigate the effects of dataset size, sensing modality, and
visual input preprocessing on policy learning. Our results mark a promising
step forward in bimanual multifingered manipulation from visuotactile data.
Videos, code, and datasets can be found at https://toruowo.github.io/hato/ .
",2024-04-25 17:59:41+00:00,cs.RO
"DeepKalPose: An Enhanced Deep-Learning Kalman Filter for Temporally
  Consistent Monocular Vehicle Pose Estimation","  This paper presents DeepKalPose, a novel approach for enhancing temporal
consistency in monocular vehicle pose estimation applied on video through a
deep-learning-based Kalman Filter. By integrating a Bi-directional Kalman
filter strategy utilizing forward and backward time-series processing, combined
with a learnable motion model to represent complex motion patterns, our method
significantly improves pose accuracy and robustness across various conditions,
particularly for occluded or distant vehicles. Experimental validation on the
KITTI dataset confirms that DeepKalPose outperforms existing methods in both
pose accuracy and temporal consistency.
",2024-04-25 12:15:11+00:00,cs.CV
"Evolutionary Causal Discovery with Relative Impact Stratification for
  Interpretable Data Analysis","  This study proposes Evolutionary Causal Discovery (ECD) for causal discovery
that tailors response variables, predictor variables, and corresponding
operators to research datasets. Utilizing genetic programming for variable
relationship parsing, the method proceeds with the Relative Impact
Stratification (RIS) algorithm to assess the relative impact of predictor
variables on the response variable, facilitating expression simplification and
enhancing the interpretability of variable relationships. ECD proposes an
expression tree to visualize the RIS results, offering a differentiated
depiction of unknown causal relationships compared to conventional causal
discovery. The ECD method represents an evolution and augmentation of existing
causal discovery methods, providing an interpretable approach for analyzing
variable relationships in complex systems, particularly in healthcare settings
with Electronic Health Record (EHR) data. Experiments on both synthetic and
real-world EHR datasets demonstrate the efficacy of ECD in uncovering patterns
and mechanisms among variables, maintaining high accuracy and stability across
different noise levels. On the real-world EHR dataset, ECD reveals the
intricate relationships between the response variable and other predictive
variables, aligning with the results of structural equation modeling and
shapley additive explanations analyses.
",2024-04-25 06:42:32+00:00,cs.LG
"LLM-Based Section Identifiers Excel on Open Source but Stumble in Real
  World Applications","  Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.
",2024-04-25 02:25:35+00:00,cs.CL
"Towards Efficient Patient Recruitment for Clinical Trials: Application
  of a Prompt-Based Learning Model","  Objective: Clinical trials are essential for advancing pharmaceutical
interventions, but they face a bottleneck in selecting eligible participants.
Although leveraging electronic health records (EHR) for recruitment has gained
popularity, the complex nature of unstructured medical texts presents
challenges in efficiently identifying participants. Natural Language Processing
(NLP) techniques have emerged as a solution with a recent focus on transformer
models. In this study, we aimed to evaluate the performance of a prompt-based
large language model for the cohort selection task from unstructured medical
notes collected in the EHR. Methods: To process the medical records, we
selected the most related sentences of the records to the eligibility criteria
needed for the trial. The SNOMED CT concepts related to each eligibility
criterion were collected. Medical records were also annotated with MedCAT based
on the SNOMED CT ontology. Annotated sentences including concepts matched with
the criteria-relevant terms were extracted. A prompt-based large language model
(Generative Pre-trained Transformer (GPT) in this study) was then used with the
extracted sentences as the training set. To assess its effectiveness, we
evaluated the model's performance using the dataset from the 2018 n2c2
challenge, which aimed to classify medical records of 311 patients based on 13
eligibility criteria through NLP techniques. Results: Our proposed model showed
the overall micro and macro F measures of 0.9061 and 0.8060 which were among
the highest scores achieved by the experiments performed with this dataset.
Conclusion: The application of a prompt-based large language model in this
study to classify patients based on eligibility criteria received promising
scores. Besides, we proposed a method of extractive summarization with the aid
of SNOMED CT ontology that can be also applied to other medical texts.
",2024-04-24 20:42:28+00:00,cs.CL
"PRISM: Patient Records Interpretation for Semantic Clinical Trial
  Matching using Large Language Models","  Clinical trial matching is the task of identifying trials for which patients
may be potentially eligible. Typically, this task is labor-intensive and
requires detailed verification of patient electronic health records (EHRs)
against the stringent inclusion and exclusion criteria of clinical trials. This
process is manual, time-intensive, and challenging to scale up, resulting in
many patients missing out on potential therapeutic options. Recent advancements
in Large Language Models (LLMs) have made automating patient-trial matching
possible, as shown in multiple concurrent research studies. However, the
current approaches are confined to constrained, often synthetic datasets that
do not adequately mirror the complexities encountered in real-world medical
data. In this study, we present the first, end-to-end large-scale empirical
evaluation of clinical trial matching using real-world EHRs. Our study
showcases the capability of LLMs to accurately match patients with appropriate
clinical trials. We perform experiments with proprietary LLMs, including GPT-4
and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show
that OncoLLM, despite its significantly smaller size, not only outperforms
GPT-3.5 but also matches the performance of qualified medical doctors. All
experiments were carried out on real-world EHRs that include clinical notes and
available clinical trials from a single cancer center in the United States.
",2024-04-23 22:33:19+00:00,cs.CL
CORE-BEHRT: A Carefully Optimized and Rigorously Evaluated BEHRT,"  BERT-based models for Electronic Health Records (EHR) have surged in
popularity following the release of BEHRT and Med-BERT. Subsequent models have
largely built on these foundations despite the fundamental design choices of
these pioneering models remaining underexplored. To address this issue, we
introduce CORE-BEHRT, a Carefully Optimized and Rigorously Evaluated BEHRT.
Through incremental optimization, we isolate the sources of improvement for key
design choices, giving us insights into the effect of data representation and
individual technical components on performance. Evaluating this across a set of
generic tasks (death, pain treatment, and general infection), we showed that
improving data representation can increase the average downstream performance
from 0.785 to 0.797 AUROC, primarily when including medication and timestamps.
Improving the architecture and training protocol on top of this increased
average downstream performance to 0.801 AUROC. We then demonstrated the
consistency of our optimization through a rigorous evaluation across 25 diverse
clinical prediction tasks. We observed significant performance increases in 17
out of 25 tasks and improvements in 24 tasks, highlighting the generalizability
of our findings. Our findings provide a strong foundation for future work and
aim to increase the trustworthiness of BERT-based EHR models.
",2024-04-23 16:35:59+00:00,cs.LG
"Time-aware Heterogeneous Graph Transformer with Adaptive Attention
  Merging for Health Event Prediction","  The widespread application of Electronic Health Records (EHR) data in the
medical field has led to early successes in disease risk prediction using deep
learning methods. These methods typically require extensive data for training
due to their large parameter sets. However, existing works do not exploit the
full potential of EHR data. A significant challenge arises from the infrequent
occurrence of many medical codes within EHR data, limiting their clinical
applicability. Current research often lacks in critical areas: 1) incorporating
disease domain knowledge; 2) heterogeneously learning disease representations
with rich meanings; 3) capturing the temporal dynamics of disease progression.
To overcome these limitations, we introduce a novel heterogeneous graph
learning model designed to assimilate disease domain knowledge and elucidate
the intricate relationships between drugs and diseases. This model innovatively
incorporates temporal data into visit-level embeddings and leverages a
time-aware transformer alongside an adaptive attention mechanism to produce
patient representations. When evaluated on two healthcare datasets, our
approach demonstrated notable enhancements in both prediction accuracy and
interpretability over existing methodologies, signifying a substantial
advancement towards personalized and proactive healthcare management.
",2024-04-23 08:01:30+00:00,cs.LG
Compressed Meta-Optical Encoder for Image Classification,"  Optical and hybrid convolutional neural networks (CNNs) recently have become
of increasing interest to achieve low-latency, low-power image classification
and computer vision tasks. However, implementing optical nonlinearity is
challenging, and omitting the nonlinear layers in a standard CNN comes at a
significant reduction in accuracy. In this work, we use knowledge distillation
to compress modified AlexNet to a single linear convolutional layer and an
electronic backend (two fully connected layers). We obtain comparable
performance to a purely electronic CNN with five convolutional layers and three
fully connected layers. We implement the convolution optically via engineering
the point spread function of an inverse-designed meta-optic. Using this hybrid
approach, we estimate a reduction in multiply-accumulate operations from 17M in
a conventional electronic modified AlexNet to only 86K in the hybrid compressed
network enabled by the optical frontend. This constitutes over two orders of
magnitude reduction in latency and power consumption. Furthermore, we
experimentally demonstrate that the classification accuracy of the system
exceeds 93% on the MNIST dataset.
",2024-04-23 00:54:31+00:00,cs.CV
"Co-designing a Sub-millisecond Latency Event-based Eye Tracking System
  with Submanifold Sparse CNN","  Eye-tracking technology is integral to numerous consumer electronics
applications, particularly in the realm of virtual and augmented reality
(VR/AR). These applications demand solutions that excel in three crucial
aspects: low-latency, low-power consumption, and precision. Yet, achieving
optimal performance across all these fronts presents a formidable challenge,
necessitating a balance between sophisticated algorithms and efficient backend
hardware implementations. In this study, we tackle this challenge through a
synergistic software/hardware co-design of the system with an event camera.
Leveraging the inherent sparsity of event-based input data, we integrate a
novel sparse FPGA dataflow accelerator customized for submanifold sparse
convolution neural networks (SCNN). The SCNN implemented on the accelerator can
efficiently extract the embedding feature vector from each representation of
event slices by only processing the non-zero activations. Subsequently, these
vectors undergo further processing by a gated recurrent unit (GRU) and a fully
connected layer on the host CPU to generate the eye centers. Deployment and
evaluation of our system reveal outstanding performance metrics. On the
Event-based Eye-Tracking-AIS2024 dataset, our system achieves 81% p5 accuracy,
99.5% p10 accuracy, and 3.71 Mean Euclidean Distance with 0.7 ms latency while
only consuming 2.29 mJ per inference. Notably, our solution opens up
opportunities for future eye-tracking systems. Code is available at
https://github.com/CASR-HKU/ESDA/tree/eye_tracking.
",2024-04-22 15:28:42+00:00,cs.CV
"Robotic Blended Sonification: Consequential Robot Sound as Creative
  Material for Human-Robot Interaction","  Current research in robotic sounds generally focuses on either masking the
consequential sound produced by the robot or on sonifying data about the robot
to create a synthetic robot sound. We propose to capture, modify, and utilise
rather than mask the sounds that robots are already producing. In short, this
approach relies on capturing a robot's sounds, processing them according to
contextual information (e.g., collaborators' proximity or particular work
sequences), and playing back the modified sound. Previous research indicates
the usefulness of non-semantic, and even mechanical, sounds as a communication
tool for conveying robotic affect and function. Adding to this, this paper
presents a novel approach which makes two key contributions: (1) a technique
for real-time capture and processing of consequential robot sounds, and (2) an
approach to explore these sounds through direct human-robot interaction.
Drawing on methodologies from design, human-robot interaction, and creative
practice, the resulting 'Robotic Blended Sonification' is a concept which
transforms the consequential robot sounds into a creative material that can be
explored artistically and within application-based studies.
",2024-04-22 01:51:22+00:00,cs.HC
"Accelerating Medical Knowledge Discovery through Automated Knowledge
  Graph Generation and Enrichment","  Knowledge graphs (KGs) serve as powerful tools for organizing and
representing structured knowledge. While their utility is widely recognized,
challenges persist in their automation and completeness. Despite efforts in
automation and the utilization of expert-created ontologies, gaps in
connectivity remain prevalent within KGs. In response to these challenges, we
propose an innovative approach termed ``Medical Knowledge Graph Automation
(M-KGA)"". M-KGA leverages user-provided medical concepts and enriches them
semantically using BioPortal ontologies, thereby enhancing the completeness of
knowledge graphs through the integration of pre-trained embeddings. Our
approach introduces two distinct methodologies for uncovering hidden
connections within the knowledge graph: a cluster-based approach and a
node-based approach. Through rigorous testing involving 100 frequently
occurring medical concepts in Electronic Health Records (EHRs), our M-KGA
framework demonstrates promising results, indicating its potential to address
the limitations of existing knowledge graph automation techniques.
",2024-04-21 15:54:27+00:00,cs.AI
"Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming
  Generative Adversarial Networks","  Synthetic data generation offers a promising solution to enhance the
usefulness of Electronic Healthcare Records (EHR) by generating realistic
de-identified data. However, the existing literature primarily focuses on the
quality of synthetic health data, neglecting the crucial aspect of fairness in
downstream predictions. Consequently, models trained on synthetic EHR have
faced criticism for producing biased outcomes in target tasks. These biases can
arise from either spurious correlations between features or the failure of
models to accurately represent sub-groups. To address these concerns, we
present Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based
synthetic data generator specifically designed for the healthcare domain. In
order to tackle spurious correlations (i), we propose an
information-constrained Data Generation Process that enables the generator to
learn a fair deterministic transformation based on a well-defined notion of
algorithmic fairness. To overcome the challenge of capturing exact sub-group
representations (ii), we incentivize the generator to preserve sub-group
densities through score-based weighted sampling. This approach compels the
generator to learn from underrepresented regions of the data manifold. We
conduct extensive experiments using the MIMIC-III database. Our results
demonstrate that Bt-GAN achieves SOTA accuracy while significantly improving
fairness and minimizing bias amplification. We also perform an in-depth
explainability analysis to provide additional evidence supporting the validity
of our study. In conclusion, our research introduces a novel and professional
approach to addressing the limitations of synthetic data generation in the
healthcare domain. By incorporating fairness considerations and leveraging
advanced techniques such as GANs, we pave the way for more reliable and
unbiased predictions in healthcare applications.
",2024-04-21 12:16:38+00:00,cs.LG
Parallel AIG Refactoring via Conflict Breaking,"  Algorithm parallelization to leverage multi-core platforms for improving the
efficiency of Electronic Design Automation~(EDA) tools plays a significant role
in enhancing the scalability of Integrated Circuit (IC) designs. Logic
optimization is a key process in the EDA design flow to reduce the area and
depth of the circuit graph by finding logically equivalent graphs for
substitution, which is typically time-consuming. To address these challenges,
in this paper, we first analyze two types of conflicts that need to be handled
in the parallelization framework of refactoring And-Inverter Graph~(AIG). We
then present a fine-grained parallel AIG refactoring method, which strikes a
balance between the degree of parallelism and the conflicts encountered during
the refactoring operations. Experiment results show that our parallel refactor
is 28x averagely faster than the sequential algorithm on large benchmark tests
with 64 physical CPU cores, and has comparable optimization quality.
",2024-04-21 10:54:12+00:00,cs.DC
Enhancing ASIC Technology Mapping via Parallel Supergate Computing,"  With the development of large-scale integrated circuits, electronic design
automation~(EDA) tools are increasingly emphasizing efficiency, with parallel
algorithms becoming a trend. The optimization of delay reduction is a crucial
factor for ASIC technology mapping, and supergate technology proves to be an
effective method for achieving this in EDA tools flow. However, we have
observed that increasing the number of generated supergates can reduce delay,
but this comes at the cost of an exponential increase in computation time. In
this paper, we propose a parallel supergate computing method that addresses the
tradeoff between time-consuming and delay optimization. The proposed method
utilizes the input-constrained supergate pattern to parallelly generate the
supergate candidates, and then filter the valid supergates as the results.
Experiment results show the efficiency of the proposed method, for example, it
can attain the improvement of 4x speedup in computation time and 10.1 in delay
reduction with 32 threads.
",2024-04-21 10:50:25+00:00,cs.DC
Exploring Diverse Methods in Visual Question Answering,"  This study explores innovative methods for improving Visual Question
Answering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and
attention mechanisms. Leveraging a balanced VQA dataset, we investigate three
distinct strategies. Firstly, GAN-based approaches aim to generate answer
embeddings conditioned on image and question inputs, showing potential but
struggling with more complex tasks. Secondly, autoencoder-based techniques
focus on learning optimal embeddings for questions and images, achieving
comparable results with GAN due to better ability on complex questions. Lastly,
attention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),
address language priors and attention modeling, albeit with a
complexity-performance trade-off. This study underscores the challenges and
opportunities in VQA and suggests avenues for future research, including
alternative GAN formulations and attentional mechanisms.
",2024-04-21 07:34:44+00:00,cs.CV
"EHRFL: Federated Learning Framework for Heterogeneous EHRs and
  Precision-guided Selection of Participating Clients","  In this study, we provide solutions to two practical yet overlooked scenarios
in federated learning for electronic health records (EHRs): firstly, we
introduce EHRFL, a framework that facilitates federated learning across
healthcare institutions with distinct medical coding systems and database
schemas using text-based linearization of EHRs. Secondly, we focus on a
scenario where a single healthcare institution initiates federated learning to
build a model tailored for itself, in which the number of clients must be
optimized in order to reduce expenses incurred by the host. For selecting
participating clients, we present a novel precision-based method, leveraging
data latents to identify suitable participants for the institution. Our
empirical results show that EHRFL effectively enables federated learning across
hospitals with different EHR systems. Furthermore, our results demonstrate the
efficacy of our precision-based method in selecting reduced number of
participating clients without compromising model performance, resulting in
lower operational costs when constructing institution-specific models. We
believe this work lays a foundation for the broader adoption of federated
learning on EHRs.
",2024-04-20 08:23:46+00:00,cs.LG
"FreSeg: Frenet-Frame-based Part Segmentation for 3D Curvilinear
  Structures","  Part segmentation is a crucial task for 3D curvilinear structures like neuron
dendrites and blood vessels, enabling the analysis of dendritic spines and
aneurysms with scientific and clinical significance. However, their diversely
winded morphology poses a generalization challenge to existing deep learning
methods, which leads to labor-intensive manual correction. In this work, we
propose FreSeg, a framework of part segmentation tasks for 3D curvilinear
structures. With Frenet-Frame-based point cloud transformation, it enables the
models to learn more generalizable features and have significant performance
improvements on tasks involving elongated and curvy geometries. We evaluate
FreSeg on 2 datasets: 1) DenSpineEM, an in-house dataset for dendritic spine
segmentation, and 2) IntrA, a public 3D dataset for intracranial aneurysm
segmentation. Further, we will release the DenSpineEM dataset, which includes
roughly 6,000 spines from 69 dendrites from 3 public electron microscopy (EM)
datasets, to foster the development of effective dendritic spine instance
extraction methods and, consequently, large-scale connectivity analysis to
better understand mammalian brains.
",2024-04-19 16:40:24+00:00,cs.CV
"Les valeurs linguistiques et culturelles des documents num{é}riques et
  leur traitement s{é}mantique dans les syst{è}mes d'information
  {é}lectroniques","  The digital document evolves rapidly and spectacularly in its structure and
information content conveyed on networks and information systems. Generally
understood as a neutral support for information carrying a semantic value, the
digital document nevertheless carries parameters that denote certain cultural
and linguistic values specific to its creator. This document attempts to
emphasize some technical aspects that reflect this intrinsic identity of
electronic documents. The objective is to define a set of parameters and
recommendations capable of preserving the digital document a cultural and
linguistic identity which will identify it to its potential users in open and
distributed information systems. Ultimately, it aims to offer ""good practice""
recommendations for producers of fully or partially Arabic digital documents.
",2024-04-19 07:30:44+00:00,cs.DL
Guided Discrete Diffusion for Electronic Health Record Generation,"  Electronic health records (EHRs) are a pivotal data source that enables
numerous applications in computational medicine, e.g., disease progression
prediction, clinical trial design, and health economics and outcomes research.
Despite wide usability, their sensitive nature raises privacy and
confidentially concerns, which limit potential use cases. To tackle these
challenges, we explore the use of generative models to synthesize artificial,
yet realistic EHRs. While diffusion-based methods have recently demonstrated
state-of-the-art performance in generating other data modalities and overcome
the training instability and mode collapse issues that plague previous
GAN-based approaches, their applications in EHR generation remain
underexplored. The discrete nature of tabular medical code data in EHRs poses
challenges for high-quality data generation, especially for continuous
diffusion models. To this end, we introduce a novel tabular EHR generation
method, EHR-D3PM, which enables both unconditional and conditional generation
using the discrete diffusion model. Our experiments demonstrate that EHR-D3PM
significantly outperforms existing generative baselines on comprehensive
fidelity and utility metrics while maintaining less attribute and membership
vulnerability risks. Furthermore, we show EHR-D3PM is effective as a data
augmentation method and enhances performance on downstream tasks when combined
with real data.
",2024-04-18 16:50:46+00:00,cs.LG
ONOT: a High-Quality ICAO-compliant Synthetic Mugshot Dataset,"  Nowadays, state-of-the-art AI-based generative models represent a viable
solution to overcome privacy issues and biases in the collection of datasets
containing personal information, such as faces. Following this intuition, in
this paper we introduce ONOT, a synthetic dataset specifically focused on the
generation of high-quality faces in adherence to the requirements of the
ISO/IEC 39794-5 standards that, following the guidelines of the International
Civil Aviation Organization (ICAO), defines the interchange formats of face
images in electronic Machine-Readable Travel Documents (eMRTD). The strictly
controlled and varied mugshot images included in ONOT are useful in research
fields related to the analysis of face images in eMRTD, such as Morphing Attack
Detection and Face Quality Assessment. The dataset is publicly released, in
combination with the generation procedure details in order to improve the
reproducibility and enable future extensions.
",2024-04-17 10:38:51+00:00,cs.CV
Network architecture search of X-ray based scientific applications,"  X-ray and electron diffraction-based microscopy use bragg peak detection and
ptychography to perform 3-D imaging at an atomic resolution. Typically, these
techniques are implemented using computationally complex tasks such as a
Psuedo-Voigt function or solving a complex inverse problem. Recently, the use
of deep neural networks has improved the existing state-of-the-art approaches.
However, the design and development of the neural network models depends on
time and labor intensive tuning of the model by application experts. To that
end, we propose a hyperparameter (HPS) and neural architecture search (NAS)
approach to automate the design and optimization of the neural network models
for model size, energy consumption and throughput. We demonstrate the improved
performance of the auto-tuned models when compared to the manually tuned
BraggNN and PtychoNN benchmark. We study and demonstrate the importance of the
exploring the search space of tunable hyperparameters in enhancing the
performance of bragg peak detection and ptychographic reconstruction. Our NAS
and HPS of (1) BraggNN achieves a 31.03\% improvement in bragg peak detection
accuracy with a 87.57\% reduction in model size, and (2) PtychoNN achieves a
16.77\% improvement in model accuracy and a 12.82\% reduction in model size
when compared to the baseline PtychoNN model. When inferred on the Orin-AGX
platform, the optimized Braggnn and Ptychonn models demonstrate a 10.51\% and
9.47\% reduction in inference latency and a 44.18\% and 15.34\% reduction in
energy consumption when compared to their respective baselines, when inferred
in the Orin-AGX edge platform.
",2024-04-16 16:09:38+00:00,cs.LG
"Data Collection of Real-Life Knowledge Work in Context: The RLKWiC
  Dataset","  Over the years, various approaches have been employed to enhance the
productivity of knowledge workers, from addressing psychological well-being to
the development of personal knowledge assistants. A significant challenge in
this research area has been the absence of a comprehensive, publicly accessible
dataset that mirrors real-world knowledge work. Although a handful of datasets
exist, many are restricted in access or lack vital information dimensions,
complicating meaningful comparison and benchmarking in the domain. This paper
presents RLKWiC, a novel dataset of Real-Life Knowledge Work in Context,
derived from monitoring the computer interactions of eight participants over a
span of two months. As the first publicly available dataset offering a wealth
of essential information dimensions (such as explicated contexts, textual
contents, and semantics), RLKWiC seeks to address the research gap in the
personal information management domain, providing valuable insights for
modeling user behavior.
",2024-04-16 12:23:59+00:00,cs.AI
"Oxygen vacancies modulated VO2 for neurons and Spiking Neural Network
  construction","  Artificial neuronal devices are the basic building blocks for neuromorphic
computing systems, which have been motivated by realistic brain emulation.
Aiming for these applications, various device concepts have been proposed to
mimic the neuronal dynamics and functions. While till now, the artificial
neuron devices with high efficiency, high stability and low power consumption
are still far from practical application. Due to the special insulator-metal
phase transition, Vanadium Dioxide (VO2) has been considered as an idea
candidate for neuronal device fabrication. However, its intrinsic insulating
state requires the VO2 neuronal device to be driven under large bias voltage,
resulting in high power consumption and low frequency. Thus in the current
study, we have addressed this challenge by preparing oxygen vacancies modulated
VO2 film(VO2-x) and fabricating the VO2-x neuronal devices for Spiking Neural
Networks (SNNs) construction. Results indicate the neuron devices can be
operated under lower voltage with improved processing speed. The proposed VO2-x
based back-propagation SNNs (BP-SNNs) system, trained with the MNIST dataset,
demonstrates excellent accuracy in image recognition. Our study not only
demonstrates the VO2-x based neurons and SNN system for practical application,
but also offers an effective way to optimize the future neuromorphic computing
systems by defect engineering strategy.
",2024-04-16 04:18:13+00:00,cs.NE
Detecting AI Generated Text Based on NLP and Machine Learning Approaches,"  Recent advances in natural language processing (NLP) may enable artificial
intelligence (AI) models to generate writing that is identical to human written
form in the future. This might have profound ethical, legal, and social
repercussions. This study aims to address this problem by offering an accurate
AI detector model that can differentiate between electronically produced text
and human-written text. Our approach includes machine learning methods such as
XGB Classifier, SVM, BERT architecture deep learning models. Furthermore, our
results show that the BERT performs better than previous models in identifying
information generated by AI from information provided by humans. Provide a
comprehensive analysis of the current state of AI-generated text identification
in our assessment of pertinent studies. Our testing yielded positive findings,
showing that our strategy is successful, with the BERT emerging as the most
probable answer. We analyze the research's societal implications, highlighting
the possible advantages for various industries while addressing sustainability
issues pertaining to morality and the environment. The XGB classifier and SVM
give 0.84 and 0.81 accuracy in this article, respectively. The greatest
accuracy in this research is provided by the BERT model, which provides 0.93%
accuracy.
",2024-04-15 16:37:44+00:00,cs.LG
"Revealing the structure-property relationships of copper alloys with
  FAGC","  Understanding how the structure of materials affects their properties is a
cornerstone of materials science and engineering. However, traditional methods
have struggled to accurately describe the quantitative structure-property
relationships for complex structures. In our study, we bridge this gap by
leveraging machine learning to analyze images of materials' microstructures,
thus offering a novel way to understand and predict the properties of materials
based on their microstructures. We introduce a method known as FAGC (Feature
Augmentation on Geodesic Curves), specifically demonstrated for Cu-Cr-Zr
alloys. This approach utilizes machine learning to examine the shapes within
images of the alloys' microstructures and predict their mechanical and
electronic properties. This generative FAGC approach can effectively expand the
relatively small training datasets due to the limited availability of materials
images labeled with quantitative properties. The process begins with extracting
features from the images using neural networks. These features are then mapped
onto the Pre-shape space to construct the Geodesic curves. Along these curves,
new features are generated, effectively increasing the dataset. Moreover, we
design a pseudo-labeling mechanism for these newly generated features to
further enhance the training dataset. Our FAGC method has shown remarkable
results, significantly improving the accuracy of predicting the electronic
conductivity and hardness of Cu-Cr-Zr alloys, with R-squared values of 0.978
and 0.998, respectively. These outcomes underscore the potential of FAGC to
address the challenge of limited image data in materials science, providing a
powerful tool for establishing detailed and quantitative relationships between
complex microstructures and material properties.
",2024-04-15 07:20:09+00:00,cs.CV
"A Distributed Approach for Persistent Homology Computation on a Large
  Scale","  Persistent homology (PH) is a powerful mathematical method to automatically
extract relevant insights from images, such as those obtained by
high-resolution imaging devices like electron microscopes or new-generation
telescopes. However, the application of this method comes at a very high
computational cost, that is bound to explode more because new imaging devices
generate an ever-growing amount of data. In this paper we present PixHomology,
a novel algorithm for efficiently computing $0$-dimensional PH on 2D images,
optimizing memory and processing time. By leveraging the Apache Spark
framework, we also present a distributed version of our algorithm with several
optimized variants, able to concurrently process large batches of astronomical
images. Finally, we present the results of an experimental analysis showing
that our algorithm and its distributed version are efficient in terms of
required memory, execution time, and scalability, consistently outperforming
existing state-of-the-art PH computation tools when used to process large
datasets.
",2024-04-12 05:24:55+00:00,cs.DC
"Ephemeral Myographic Motion: Repurposing the Myo Armband to Control
  Disposable Pneumatic Sculptures","  This paper details the development of an interactive sculpture built from
deprecated hardware technology and intentionally decomposable, transient
materials. We detail a case study of ""Strain"" - an emotive prototype that
reclaims two orphaned digital artifacts to power a kinetic sculpture made of
common disposable objects. We use the Myo, an abandoned myoelectric armband, in
concert with the Programmable Air, a soft-robotics prototyping project, to
manipulate a pneumatic bladder array constructed from condoms, bamboo skewers,
and a small library of 3D printed PLA plastic connectors designed to work with
these generic parts. The resulting sculpture achieves surprisingly organic
actuation. The goal of this project is to produce several reusable components:
software to resuscitate the Myo Armband, homeostasis software for the
Programmable Air or equivalent pneumatic projects, and a library of
easily-printed parts that will work with generic bamboo disposables for
sculptural prototyping. This project works to develop usable, repeatable
engineering by applying it to a slightly whimsical object that promotes a
strong emotional response in its audience. Through this, we transform the
disposable into the sustainable. In this paper, we reflect on project-based
insights into rescuing and revitalizing abandoned consumer electronics for
future works.
",2024-04-11 18:09:00+00:00,cs.HC
Fabricating Paper Circuits with Subtractive Processing,"  This paper introduces a new method of paper circuit fabrication that
overcomes design barriers and increases flexibility in circuit design.
Conventional circuit boards rely on thin traces, which limits the complexity
and accuracy when applied to paper circuits. To address this issue, we propose
a method that uses large conductive zones in paper circuits and performs
subtractive processing during their fabrication. This approach eliminates
design barriers and allows for more flexibility in circuit design. We introduce
PaperCAD, a software tool that simplifies the design process by converting
traditional circuit design to paper circuit design. We demonstrate our
technique by creating two paper circuit boards. Our approach has the potential
to promote the development of new applications for paper circuits.
",2024-04-10 21:38:49+00:00,cs.HC
"Global Contrastive Training for Multimodal Electronic Health Records
  with Language Supervision","  Modern electronic health records (EHRs) hold immense promise in tracking
personalized patient health trajectories through sequential deep learning,
owing to their extensive breadth, scale, and temporal granularity. Nonetheless,
how to effectively leverage multiple modalities from EHRs poses significant
challenges, given its complex characteristics such as high dimensionality,
multimodality, sparsity, varied recording frequencies, and temporal
irregularities. To this end, this paper introduces a novel multimodal
contrastive learning framework, specifically focusing on medical time series
and clinical notes. To tackle the challenge of sparsity and irregular time
intervals in medical time series, the framework integrates temporal
cross-attention transformers with a dynamic embedding and tokenization scheme
for learning multimodal feature representations. To harness the interconnected
relationships between medical time series and clinical notes, the framework
equips a global contrastive loss, aligning a patient's multimodal feature
representations with the corresponding discharge summaries. Since discharge
summaries uniquely pertain to individual patients and represent a holistic view
of the patient's hospital stay, machine learning models are led to learn
discriminative multimodal features via global contrasting. Extensive
experiments with a real-world EHR dataset demonstrated that our framework
outperformed state-of-the-art approaches on the exemplar task of predicting the
occurrence of nine postoperative complications for more than 120,000 major
inpatient surgeries using multimodal data from UF health system split among
three hospitals (UF Health Gainesville, UF Health Jacksonville, and UF Health
Jacksonville-North).
",2024-04-10 04:19:59+00:00,cs.LG
"Federated learning model for predicting major postoperative
  complications","  Background: The accurate prediction of postoperative complication risk using
Electronic Health Records (EHR) and artificial intelligence shows great
potential. Training a robust artificial intelligence model typically requires
large-scale and diverse datasets. In reality, collecting medical data often
encounters challenges surrounding privacy protection. Methods: This
retrospective cohort study includes adult patients who were admitted to UFH
Gainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type
of inpatient surgical procedure. Using perioperative and intraoperative
features, we developed federated learning models to predict nine major
postoperative complications (i.e., prolonged intensive care unit stay and
mechanical ventilation). We compared federated learning models with local
learning models trained on a single site and central learning models trained on
pooled dataset from two centers. Results: Our federated learning models
achieved the area under the receiver operating characteristics curve (AUROC)
values ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay
at UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for
wound complications to 0.92-0.93 for hospital mortality. Federated learning
models achieved comparable AUROC performance to central learning models, except
for prolonged ICU stay, where the performance of federated learning models was
slightly higher than central learning models at UFH GNV center, but slightly
lower at UFH JAX center. In addition, our federated learning model obtained
comparable performance to the best local learning model at each center,
demonstrating strong generalizability. Conclusion: Federated learning is shown
to be a useful tool to train robust and generalizable models from large scale
data across multiple institutions where data protection barriers are high.
",2024-04-09 22:31:10+00:00,cs.LG
"ClinLinker: Medical Entity Linking of Clinical Concept Mentions in
  Spanish","  Advances in natural language processing techniques, such as named entity
recognition and normalization to widely used standardized terminologies like
UMLS or SNOMED-CT, along with the digitalization of electronic health records,
have significantly advanced clinical text analysis. This study presents
ClinLinker, a novel approach employing a two-phase pipeline for medical entity
linking that leverages the potential of in-domain adapted language models for
biomedical text mining: initial candidate retrieval using a SapBERT-based
bi-encoder and subsequent re-ranking with a cross-encoder, trained by following
a contrastive-learning strategy to be tailored to medical concepts in Spanish.
This methodology, focused initially on content in Spanish, substantially
outperforming multilingual language models designed for the same purpose. This
is true even for complex scenarios involving heterogeneous medical
terminologies and being trained on a subset of the original data. Our results,
evaluated using top-k accuracy at 25 and other top-k metrics, demonstrate our
approach's performance on two distinct clinical entity linking Gold Standard
corpora, DisTEMIST (diseases) and MedProcNER (clinical procedures),
outperforming previous benchmarks by 40 points in DisTEMIST and 43 points in
MedProcNER, both normalized to SNOMED-CT codes. These findings highlight our
approach's ability to address language-specific nuances and set a new benchmark
in entity linking, offering a potent tool for enhancing the utility of digital
medical records. The resulting system is of practical value, both for large
scale automatic generation of structured data derived from clinical records, as
well as for exhaustive extraction and harmonization of predefined clinical
variables of interest.
",2024-04-09 15:04:27+00:00,cs.CL
"Interpretable Neural Temporal Point Processes for Modelling Electronic
  Health Records","  Electronic Health Records (EHR) can be represented as temporal sequences that
record the events (medical visits) from patients. Neural temporal point process
(NTPP) has achieved great success in modeling event sequences that occur in
continuous time space. However, due to the black-box nature of neural networks,
existing NTPP models fall short in explaining the dependencies between
different event types. In this paper, inspired by word2vec and Hawkes process,
we propose an interpretable framework inf2vec for event sequence modelling,
where the event influences are directly parameterized and can be learned
end-to-end. In the experiment, we demonstrate the superiority of our model on
event prediction as well as type-type influences learning.
",2024-04-09 12:37:41+00:00,cs.LG
"Deep Reinforcement Learning for Personalized Diagnostic Decision
  Pathways Using Electronic Health Records: A Comparative Study on Anemia and
  Systemic Lupus Erythematosus","  Background: Clinical diagnosis is typically reached by following a series of
steps recommended by guidelines authored by colleges of experts. Accordingly,
guidelines play a crucial role in rationalizing clinical decisions but suffer
from limitations as they are built to cover the majority of the population and
fail at covering patients with uncommon conditions. Moreover, their updates are
long and expensive, making them unsuitable for emerging diseases and practices.
  Methods: Inspired by guidelines, we formulate the task of diagnosis as a
sequential decision-making problem and study the use of Deep Reinforcement
Learning (DRL) algorithms to learn the optimal sequence of actions to perform
in order to obtain a correct diagnosis from Electronic Health Records (EHRs).
We apply DRL on synthetic, but realistic EHRs and develop two clinical use
cases: Anemia diagnosis, where the decision pathways follow the schema of a
decision tree; and Systemic Lupus Erythematosus (SLE) diagnosis, which follows
a weighted criteria score. We particularly evaluate the robustness of our
approaches to noisy and missing data since these frequently occur in EHRs.
  Results: In both use cases, and in the presence of imperfect data, our best
DRL algorithms exhibit competitive performance when compared to the traditional
classifiers, with the added advantage that they enable the progressive
generation of a pathway to the suggested diagnosis which can both guide and
explain the decision-making process.
  Conclusion: DRL offers the opportunity to learn personalized decision
pathways to diagnosis. We illustrate with our two use cases their advantages:
they generate step-by-step pathways that are self-explanatory; and their
correctness is competitive when compared to state-of-the-art approaches.
",2024-04-09 00:07:16+00:00,cs.LG
"Access to Library Information Resources by University Students during
  COVID-19 Pandemic in Africa: A Systematic Literature Review","  The study examined access to library information resources by university
students during the outbreak of the COVID-19 pandemic. The study investigated
measures that were adopted by academic libraries for smooth delivery of library
information resources to their patrons. It also identified technological tools
that were employed by libraries to facilitate access to library information
resources. We also investigated the challenges faced by students in accessing
library information resources. A systematic literature review approach using
PRISMA guidelines was employed to investigate the relevant literature on the
subject. The keyword search strategy was employed to search for relevant
literature from four scholarly databases Scopus, emerald, Research4life, and
Google Scholar. In this study, 23 studies that fulfilled the criteria were
included. The findings revealed that the majority of the reviewed studies
indicate that, during the COVID-19 pandemic many academic libraries in Africa
adopted different approaches to facilitate access to library information
resources by university students including expanding access to electronic
resources off-campus, virtual reference services, circulation and lending
services. To support access to different library services and information
resources academic libraries in Africa used various digital technological tools
like social media, library websites, email and video conferencing. Moreover,
the study revealed that limited access to internet services and ICT devices,
inadequate electronic library collection and inadequate digital and information
literacy were the major challenges faced by patrons during the pandemic. This
study recommends investment in ICT infrastructures and expanding electronic
resource collections which are vital resources in the digital era.
",2024-04-08 16:13:35+00:00,cs.IR
"Exploring Quantization and Mapping Synergy in Hardware-Aware Deep Neural
  Network Accelerators","  Energy efficiency and memory footprint of a convolutional neural network
(CNN) implemented on a CNN inference accelerator depend on many factors,
including a weight quantization strategy (i.e., data types and bit-widths) and
mapping (i.e., placement and scheduling of DNN elementary operations on
hardware units of the accelerator). We show that enabling rich mixed
quantization schemes during the implementation can open a previously hidden
space of mappings that utilize the hardware resources more effectively. CNNs
utilizing quantized weights and activations and suitable mappings can
significantly improve trade-offs among the accuracy, energy, and memory
requirements compared to less carefully optimized CNN implementations. To find,
analyze, and exploit these mappings, we: (i) extend a general-purpose
state-of-the-art mapping tool (Timeloop) to support mixed quantization, which
is not currently available; (ii) propose an efficient multi-objective
optimization algorithm to find the most suitable bit-widths and mapping for
each DNN layer executed on the accelerator; and (iii) conduct a detailed
experimental evaluation to validate the proposed method. On two CNNs
(MobileNetV1 and MobileNetV2) and two accelerators (Eyeriss and Simba) we show
that for a given quality metric (such as the accuracy on ImageNet), energy
savings are up to 37% without any accuracy drop.
",2024-04-08 10:10:30+00:00,cs.AR
StaccaToe: A Single-Leg Robot that Mimics the Human Leg and Toe,"  We introduce StaccaToe, a human-scale, electric motor-powered single-leg
robot designed to rival the agility of human locomotion through two distinctive
attributes: an actuated toe and a co-actuation configuration inspired by the
human leg. Leveraging the foundational design of HyperLeg's lower leg
mechanism, we develop a stand-alone robot by incorporating new link designs,
custom-designed power electronics, and a refined control system. Unlike
previous jumping robots that rely on either special mechanisms (e.g., springs
and clutches) or hydraulic/pneumatic actuators, StaccaToe employs electric
motors without energy storage mechanisms. This choice underscores our ultimate
goal of developing a practical, high-performance humanoid robot capable of
human-like, stable walking as well as explosive dynamic movements. In this
paper, we aim to empirically evaluate the balance capability and the exertion
of explosive ground reaction forces of our toe and co-actuation mechanisms.
Throughout extensive hardware and controller development, StaccaToe showcases
its control fidelity by demonstrating a balanced tip-toe stance and dynamic
jump. This study is significant for three key reasons: 1) StaccaToe represents
the first human-scale, electric motor-driven single-leg robot to execute
dynamic maneuvers without relying on specialized mechanisms; 2) our research
provides empirical evidence of the benefits of replicating critical human leg
attributes in robotic design; and 3) we explain the design process for creating
agile legged robots, the details that have been scantily covered in academic
literature.
",2024-04-07 18:47:52+00:00,cs.RO
Explaining EDA synthesis errors with LLMs,"  Training new engineers in digital design is a challenge, particularly when it
comes to teaching the complex electronic design automation (EDA) tooling used
in this domain. Learners will typically deploy designs in the Verilog and VHDL
hardware description languages to Field Programmable Gate Arrays (FPGAs) from
Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains
(Quartus Prime and Vivado, respectively). These tools are complex and difficult
to use -- yet, as they are the tools used in industry, they are an essential
first step in this space. In this work, we examine how recent advances in
artificial intelligence may be leveraged to address aspects of this challenge.
Specifically, we investigate if Large Language Models (LLMs), which have
demonstrated text comprehension and question-answering capabilities, can be
used to generate novice-friendly explanations of compile-time synthesis error
messages from Quartus Prime and Vivado. To perform this study we generate 936
error message explanations using three OpenAI LLMs over 21 different buggy code
samples. These are then graded for relevance and correctness, and we find that
in approximately 71% of cases the LLMs give correct & complete explanations
suitable for novice learners.
",2024-04-07 07:12:16+00:00,cs.AR
"Interpretable Multimodal Learning for Cardiovascular Hemodynamics
  Assessment","  Pulmonary Arterial Wedge Pressure (PAWP) is an essential cardiovascular
hemodynamics marker to detect heart failure. In clinical practice, Right Heart
Catheterization is considered a gold standard for assessing cardiac
hemodynamics while non-invasive methods are often needed to screen high-risk
patients from a large population. In this paper, we propose a multimodal
learning pipeline to predict PAWP marker. We utilize complementary information
from Cardiac Magnetic Resonance Imaging (CMR) scans (short-axis and
four-chamber) and Electronic Health Records (EHRs). We extract spatio-temporal
features from CMR scans using tensor-based learning. We propose a graph
attention network to select important EHR features for prediction, where we
model subjects as graph nodes and feature relationships as graph edges using
the attention mechanism. We design four feature fusion strategies: early,
intermediate, late, and hybrid fusion. With a linear classifier and linear
fusion strategies, our pipeline is interpretable. We validate our pipeline on a
large dataset of $2,641$ subjects from our ASPIRE registry. The comparative
study against state-of-the-art methods confirms the superiority of our
pipeline. The decision curve analysis further validates that our pipeline can
be applied to screen a large population. The code is available at
https://github.com/prasunc/hemodynamics.
",2024-04-06 19:42:25+00:00,cs.CV
"Advances in Differential Privacy and Differentially Private Machine
  Learning","  There has been an explosion of research on differential privacy (DP) and its
various applications in recent years, ranging from novel variants and
accounting techniques in differential privacy to the thriving field of
differentially private machine learning (DPML) to newer implementations in
practice, like those by various companies and organisations such as census
bureaus. Most recent surveys focus on the applications of differential privacy
in particular contexts like data publishing, specific machine learning tasks,
analysis of unstructured data, location privacy, etc. This work thus seeks to
fill the gap for a survey that primarily discusses recent developments in the
theory of differential privacy along with newer DP variants, viz. Renyi DP and
Concentrated DP, novel mechanisms and techniques, and the theoretical
developments in differentially private machine learning in proper detail. In
addition, this survey discusses its applications to privacy-preserving machine
learning in practice and a few practical implementations of DP.
",2024-04-06 18:49:24+00:00,cs.CR
Neuroevolving Electronic Dynamical Networks,"  Neuroevolution is a powerful method of applying an evolutionary algorithm to
refine the performance of artificial neural networks through natural selection;
however, the fitness evaluation of these networks can be time-consuming and
computationally expensive, particularly for continuous time recurrent neural
networks (CTRNNs) that necessitate the simulation of differential equations. To
overcome this challenge, field programmable gate arrays (FPGAs) have emerged as
an increasingly popular solution, due to their high performance and low power
consumption. Further, their ability to undergo dynamic and partial
reconfiguration enables the extremely rapid evaluation of the fitness of
CTRNNs, effectively addressing the bottleneck associated with conventional
methods of evolvable hardware. By incorporating fitness evaluation directly
upon the programmable logic of the FPGA, hyper-parallel evaluation becomes
feasible, dramatically reducing the time required for assessment. This inherent
parallelism of FPGAs accelerates the entire neuroevolutionary process by
several orders of magnitude, facilitating faster convergence to an optimal
solution. The work presented in this study demonstrates the potential of
utilizing dynamic and partial reconfiguration on capable FPGAs as a powerful
platform for neuroevolving dynamic neural networks.
",2024-04-06 10:54:35+00:00,cs.NE
"Quantum-informed simulations for mechanics of materials: DFTB+MBD
  framework","  The macroscopic behaviors of materials are determined by interactions that
occur at multiple lengths and time scales. Depending on the application,
describing, predicting, and understanding these behaviors require models that
rely on insights from electronic and atomic scales. In such cases, classical
simplified approximations at those scales are insufficient, and quantum-based
modeling is required. In this paper, we study how quantum effects can modify
the mechanical properties of systems relevant to materials engineering. We base
our study on a high-fidelity modeling framework that combines two
computationally efficient models rooted in quantum first principles: Density
Functional Tight Binding (DFTB) and many-body dispersion (MBD). The MBD model
is applied to accurately describe non-covalent van der Waals interactions.
Through various benchmark applications, we demonstrate the capabilities of this
framework and the limitations of simplified modeling. We provide an open-source
repository containing all codes, datasets, and examples presented in this work.
This repository serves as a practical toolkit that we hope will support the
development of future research in effective large-scale and multiscale modeling
with quantum-mechanical fidelity.
",2024-04-05 16:59:01+00:00,cs.CE
"VoltaVision: A Transfer Learning model for electronic component
  classification","  In this paper, we analyze the effectiveness of transfer learning on
classifying electronic components. Transfer learning reuses pre-trained models
to save time and resources in building a robust classifier rather than learning
from scratch. Our work introduces a lightweight CNN, coined as VoltaVision, and
compares its performance against more complex models. We test the hypothesis
that transferring knowledge from a similar task to our target domain yields
better results than state-of-the-art models trained on general datasets. Our
dataset and code for this work are available at
https://github.com/AnasIshfaque/VoltaVision.
",2024-04-05 05:42:23+00:00,cs.CV
Holon: a cybernetic interface for bio-semiotics,"  This paper presents an interactive artwork, ""Holon"", a collection of 130
autonomous, cybernetic organisms that listen and make sound in collaboration
with the natural environment. The work was developed for installation on water
at a heritage-listed dock in Melbourne, Australia. Conceptual issues informing
the work are presented, along with a detailed technical overview of the
implementation. Individual holons are of three types, inspired by biological
models of animal communication: composer/generators, collector/critics and
disruptors. Collectively, Holon integrates and occupies elements of the
acoustic spectrum in collaboration with human and non-human agents.
",2024-04-05 05:03:39+00:00,cs.SD
"On Extending the Automatic Test Markup Language (ATML) for Machine
  Learning","  This paper addresses the urgent need for messaging standards in the
operational test and evaluation (T&E) of machine learning (ML) applications,
particularly in edge ML applications embedded in systems like robots,
satellites, and unmanned vehicles. It examines the suitability of the IEEE
Standard 1671 (IEEE Std 1671), known as the Automatic Test Markup Language
(ATML), an XML-based standard originally developed for electronic systems, for
ML application testing. The paper explores extending IEEE Std 1671 to encompass
the unique challenges of ML applications, including the use of datasets and
dependencies on software. Through modeling various tests such as adversarial
robustness and drift detection, this paper offers a framework adaptable to
specific applications, suggesting that minor modifications to ATML might
suffice to address the novelties of ML. This paper differentiates ATML's focus
on testing from other ML standards like Predictive Model Markup Language (PMML)
or Open Neural Network Exchange (ONNX), which concentrate on ML model
specification. We conclude that ATML is a promising tool for effective, near
real-time operational T&E of ML applications, an essential aspect of AI
lifecycle management, safety, and governance.
",2024-04-04 19:28:38+00:00,cs.SE
"Conversational Disease Diagnosis via External Planner-Controlled Large
  Language Models","  The development of large language models (LLMs) has brought unprecedented
possibilities for artificial intelligence (AI) based medical diagnosis.
However, the application perspective of LLMs in real diagnostic scenarios is
still unclear because they are not adept at collecting patient data
proactively. This study presents a LLM-based diagnostic system that enhances
planning capabilities by emulating doctors. Our system involves two external
planners to handle planning tasks. The first planner employs a reinforcement
learning approach to formulate disease screening questions and conduct initial
diagnoses. The second planner uses LLMs to parse medical guidelines and conduct
differential diagnoses. By utilizing real patient electronic medical record
data, we constructed simulated dialogues between virtual patients and doctors
and evaluated the diagnostic abilities of our system. We demonstrated that our
system obtained impressive performance in both disease screening and
differential diagnoses tasks. This research represents a step towards more
seamlessly integrating AI into clinical settings, potentially enhancing the
accuracy and accessibility of medical diagnostics.
",2024-04-04 06:16:35+00:00,cs.CL
Biodegradable Interactive Materials,"  The sense of touch is fundamental to how we interact with the physical and
digital world. Conventional interactive surfaces and tactile interfaces use
electronic sensors embedded into objects, however this approach poses serious
challenges both for environmental sustainability and a future of truly
ubiquitous interaction systems where information is encoded into everyday
objects. In this work, we present Biodegradable Interactive Materials:
backyard-compostable interactive interfaces that leverage information encoded
in material properties. Inspired by natural systems, we propose an architecture
that programmatically encodes multidimensional information into materials
themselves and combines them with wearable devices that extend human senses to
perceive the embedded data. We combine unrefined biological matter from plants
and algae like chlorella with natural minerals like graphite and magnetite to
produce materials with varying electrical, magnetic, and surface properties. We
perform in-depth analysis using physics models, computational simulations, and
real-world experiments to characterize their information density and develop
decoding methods. Our passive, chip-less materials can robustly encode 12 bits
of information, equivalent to 4096 unique classes. We further develop wearable
device prototypes that can decode this information during touch interactions
using off-the-shelf sensors. We demonstrate sample applications such as
customized buttons, tactile maps, and interactive surfaces. We further
demonstrate the natural degradation of these interactive materials in degrade
outdoors within 21 days and perform a comparative environmental analysis of the
benefits of this approach.
",2024-04-04 00:47:13+00:00,cs.HC
"DNN Memory Footprint Reduction via Post-Training Intra-Layer
  Multi-Precision Quantization","  The imperative to deploy Deep Neural Network (DNN) models on
resource-constrained edge devices, spurred by privacy concerns, has become
increasingly apparent. To facilitate the transition from cloud to edge
computing, this paper introduces a technique that effectively reduces the
memory footprint of DNNs, accommodating the limitations of resource-constrained
edge devices while preserving model accuracy. Our proposed technique, named
Post-Training Intra-Layer Multi-Precision Quantization (PTILMPQ), employs a
post-training quantization approach, eliminating the need for extensive
training data. By estimating the importance of layers and channels within the
network, the proposed method enables precise bit allocation throughout the
quantization process. Experimental results demonstrate that PTILMPQ offers a
promising solution for deploying DNNs on edge devices with restricted memory
resources. For instance, in the case of ResNet50, it achieves an accuracy of
74.57\% with a memory footprint of 9.5 MB, representing a 25.49\% reduction
compared to previous similar methods, with only a minor 1.08\% decrease in
accuracy.
",2024-04-03 15:06:09+00:00,cs.LG
"Designing a Photonic Physically Unclonable Function Having Resilience to
  Machine Learning Attacks","  Physically unclonable functions (PUFs) are designed to act as device
'fingerprints.' Given an input challenge, the PUF circuit should produce an
unpredictable response for use in situations such as root-of-trust applications
and other hardware-level cybersecurity applications. PUFs are typically
subcircuits present within integrated circuits (ICs), and while conventional IC
PUFs are well-understood, several implementations have proven vulnerable to
malicious exploits, including those perpetrated by machine learning (ML)-based
attacks. Such attacks can be difficult to prevent because they are often
designed to work even when relatively few challenge-response pairs are known in
advance. Hence the need for both more resilient PUF designs and analysis of
ML-attack susceptibility. Previous work has developed a PUF for photonic
integrated circuits (PICs). A PIC PUF not only produces unpredictable responses
given manufacturing-introduced tolerances, but is also less prone to
electromagnetic radiation eavesdropping attacks than a purely electronic IC
PUF. In this work, we analyze the resilience of the proposed photonic PUF when
subjected to ML-based attacks. Specifically, we describe a computational PUF
model for producing the large datasets required for training ML attacks; we
analyze the quality of the model; and we discuss the modeled PUF's
susceptibility to ML-based attacks. We find that the modeled PUF generates
distributions that resemble uniform white noise, explaining the exhibited
resilience to neural-network-based attacks designed to exploit latent
relationships between challenges and responses. Preliminary analysis suggests
that the PUF exhibits similar resilience to generative adversarial networks,
and continued development will show whether more-sophisticated ML approaches
better compromise the PUF and -- if so -- how design modifications might
improve resilience.
",2024-04-03 03:58:21+00:00,cs.CR
"Open Experimental Measurements of Sub-6GHz Reconfigurable Intelligent
  Surfaces","  In this paper, we present two datasets that we make publicly available for
research. The data is collected in a testbed comprised of a custom-made
Reconfigurable Intelligent Surface (RIS) prototype and two regular OFDM
transceivers within an anechoic chamber. First, we discuss the details of the
testbed and equipment used, including insights about the design and
implementation of our RIS prototype. We further present the methodology we
employ to gather measurement samples, which consists of letting the RIS
electronically steer the signal reflections from an OFDM transmitter toward a
specific location. To this end, we evaluate a suitably designed configuration
codebook and collect measurement samples of the received power with an OFDM
receiver. Finally, we present the resulting datasets, their format, and
examples of exploiting this data for research purposes.
",2024-04-02 09:56:19+00:00,cs.IT
Voice EHR: Introducing Multimodal Audio Data for Health,"  Large AI models trained on audio data may have the potential to rapidly
classify patients, enhancing medical decision-making and potentially improving
outcomes through early detection. Existing technologies depend on limited
datasets using expensive recording equipment in high-income, English-speaking
countries. This challenges deployment in resource-constrained, high-volume
settings where audio data may have a profound impact. This report introduces a
novel data type and a corresponding collection system that captures health data
through guided questions using only a mobile/web application. This application
ultimately results in an audio electronic health record (voice EHR) which may
contain complex biomarkers of health from conventional voice/respiratory
features, speech patterns, and language with semantic meaning - compensating
for the typical limitations of unimodal clinical datasets. This report
introduces a consortium of partners for global work, presents the application
used for data collection, and showcases the potential of informative voice EHR
to advance the scalability and diversity of audio AI.
",2024-04-02 04:07:22+00:00,cs.SD
Classifying Cancer Stage with Open-Source Clinical Large Language Models,"  Cancer stage classification is important for making treatment and care
management plans for oncology patients. Information on staging is often
included in unstructured form in clinical, pathology, radiology and other
free-text reports in the electronic health record system, requiring extensive
work to parse and obtain. To facilitate the extraction of this information,
previous NLP approaches rely on labeled training datasets, which are
labor-intensive to prepare. In this study, we demonstrate that without any
labeled training data, open-source clinical large language models (LLMs) can
extract pathologic tumor-node-metastasis (pTNM) staging information from
real-world pathology reports. Our experiments compare LLMs and a BERT-based
model fine-tuned using the labeled data. Our findings suggest that while LLMs
still exhibit subpar performance in Tumor (T) classification, with the
appropriate adoption of prompting strategies, they can achieve comparable
performance on Metastasis (M) classification and improved performance on Node
(N) classification.
",2024-04-02 02:30:47+00:00,cs.CL
TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model,"  Clinical trials are indispensable for medical research and the development of
new treatments. However, clinical trials often involve thousands of
participants and can span several years to complete, with a high probability of
failure during the process. Recently, there has been a burgeoning interest in
virtual clinical trials, which simulate real-world scenarios and hold the
potential to significantly enhance patient safety, expedite development, reduce
costs, and contribute to the broader scientific knowledge in healthcare.
Existing research often focuses on leveraging electronic health records (EHRs)
to support clinical trial outcome prediction. Yet, trained with limited
clinical trial outcome data, existing approaches frequently struggle to perform
accurate predictions. Some research has attempted to generate EHRs to augment
model development but has fallen short in personalizing the generation for
individual patient profiles. Recently, the emergence of large language models
has illuminated new possibilities, as their embedded comprehensive clinical
knowledge has proven beneficial in addressing medical issues. In this paper, we
propose a large language model-based digital twin creation approach, called
TWIN-GPT. TWIN-GPT can establish cross-dataset associations of medical
information given limited data, generating unique personalized digital twins
for different patients, thereby preserving individual patient characteristics.
Comprehensive experiments show that using digital twins created by TWIN-GPT can
boost the clinical trial outcome prediction, exceeding various previous
prediction approaches.
",2024-04-01 17:48:55+00:00,cs.LG
"Towards System Modelling to Support Diseases Data Extraction from the
  Electronic Health Records for Physicians Research Activities","  The use of Electronic Health Records (EHRs) has increased dramatically in the
past 15 years, as, it is considered an important source of managing data od
patients. The EHRs are primary sources of disease diagnosis and demographic
data of patients worldwide. Therefore, the data can be utilized for secondary
tasks such as research. This paper aims to make such data usable for research
activities such as monitoring disease statistics for a specific population. As
a result, the researchers can detect the disease causes for the behavior and
lifestyle of the target group. One of the limitations of EHRs systems is that
the data is not available in the standard format but in various forms.
Therefore, it is required to first convert the names of the diseases and
demographics data into one standardized form to make it usable for research
activities. There is a large amount of EHRs available, and solving the
standardizing issues requires some optimized techniques. We used a first-hand
EHR dataset extracted from EHR systems. Our application uploads the dataset
from the EHRs and converts it to the ICD-10 coding system to solve the
standardization problem. So, we first apply the steps of pre-processing,
annotation, and transforming the data to convert it into the standard form. The
data pre-processing is applied to normalize demographic formats. In the
annotation step, a machine learning model is used to recognize the diseases
from the text. Furthermore, the transforming step converts the disease name to
the ICD-10 coding format. The model was evaluated manually by comparing its
performance in terms of disease recognition with an available dictionary-based
system (MetaMap). The accuracy of the proposed machine learning model is 81%,
that outperformed MetaMap accuracy of 67%. This paper contributed to system
modelling for EHR data extraction to support research activities.
",2024-04-01 16:18:40+00:00,cs.LG
"Generating Faithful and Complete Hospital-Course Summaries from the
  Electronic Health Record","  The rapid adoption of Electronic Health Records (EHRs) has been instrumental
in streamlining administrative tasks, increasing transparency, and enabling
continuity of care across providers. An unintended consequence of the increased
documentation burden, however, has been reduced face-time with patients and,
concomitantly, a dramatic rise in clinician burnout. In this thesis, we
pinpoint a particularly time-intensive, yet critical, documentation task:
generating a summary of a patient's hospital admissions, and propose and
evaluate automated solutions. In Chapter 2, we construct a dataset based on
109,000 hospitalizations (2M source notes) and perform exploratory analyses to
motivate future work on modeling and evaluation [NAACL 2021]. In Chapter 3, we
address faithfulness from a modeling perspective by revising noisy references
[EMNLP 2022] and, to reduce the reliance on references, directly calibrating
model outputs to metrics [ACL 2023]. These works relied heavily on automatic
metrics as human annotations were limited. To fill this gap, in Chapter 4, we
conduct a fine-grained expert annotation of system errors in order to
meta-evaluate existing metrics and better understand task-specific issues of
domain adaptation and source-summary alignments. To learn a metric less
correlated to extractiveness (copy-and-paste), we derive noisy faithfulness
labels from an ensemble of existing metrics and train a faithfulness classifier
on these pseudo labels [MLHC 2023]. Finally, in Chapter 5, we demonstrate that
fine-tuned LLMs (Mistral and Zephyr) are highly prone to entity hallucinations
and cover fewer salient entities. We improve both coverage and faithfulness by
performing sentence-level entity planning based on a set of pre-computed
salient entities from the source text, which extends our work on entity-guided
news summarization [ACL, 2023], [EMNLP, 2023].
",2024-04-01 15:47:21+00:00,cs.CL
"Extracting Social Determinants of Health from Pediatric Patient Notes
  Using Large Language Models: Novel Corpus and Methods","  Social determinants of health (SDoH) play a critical role in shaping health
outcomes, particularly in pediatric populations where interventions can have
long-term implications. SDoH are frequently studied in the Electronic Health
Record (EHR), which provides a rich repository for diverse patient data. In
this work, we present a novel annotated corpus, the Pediatric Social History
Annotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed
SDoH representations using fine-tuned and in-context learning methods with
Large Language Models (LLMs). PedSHAC comprises annotated social history
sections from 1,260 clinical notes obtained from pediatric patients within the
University of Washington (UW) hospital system. Employing an event-based
annotation scheme, PedSHAC captures ten distinct health determinants to
encompass living and economic stability, prior trauma, education access,
substance use history, and mental health with an overall annotator agreement of
81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance
at 78.4 F1 for event arguments. In-context learning approaches with GPT-4
demonstrate promise for reliable SDoH extraction with limited annotated
examples, with extraction performance at 82.3 F1 for event triggers.
",2024-03-31 23:37:18+00:00,cs.CL
"Weakly-Supervised Cross-Domain Segmentation of Electron Microscopy with
  Sparse Point Annotation","  Accurate segmentation of organelle instances from electron microscopy (EM)
images plays an essential role in many neuroscience researches. However,
practical scenarios usually suffer from high annotation costs, label scarcity,
and large domain diversity. While unsupervised domain adaptation (UDA) that
assumes no annotation effort on the target data is promising to alleviate these
challenges, its performance on complicated segmentation tasks is still far from
practical usage. To address these issues, we investigate a highly
annotation-efficient weak supervision, which assumes only sparse center-points
on a small subset of object instances in the target training images. To achieve
accurate segmentation with partial point annotations, we introduce instance
counting and center detection as auxiliary tasks and design a multitask
learning framework to leverage correlations among the counting, detection, and
segmentation, which are all tasks with partial or no supervision. Building upon
the different domain-invariances of the three tasks, we enforce counting
estimation with a novel soft consistency loss as a global prior for center
detection, which further guides the per-pixel segmentation. To further
compensate for annotation sparsity, we develop a cross-position cut-and-paste
for label augmentation and an entropy-based pseudo-label selection. The
experimental results highlight that, by simply using extremely weak annotation,
e.g., 15\% sparse points, for model training, the proposed model is capable of
significantly outperforming UDA methods and produces comparable performance as
the supervised counterpart. The high robustness of our model shown in the
validations and the low requirement of expert knowledge for sparse point
annotation further improve the potential application value of our model.
",2024-03-31 12:22:23+00:00,cs.CV
Denoising Low-dose Images Using Deep Learning of Time Series Images,"  Digital image devices have been widely applied in many fields, including
scientific imaging, recognition of individuals, and remote sensing. As the
application of these imaging technologies to autonomous driving and
measurement, image noise generated when observation cannot be performed with a
sufficient dose has become a major problem. Machine learning denoise technology
is expected to be the solver of this problem, but there are the following
problems. Here we report, artifacts generated by machine learning denoise in
ultra-low dose observation using an in-situ observation video of an electron
microscope as an example. And as a method to solve this problem, we propose a
method to decompose a time series image into a 2D image of the spatial axis and
time to perform machine learning denoise. Our method opens new avenues accurate
and stable reconstruction of continuous high-resolution images from low-dose
imaging in science, industry, and life.
",2024-03-31 01:05:28+00:00,cs.CV
"Leveraging Pre-trained and Transformer-derived Embeddings from EHRs to
  Characterize Heterogeneity Across Alzheimer's Disease and Related Dementias","  Alzheimer's disease is a progressive, debilitating neurodegenerative disease
that affects 50 million people globally. Despite this substantial health
burden, available treatments for the disease are limited and its fundamental
causes remain poorly understood. Previous work has suggested the existence of
clinically-meaningful sub-types, which it is suggested may correspond to
distinct etiologies, disease courses, and ultimately appropriate treatments.
Here, we use unsupervised learning techniques on electronic health records
(EHRs) from a cohort of memory disorder patients to characterise heterogeneity
in this disease population. Pre-trained embeddings for medical codes as well as
transformer-derived Clinical BERT embeddings of free text are used to encode
patient EHRs. We identify the existence of sub-populations on the basis of
comorbidities and shared textual features, and discuss their clinical
significance.
",2024-03-30 20:11:34+00:00,cs.LG
"Bespoke Large Language Models for Digital Triage Assistance in Mental
  Health Care","  Contemporary large language models (LLMs) may have utility for processing
unstructured, narrative free-text clinical data contained in electronic health
records (EHRs) -- a particularly important use-case for mental health where a
majority of routinely-collected patient data lacks structured, machine-readable
content.
  A significant problem for the the United Kingdom's National Health Service
(NHS) are the long waiting lists for specialist mental healthcare. According to
NHS data, in each month of 2023, there were between 370,000 and 470,000
individual new referrals into secondary mental healthcare services. Referrals
must be triaged by clinicians, using clinical information contained in the
patient's EHR to arrive at a decision about the most appropriate mental
healthcare team to assess and potentially treat these patients.
  The ability to efficiently recommend a relevant team by ingesting potentially
voluminous clinical notes could help services both reduce referral waiting
times and with the right technology, improve the evidence available to justify
triage decisions.
  We present and evaluate three different approaches for LLM-based, end-to-end
ingestion of variable-length clinical EHR data to assist clinicians when
triaging referrals. Our model is able to deliver triage recommendations
consistent with existing clinical practices and it's architecture was
implemented on a single GPU, making it practical for implementation in
resource-limited NHS environments where private implementations of LLM
technology will be necessary to ensure confidential clinical data is
appropriately controlled and governed.
",2024-03-28 19:17:07+00:00,cs.AI
"JDocQA: Japanese Document Question Answering Dataset for Generative
  Language Models","  Document question answering is a task of question answering on given
documents such as reports, slides, pamphlets, and websites, and it is a truly
demanding task as paper and electronic forms of documents are so common in our
society. This is known as a quite challenging task because it requires not only
text understanding but also understanding of figures and tables, and hence
visual question answering (VQA) methods are often examined in addition to
textual approaches. We introduce Japanese Document Question Answering (JDocQA),
a large-scale document-based QA dataset, essentially requiring both visual and
textual information to answer questions, which comprises 5,504 documents in PDF
format and annotated 11,600 question-and-answer instances in Japanese. Each QA
instance includes references to the document pages and bounding boxes for the
answer clues. We incorporate multiple categories of questions and unanswerable
questions from the document for realistic question-answering applications. We
empirically evaluate the effectiveness of our dataset with text-based large
language models (LLMs) and multimodal models. Incorporating unanswerable
questions in finetuning may contribute to harnessing the so-called
hallucination generation.
",2024-03-28 14:22:54+00:00,cs.CL
EDA-Driven Preprocessing for SAT Solving,"  Effective formulation of problems into Conjunctive Normal Form (CNF) is
critical in modern Boolean Satisfiability (SAT) solving for optimizing solver
performance. Addressing the limitations of existing methods, our Electronic
Design Automation (EDA)-driven preprocessing framework introduces a novel
methodology for preparing SAT instances, leveraging both circuit and CNF
formats for enhanced flexibility and efficiency. Central to our approach is the
integration of a new logic synthesis technique, guided by a reinforcement
learning agent, and a novel cost-customized LUT mapping strategy, enabling
efficient handling of diverse SAT challenges. By transforming the SAT
competition benchmarks into circuit instances, our framework demonstrates
substantial performance improvements, as evidenced by a 52.42% reduction on
average compared to solving directly. Moreover, our framework achieves a
remarkable 96.14% runtime reduction on average for a set of logic equivalence
checking problems that exhibit inherent circuit structures. These results
highlight the effectiveness and versatility of our approach in handling both
CNF and circuit instances. The code is available at
https://github.com/cure-lab/EDA4SAT.
",2024-03-28 14:15:50+00:00,cs.LO
"A Data-Driven Predictive Analysis on Cyber Security Threats with Key
  Risk Factors","  Cyber risk refers to the risk of defacing reputation, monetary losses, or
disruption of an organization or individuals, and this situation usually occurs
by the unconscious use of cyber systems. The cyber risk is unhurriedly
increasing day by day and it is right now a global threat. Developing countries
like Bangladesh face major cyber risk challenges. The growing cyber threat
worldwide focuses on the need for effective modeling to predict and manage the
associated risk. This paper exhibits a Machine Learning(ML) based model for
predicting individuals who may be victims of cyber attacks by analyzing
socioeconomic factors. We collected the dataset from victims and non-victims of
cyberattacks based on socio-demographic features. The study involved the
development of a questionnaire to gather data, which was then used to measure
the significance of features. Through data augmentation, the dataset was
expanded to encompass 3286 entries, setting the stage for our investigation and
modeling. Among several ML models with 19, 20, 21, and 26 features, we proposed
a novel Pertinent Features Random Forest (RF) model, which achieved maximum
accuracy with 20 features (95.95\%) and also demonstrated the association among
the selected features using the Apriori algorithm with Confidence (above 80\%)
according to the victim. We generated 10 important association rules and
presented the framework that is rigorously evaluated on real-world datasets,
demonstrating its potential to predict cyberattacks and associated risk factors
effectively. Looking ahead, future efforts will be directed toward refining the
predictive model's precision and delving into additional risk factors, to
fortify the proposed framework's efficacy in navigating the complex terrain of
cybersecurity threats.
",2024-03-28 09:41:24+00:00,cs.CR
"Towards Reverse-Engineering the Brain: Brain-Derived Neuromorphic
  Computing Approach with Photonic, Electronic, and Ionic Dynamicity in 3D
  integrated circuits","  The human brain has immense learning capabilities at extreme energy
efficiencies and scale that no artificial system has been able to match. For
decades, reverse engineering the brain has been one of the top priorities of
science and technology research. Despite numerous efforts, conventional
electronics-based methods have failed to match the scalability, energy
efficiency, and self-supervised learning capabilities of the human brain. On
the other hand, very recent progress in the development of new generations of
photonic and electronic memristive materials, device technologies, and 3D
electronic-photonic integrated circuits (3D EPIC ) promise to realize new
brain-derived neuromorphic systems with comparable connectivity, density,
energy-efficiency, and scalability. When combined with bio-realistic learning
algorithms and architectures, it may be possible to realize an 'artificial
brain' prototype with general self-learning capabilities. This paper argues the
possibility of reverse-engineering the brain through architecting a prototype
of a brain-derived neuromorphic computing system consisting of artificial
electronic, ionic, photonic materials, devices, and circuits with dynamicity
resembling the bio-plausible molecular, neuro/synaptic, neuro-circuit, and
multi-structural hierarchical macro-circuits of the brain based on well-tested
computational models. We further argue the importance of bio-plausible local
learning algorithms applicable to the neuromorphic computing system that
capture the flexible and adaptive unsupervised and self-supervised learning
mechanisms central to human intelligence. Most importantly, we emphasize that
the unique capabilities in brain-derived neuromorphic computing prototype
systems will enable us to understand links between specific neuronal and
network-level properties with system-level functioning and behavior.
",2024-03-28 05:24:04+00:00,cs.ET
"SolderlessPCB: Reusing Electronic Components in PCB Prototyping through
  Detachable 3D Printed Housings","  The iterative prototyping process for printed circuit boards (PCBs)
frequently employs surface-mounted device (SMD) components, which are often
discarded rather than reused due to the challenges associated with desoldering,
leading to unnecessary electronic waste. This paper introduces SolderlessPCB, a
collection of techniques for solder-free PCB prototyping, specifically designed
to promote the recycling and reuse of electronic components. Central to this
approach are custom 3D-printable housings that allow SMD components to be
mounted onto PCBs without soldering. We detail the design of SolderlessPCB and
the experiments conducted to evaluate its design parameters, electrical
performance, and durability. To illustrate the potential for reusing SMD
components with SolderlessPCB, we discuss two scenarios: the reuse of
components from earlier design iterations and from obsolete prototypes. We also
provide examples demonstrating that SolderlessPCB can handle high-current
applications and is suitable for high-speed data transmission. The paper
concludes by discussing the limitations of our approach and suggesting future
directions to overcome these challenges.
",2024-03-27 17:44:29+00:00,cs.HC
Merits of Time-Domain Computing for VMM -- A Quantitative Comparison,"  Vector-matrix-multiplication (VMM) accel-erators have gained a lot of
traction, especially due to therise of convolutional neural networks (CNNs) and
the desireto compute them on the edge. Besides the classical digitalapproach,
analog computing has gone through a renais-sance to push energy efficiency
further. A more recent ap-proach is called time-domain (TD) computing. In
contrastto analog computing, TD computing permits easy technol-ogy as well as
voltage scaling. As it has received limitedresearch attention, it is not yet
clear which scenarios aremost suitable to be computed in the TD. In this work,
weinvestigate these scenarios, focussing on energy efficiencyconsidering
approximative computations that preserve ac-curacy. Both goals are addressed by
a novel efficiency met-ric, which is used to find a baseline design. We use
SPICEsimulation data which is fed into a python framework toevaluate how
performance scales for VMM computation.We see that TD computing offers best
energy efficiency forsmall to medium sized arrays. With throughput and sili-con
footprint we investigate two additional metrics, givinga holistic comparison.
",2024-03-27 08:58:32+00:00,cs.AR
"ERIOS: Co-construction of a Dynamic Temporal Visualization Tool in the
  Electronic Health Record","  ERIOS, is a collaborative project between Dedalus, a health software company,
Montpellier University Hospital Center (CHU), and the University of
Montpellier. This initiative aims to incorporate research and development
(R\&D) directly within the hospital, focusing on co-creating components of the
Electronic Health Record (EHR) alongside end-users. The project was initiated
with two initial use cases, which led to the development of components for
dynamic temporal visualization, now integrated into specific dashboards. The
application of academic recommendations regarding user engagement methodology
and human-computer interactions significantly enhanced our ability to meet user
needs.
",2024-03-27 08:53:25+00:00,cs.HC
"Multi-Modal Contrastive Learning for Online Clinical Time-Series
  Applications","  Electronic Health Record (EHR) datasets from Intensive Care Units (ICU)
contain a diverse set of data modalities. While prior works have successfully
leveraged multiple modalities in supervised settings, we apply advanced
self-supervised multi-modal contrastive learning techniques to ICU data,
specifically focusing on clinical notes and time-series for clinically relevant
online prediction tasks. We introduce a loss function Multi-Modal Neighborhood
Contrastive Loss (MM-NCL), a soft neighborhood function, and showcase the
excellent linear probe and zero-shot performance of our approach.
",2024-03-27 07:38:36+00:00,cs.LG
"HealthGAT: Node Classifications in Electronic Health Records using Graph
  Attention Networks","  While electronic health records (EHRs) are widely used across various
applications in healthcare, most applications use the EHRs in their raw
(tabular) format. Relying on raw or simple data pre-processing can greatly
limit the performance or even applicability of downstream tasks using EHRs. To
address this challenge, we present HealthGAT, a novel graph attention network
framework that utilizes a hierarchical approach to generate embeddings from
EHR, surpassing traditional graph-based methods. Our model iteratively refines
the embeddings for medical codes, resulting in improved EHR data analysis. We
also introduce customized EHR-centric auxiliary pre-training tasks to leverage
the rich medical knowledge embedded within the data. This approach provides a
comprehensive analysis of complex medical relationships and offers significant
advancement over standard data representation techniques. HealthGAT has
demonstrated its effectiveness in various healthcare scenarios through
comprehensive evaluations against established methodologies. Specifically, our
model shows outstanding performance in node classification and downstream tasks
such as predicting readmissions and diagnosis classifications.
  Our code is available at https://github.com/healthylaife/HealthGAT
",2024-03-26 22:17:01+00:00,cs.LG
"Natural-artificial hybrid swarm: Cyborg-insect group navigation in
  unknown obstructed soft terrain","  Navigating multi-robot systems in complex terrains has always been a
challenging task. This is due to the inherent limitations of traditional robots
in collision avoidance, adaptation to unknown environments, and sustained
energy efficiency. In order to overcome these limitations, this research
proposes a solution by integrating living insects with miniature electronic
controllers to enable robotic-like programmable control, and proposing a novel
control algorithm for swarming. Although these creatures, called cyborg
insects, have the ability to instinctively avoid collisions with neighbors and
obstacles while adapting to complex terrains, there is a lack of literature on
the control of multi-cyborg systems. This research gap is due to the difficulty
in coordinating the movements of a cyborg system under the presence of insects'
inherent individual variability in their reactions to control input. In
response to this issue, we propose a novel swarm navigation algorithm
addressing these challenges. The effectiveness of the algorithm is demonstrated
through an experimental validation in which a cyborg swarm was successfully
navigated through an unknown sandy field with obstacles and hills. This
research contributes to the domain of swarm robotics and showcases the
potential of integrating biological organisms with robotics and control theory
to create more intelligent autonomous systems with real-world applications.
",2024-03-26 05:23:12+00:00,cs.RO
Extracting Biomedical Entities from Noisy Audio Transcripts,"  Automatic Speech Recognition (ASR) technology is fundamental in transcribing
spoken language into text, with considerable applications in the clinical
realm, including streamlining medical transcription and integrating with
Electronic Health Record (EHR) systems. Nevertheless, challenges persist,
especially when transcriptions contain noise, leading to significant drops in
performance when Natural Language Processing (NLP) models are applied. Named
Entity Recognition (NER), an essential clinical task, is particularly affected
by such noise, often termed the ASR-NLP gap. Prior works have primarily studied
ASR's efficiency in clean recordings, leaving a research gap concerning the
performance in noisy environments. This paper introduces a novel dataset,
BioASR-NER, designed to bridge the ASR-NLP gap in the biomedical domain,
focusing on extracting adverse drug reactions and mentions of entities from the
Brief Test of Adult Cognition by Telephone (BTACT) exam. Our dataset offers a
comprehensive collection of almost 2,000 clean and noisy recordings. In
addressing the noise challenge, we present an innovative transcript-cleaning
method using GPT4, investigating both zero-shot and few-shot methodologies. Our
study further delves into an error analysis, shedding light on the types of
errors in transcription software, corrections by GPT4, and the challenges GPT4
faces. This paper aims to foster improved understanding and potential solutions
for the ASR-NLP gap, ultimately supporting enhanced healthcare documentation
practices.
",2024-03-26 03:58:52+00:00,cs.CL
"Extracting Social Support and Social Isolation Information from Clinical
  Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language
  Model","  Background: Social support (SS) and social isolation (SI) are social
determinants of health (SDOH) associated with psychiatric outcomes. In
electronic health records (EHRs), individual-level SS/SI is typically
documented as narrative clinical notes rather than structured coded data.
Natural language processing (NLP) algorithms can automate the otherwise
labor-intensive process of data extraction.
  Data and Methods: Psychiatric encounter notes from Mount Sinai Health System
(MSHS, n=300) and Weill Cornell Medicine (WCM, n=225) were annotated and
established a gold standard corpus. A rule-based system (RBS) involving
lexicons and a large language model (LLM) using FLAN-T5-XL were developed to
identify mentions of SS and SI and their subcategories (e.g., social network,
instrumental support, and loneliness).
  Results: For extracting SS/SI, the RBS obtained higher macro-averaged
f-scores than the LLM at both MSHS (0.89 vs. 0.65) and WCM (0.85 vs. 0.82). For
extracting subcategories, the RBS also outperformed the LLM at both MSHS (0.90
vs. 0.62) and WCM (0.82 vs. 0.81).
  Discussion and Conclusion: Unexpectedly, the RBS outperformed the LLMs across
all metrics. Intensive review demonstrates that this finding is due to the
divergent approach taken by the RBS and LLM. The RBS were designed and refined
to follow the same specific rules as the gold standard annotations. Conversely,
the LLM were more inclusive with categorization and conformed to common
English-language understanding. Both approaches offer advantages and are made
available open-source for future testing.
",2024-03-25 21:19:50+00:00,cs.CL
"Symbolic and User-friendly Geometric Algebra Routines (SUGAR) for
  Computations in Matlab","  Geometric algebra (GA) is a mathematical tool for geometric computing,
providing a framework that allows a unified and compact approach to geometric
relations which in other mathematical systems are typically described using
different more complicated elements. This fact has led to an increasing
adoption of GA in applied mathematics and engineering problems. However, the
scarcity of symbolic implementations of GA and its inherent complexity,
requiring a specific mathematical background, make it challenging and less
intuitive for engineers to work with. This prevents wider adoption among more
applied professionals. To address this challenge, this paper introduces SUGAR
(Symbolic and User-friendly Geometric Algebra Routines), an open-source toolbox
designed for Matlab and licensed under the MIT License. SUGAR facilitates the
translation of GA concepts into Matlab and provides a collection of
user-friendly functions tailored for GA computations, including support for
symbolic operations. It supports both numeric and symbolic computations in
high-dimensional GAs. Specifically tailored for applied mathematics and
engineering applications, SUGAR has been meticulously engineered to represent
geometric elements and transformations within two and three-dimensional
projective and conformal geometric algebras, aligning with established
computational methodologies in the literature. Furthermore, SUGAR efficiently
handles functions of multivectors, such as exponential, logarithmic,
sinusoidal, and cosine functions, enhancing its applicability across various
engineering domains, including robotics, control systems, and power
electronics. Finally, this work includes four distinct validation examples,
demonstrating SUGAR's capabilities across the above-mentioned fields and its
practical utility in addressing real-world applied mathematics and engineering
problems.
",2024-03-25 11:22:38+00:00,cs.MS
"An Experiment with the Use of ChatGPT for LCSH Subject Assignment on
  Electronic Theses and Dissertations","  This study delves into the potential use of large language models (LLMs) for
generating Library of Congress Subject Headings (LCSH). The authors employed
ChatGPT to generate subject headings for electronic theses and dissertations
(ETDs) based on their titles and abstracts. The results suggests that LLMs such
as ChatGPT have the potential to reduce cataloging time needed for assigning
LCSH subject terms for ETDs as well as to improve the discovery of this type of
resource in academic libraries. Nonetheless, human catalogers remain essential
for verifying and enhancing the validity, exhaustivity, and specificity of LCSH
generated by LLMs.
",2024-03-25 05:04:52+00:00,cs.AI
"Electron-Tunnelling-Noise Programmable Random Variate Accelerator for
  Monte Carlo Sampling","  This article presents an electron tunneling noise programmable random variate
accelerator for accelerating the sampling stage of Monte Carlo simulations. We
used the LiteX framework to generate a FemtoRV imfc RISC-V instruction set soft
processor and deploy it on a Digilent Arty-100T FPGA development board. The
RISC-V soft processor augmented with our programmable random variate
accelerator achieves an average speedup of 8.70 times and a median speedup of
8.68 times for a suite of twelve different benchmark applications when compared
to GNU Scientific Library software random number generation. These speedups are
achievable because the benchmarks spend an average of 90.0 % of their execution
time generating random samples. The results of the Monte Carlo benchmark
programs run over the programmable random variate accelerator have an average
Wasserstein distance of 1.48 times and a median Wasserstein distance of 1.41
times that of the results produced by the GNU Scientific Library random number
generators. The soft processor samples the electron tunneling noise source
using the hardened XADC block in the FPGA. The flexibility of the LiteX
framework allows for the deployment of any LiteX-supported soft processor with
an electron tunneling noise programmable random variate accelerator on any
LiteX-supported development board that contains an FPGA with an XADC.
",2024-03-25 04:50:02+00:00,cs.AR
"MRC-based Nested Medical NER with Co-prediction and Adaptive
  Pre-training","  In medical information extraction, medical Named Entity Recognition (NER) is
indispensable, playing a crucial role in developing medical knowledge graphs,
enhancing medical question-answering systems, and analyzing electronic medical
records. The challenge in medical NER arises from the complex nested structures
and sophisticated medical terminologies, distinguishing it from its
counterparts in traditional domains. In response to these complexities, we
propose a medical NER model based on Machine Reading Comprehension (MRC), which
uses a task-adaptive pre-training strategy to improve the model's capability in
the medical field. Meanwhile, our model introduces multiple word-pair
embeddings and multi-granularity dilated convolution to enhance the model's
representation ability and uses a combined predictor of Biaffine and MLP to
improve the model's recognition performance. Experimental evaluations conducted
on the CMeEE, a benchmark for Chinese nested medical NER, demonstrate that our
proposed model outperforms the compared state-of-the-art (SOTA) models.
",2024-03-23 11:14:02+00:00,cs.CL
Towards a RAG-based Summarization Agent for the Electron-Ion Collider,"  The complexity and sheer volume of information encompassing documents,
papers, data, and other resources from large-scale experiments demand
significant time and effort to navigate, making the task of accessing and
utilizing these varied forms of information daunting, particularly for new
collaborators and early-career scientists. To tackle this issue, a Retrieval
Augmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under
development. This AI-Agent not only condenses information but also effectively
references relevant responses, offering substantial advantages for
collaborators. Our project involves a two-step approach: first, querying a
comprehensive vector database containing all pertinent experiment information;
second, utilizing a Large Language Model (LLM) to generate concise summaries
enriched with citations based on user queries and retrieved data. We describe
the evaluation methods that use RAG assessments (RAGAs) scoring mechanisms to
assess the effectiveness of responses. Furthermore, we describe the concept of
prompt template-based instruction-tuning which provides flexibility and
accuracy in summarization. Importantly, the implementation relies on LangChain,
which serves as the foundation of our entire workflow. This integration ensures
efficiency and scalability, facilitating smooth deployment and accessibility
for various user groups within the Electron Ion Collider (EIC) community. This
innovative AI-driven framework not only simplifies the understanding of vast
datasets but also encourages collaborative participation, thereby empowering
researchers. As a demonstration, a web application has been developed to
explain each stage of the RAG Agent development in detail.
",2024-03-23 05:32:46+00:00,cs.CL
"An Interactive Decision-Support Dashboard for Optimal Hospital Capacity
  Management","  Data-driven optimization models have the potential to significantly improve
hospital capacity management, particularly during demand surges, when effective
allocation of capacity is most critical and challenging. However, integrating
models into existing processes in a way that provides value requires
recognizing that hospital administrators are ultimately responsible for making
capacity management decisions, and carefully building trustworthy and
accessible tools for them. In this study, we develop an interactive,
user-friendly, electronic dashboard for informing hospital capacity management
decisions during surge periods. The dashboard integrates real-time hospital
data, predictive analytics, and optimization models. It allows hospital
administrators to interactively customize parameters, enabling them to explore
a range of scenarios, and provides real-time updates on recommended optimal
decisions. The dashboard was created through a participatory design process,
involving hospital administrators in the development team to ensure practical
utility, trustworthiness, transparency, explainability, and usability. We
successfully deployed our dashboard within the Johns Hopkins Health System
during the height of the COVID-19 pandemic, addressing the increased need for
tools to inform hospital capacity management. It was used on a daily basis,
with results regularly communicated to hospital leadership. This study
demonstrates the practical application of a prospective, data-driven,
interactive decision-support tool for hospital system capacity management.
",2024-03-22 22:13:18+00:00,cs.CY
MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis,"  Chest X-ray images are commonly used for predicting acute and chronic
cardiopulmonary conditions, but efforts to integrate them with structured
clinical data face challenges due to incomplete electronic health records
(EHR). This paper introduces MedPromptX, the first model to integrate
multimodal large language models (MLLMs), few-shot prompting (FP) and visual
grounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A
pre-trained MLLM is utilized to complement the missing EHR information,
providing a comprehensive understanding of patients' medical history.
Additionally, FP reduces the necessity for extensive training of MLLMs while
effectively tackling the issue of hallucination. Nevertheless, the process of
determining the optimal number of few-shot examples and selecting high-quality
candidates can be burdensome, yet it profoundly influences model performance.
Hence, we propose a new technique that dynamically refines few-shot data for
real-time adjustment to new patient scenarios. Moreover, VG aids in focusing
the model's attention on relevant regions of interest in X-ray images,
enhancing the identification of abnormalities. We release MedPromptX-VQA, a new
in-context visual question answering dataset encompassing interleaved image and
EHR data derived from MIMIC-IV and MIMIC-CXR databases. Results demonstrate the
SOTA performance of MedPromptX, achieving an 11% improvement in F1-score
compared to the baselines. Code and data are available at
https://github.com/BioMedIA-MBZUAI/MedPromptX
",2024-03-22 19:19:51+00:00,cs.CV
Experimental Studies of Metaverse Streaming,"  Metaverse aims to construct a large, unified, immersive, and shared digital
realm by combining various technologies, namely XR (extended reality),
blockchain, and digital twin, among others. This article explores the Metaverse
from the perspective of multimedia communication by conducting and analyzing
real-world experiments on four different Metaverse platforms: VR (virtual
reality) Vircadia, VR Mozilla Hubs, VRChat, and MR (mixed reality) Virtual
City. We first investigate the traffic patterns and network performance in the
three VR platforms. After raising the challenges of the Metaverse streaming and
investigating the potential methods to enhance Metaverse performance, we
propose a remote rendering architecture and verify its advantages through a
prototype involving the campus network and MR multimodal interaction by
comparison with local rendering.
",2024-03-22 14:57:12+00:00,cs.MM
Range-Angle Estimation for FDA-MIMO System With Frequency Offset,"  Frequency diverse array multiple-input multiple-output (FDA-MIMO) radar
differs from the traditional phased array (PA) radar, and can form
range-angle-dependent beampattern and differentiate between closely spaced
targets sharing the same angle but occupying distinct range cells. In the
FDA-MIMO radar, target range estimation is achieved by employing a subtle
frequency variation between adjacent array antennas, so the estimation
performance is degraded severely in a practical scenario with frequency offset.
In this paper, the range-angle estimation problem for FDA-MIMO radar is
considered with frequency offsets in both transmitting and receiving arrays.
First, we build a system model for the FDA-MIMO radar with transmitting and
receiving frequency offsets. Then, the frequency offset is transferred into an
equalized additional noise. The noise characteristics are analyzed in detail
theoretically, together with the influence on the range-angle estimation.
Moreover, since the effect of the transmitting frequency offset is similar to
additional colored noise, denoising algorithms are introduced to mitigate the
performance deterioration caused by the frequency offset. Finally,
Cram\'{e}r-Rao lower bounds (CRLB) for the range-angle estimation are derived
in the scenario with the frequency offsets. Simulation results show the
analysis of frequency offset and the corresponding estimation performance using
different algorithms.
",2024-03-22 06:22:34+00:00,cs.IT
"Photonic-Electronic Integrated Circuits for High-Performance Computing
  and AI Accelerators","  In recent decades, the demand for computational power has surged,
particularly with the rapid expansion of artificial intelligence (AI). As we
navigate the post-Moore's law era, the limitations of traditional electrical
digital computing, including process bottlenecks and power consumption issues,
are propelling the search for alternative computing paradigms. Among various
emerging technologies, integrated photonics stands out as a promising solution
for next-generation high-performance computing, thanks to the inherent
advantages of light, such as low latency, high bandwidth, and unique
multiplexing techniques. Furthermore, the progress in photonic integrated
circuits (PICs), which are equipped with abundant photoelectronic components,
positions photonic-electronic integrated circuits as a viable solution for
high-performance computing and hardware AI accelerators. In this review, we
survey recent advancements in both PIC-based digital and analog computing for
AI, exploring the principal benefits and obstacles of implementation.
Additionally, we propose a comprehensive analysis of photonic AI from the
perspectives of hardware implementation, accelerator architecture, and
software-hardware co-design. In the end, acknowledging the existing challenges,
we underscore potential strategies for overcoming these issues and offer
insights into the future drivers for optical computing.
",2024-03-21 19:38:05+00:00,cs.ET
"The Ethics of ChatGPT in Medicine and Healthcare: A Systematic Review on
  Large Language Models (LLMs)","  With the introduction of ChatGPT, Large Language Models (LLMs) have received
enormous attention in healthcare. Despite their potential benefits, researchers
have underscored various ethical implications. While individual instances have
drawn much attention, the debate lacks a systematic overview of practical
applications currently researched and ethical issues connected to them. Against
this background, this work aims to map the ethical landscape surrounding the
current stage of deployment of LLMs in medicine and healthcare. Electronic
databases and preprint servers were queried using a comprehensive search
strategy. Studies were screened and extracted following a modified rapid review
approach. Methodological quality was assessed using a hybrid approach. For 53
records, a meta-aggregative synthesis was performed. Four fields of
applications emerged and testify to a vivid exploration phase. Advantages of
using LLMs are attributed to their capacity in data analysis, personalized
information provisioning, support in decision-making, mitigating information
loss and enhancing information accessibility. However, we also identifies
recurrent ethical concerns connected to fairness, bias, non-maleficence,
transparency, and privacy. A distinctive concern is the tendency to produce
harmful misinformation or convincingly but inaccurate content. A recurrent plea
for ethical guidance and human oversight is evident. Given the variety of use
cases, it is suggested that the ethical guidance debate be reframed to focus on
defining what constitutes acceptable human oversight across the spectrum of
applications. This involves considering diverse settings, varying potentials
for harm, and different acceptable thresholds for performance and certainty in
healthcare. In addition, a critical inquiry is necessary to determine the
extent to which the current experimental use of LLMs is necessary and
justified.
",2024-03-21 15:20:07+00:00,cs.CY
Bringing Robots Home: The Rise of AI Robots in Consumer Electronics,"  On March 18, 2024, NVIDIA unveiled Project GR00T, a general-purpose
multimodal generative AI model designed specifically for training humanoid
robots. Preceding this event, Tesla's unveiling of the Optimus Gen 2 humanoid
robot on December 12, 2023, underscored the profound impact robotics is poised
to have on reshaping various facets of our daily lives. While robots have long
dominated industrial settings, their presence within our homes is a burgeoning
phenomenon. This can be attributed, in part, to the complexities of domestic
environments and the challenges of creating robots that can seamlessly
integrate into our daily routines.
",2024-03-21 14:56:46+00:00,cs.RO
"Accelerating Time-to-Science by Streaming Detector Data Directly into
  Perlmutter Compute Nodes","  Recent advancements in detector technology have significantly increased the
size and complexity of experimental data, and high-performance computing (HPC)
provides a path towards more efficient and timely data processing. However,
movement of large data sets from acquisition systems to HPC centers introduces
bottlenecks owing to storage I/O at both ends. This manuscript introduces a
streaming workflow designed for an high data rate electron detector that
streams data directly to compute node memory at the National Energy Research
Scientific Computing Center (NERSC), thereby avoiding storage I/O. The new
workflow deploys ZeroMQ-based services for data production, aggregation, and
distribution for on-the-fly processing, all coordinated through a distributed
key-value store. The system is integrated with the detector's science gateway
and utilizes the NERSC Superfacility API to initiate streaming jobs through a
web-based frontend. Our approach achieves up to a 14-fold increase in data
throughput and enhances predictability and reliability compared to a I/O-heavy
file-based transfer workflow. Our work highlights the transformative potential
of streaming workflows to expedite data analysis for time-sensitive
experiments.
",2024-03-21 12:28:24+00:00,cs.NI
"Adversarial Attacks and Defenses in Fault Detection and Diagnosis: A
  Comprehensive Benchmark on the Tennessee Eastman Process","  Integrating machine learning into Automated Control Systems (ACS) enhances
decision-making in industrial process management. One of the limitations to the
widespread adoption of these technologies in industry is the vulnerability of
neural networks to adversarial attacks. This study explores the threats in
deploying deep learning models for fault diagnosis in ACS using the Tennessee
Eastman Process dataset. By evaluating three neural networks with different
architectures, we subject them to six types of adversarial attacks and explore
five different defense methods. Our results highlight the strong vulnerability
of models to adversarial samples and the varying effectiveness of defense
strategies. We also propose a novel protection approach by combining multiple
defense methods and demonstrate it's efficacy. This research contributes
several insights into securing machine learning within ACS, ensuring robust
fault diagnosis in industrial processes.
",2024-03-20 10:59:06+00:00,cs.LG
"HyperFusion: A Hypernetwork Approach to Multimodal Integration of
  Tabular and Medical Imaging Data for Predictive Modeling","  The integration of diverse clinical modalities such as medical imaging and
the tabular data obtained by the patients' Electronic Health Records (EHRs) is
a crucial aspect of modern healthcare. The integrative analysis of multiple
sources can provide a comprehensive understanding of a patient's condition and
can enhance diagnoses and treatment decisions. Deep Neural Networks (DNNs)
consistently showcase outstanding performance in a wide range of multimodal
tasks in the medical domain. However, the complex endeavor of effectively
merging medical imaging with clinical, demographic and genetic information
represented as numerical tabular data remains a highly active and ongoing
research pursuit.
  We present a novel framework based on hypernetworks to fuse clinical imaging
and tabular data by conditioning the image processing on the EHR's values and
measurements. This approach aims to leverage the complementary information
present in these modalities to enhance the accuracy of various medical
applications. We demonstrate the strength and the generality of our method on
two different brain Magnetic Resonance Imaging (MRI) analysis tasks, namely,
brain age prediction conditioned by subject's sex, and multiclass Alzheimer's
Disease (AD) classification conditioned by tabular data. We show that our
framework outperforms both single-modality models and state-of-the-art
MRI-tabular data fusion methods. The code, enclosed to this manuscript will be
made publicly available.
",2024-03-20 05:50:04+00:00,cs.CV
"LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
  Combining Predictive Agent Reasoning and Critical Agent Instruction","  Electronic health records (EHRs) contain valuable patient data for
health-related prediction tasks, such as disease prediction. Traditional
approaches rely on supervised learning methods that require large labeled
datasets, which can be expensive and challenging to obtain. In this study, we
investigate the feasibility of applying Large Language Models (LLMs) to convert
structured patient visit data (e.g., diagnoses, labs, prescriptions) into
natural language narratives. We evaluate the zero-shot and few-shot performance
of LLMs using various EHR-prediction-oriented prompting strategies.
Furthermore, we propose a novel approach that utilizes LLM agents with
different roles: a predictor agent that makes predictions and generates
reasoning processes and a critic agent that analyzes incorrect predictions and
provides guidance for improving the reasoning of the predictor agent. Our
results demonstrate that with the proposed approach, LLMs can achieve decent
few-shot performance compared to traditional supervised learning methods in
EHR-based disease predictions, suggesting its potential for health-oriented
applications.
",2024-03-19 18:10:13+00:00,cs.CL
MEDBind: Unifying Language and Multimodal Medical Data Embeddings,"  Medical vision-language pretraining models (VLPM) have achieved remarkable
progress in fusing chest X-rays (CXR) with clinical texts, introducing
image-text data binding approaches that enable zero-shot learning and
downstream clinical tasks. However, the current landscape lacks the holistic
integration of additional medical modalities, such as electrocardiograms (ECG).
We present MEDBind (Medical Electronic patient recorD), which learns joint
embeddings across CXR, ECG, and medical text. Using text data as the central
anchor, MEDBind features tri-modality binding, delivering competitive
performance in top-K retrieval, zero-shot, and few-shot benchmarks against
established VLPM, and the ability for CXR-to-ECG zero-shot classification and
retrieval. This seamless integration is achieved through combination of
contrastive loss on modality-text pairs with our proposed contrastive loss
function, Edge-Modality Contrastive Loss, fostering a cohesive embedding space
for CXR, ECG, and text. Finally, we demonstrate that MEDBind can improve
downstream tasks by directly integrating CXR and ECG embeddings into a
large-language model for multimodal prompt tuning.
",2024-03-19 16:46:29+00:00,cs.CV
"Freshness-aware Block Propagation Optimization in 6G-based Web 3.0: An
  Evolutionary Game Approach","  Driven by the aspiration to establish a decentralized digital economy, Web
3.0 is emerging as the fundamental technology for digital transformation.
Incorporating the promising sixth-generation (6G) technology with large
bandwidth and space-air-ground integrated coverage, 6G-based Web 3.0 holds
great potential in empowering users with enhanced data control and facilitating
secure peer-to-peer transactions, especially in consumer electronics, through
the utilization of blockchain technologies. However, 6G-based Web 3.0 is still
in its infancy, such as ensuring block freshness and optimizing block
propagation to improve blockchain performance. In this paper, we develop a
freshness-aware block propagation optimization framework for 6G-based Web 3.0.
We first propose a novel metric called Age of Block Information (AoBI) based on
the concept of age of information to quantify block freshness. To make block
propagation optimization tractable, we classify miners into five different
states and propose a block propagation model for public blockchains inspired by
epidemic models. Moreover, considering that the miners are bounded rational, we
propose an incentive mechanism based on the evolutionary game for block
propagation to improve block propagation efficiency. Numerical results
demonstrate that compared with other block propagation mechanisms, the proposed
scheme has a higher block forwarding probability, which improves block
propagation efficiency.
",2024-03-19 15:07:12+00:00,cs.GT
Individual and Product-Related Antecedents of Electronic Word-of-Mouth,"  This research investigates the antecedents of positive and negative
electronic word-of-mouth (eWOM) propensity, as well as the impact of eWOM
propensity on the intention to repurchase the product. Two types of eWOM
predictors were considered: product related variables and personal factors. The
data were collected through an online survey conducted on a sample of 335
Romanian subjects, and the analysis method was Structural Equation Modeling.
Our findings show that personal factors - social media usage behavior,
marketing mavenism and need to evaluate - are the most important antecedents of
the intention to write product reviews and comments online, either positive or
negative. From the product related factors, only brand trust influences the
propensity to provide eWOM. Furthermore, both positive and negative eWOM
intentions are associated with the repurchase intention.
",2024-03-19 07:50:26+00:00,cs.CY
WoLF: Wide-scope Large Language Model Framework for CXR Understanding,"  Significant methodological strides have been made toward Chest X-ray (CXR)
understanding via modern vision-language models (VLMs), demonstrating
impressive Visual Question Answering (VQA) and CXR report generation abilities.
However, existing CXR understanding frameworks still possess several procedural
caveats. (1) Previous methods solely use CXR reports, which are insufficient
for comprehensive Visual Question Answering (VQA), especially when additional
health-related data like medication history and prior diagnoses are needed. (2)
Previous methods use raw CXR reports, which are often arbitrarily structured.
While modern language models can understand various text formats, restructuring
reports for clearer, organized anatomy-based information could enhance their
usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize
linguistic correctness, lacking the capability to offer nuanced assessments of
the generated answers. In this work, to address the aforementioned caveats, we
introduce WoLF, a Wide-scope Large Language Model Framework for CXR
understanding. To resolve (1), we capture multi-faceted records of patients,
which are utilized for accurate diagnoses in real-world clinical scenarios.
Specifically, we adopt the Electronic Health Records (EHR) to generate
instruction-following data suited for CXR understanding. Regarding (2), we
enhance report generation performance by decoupling knowledge in CXR reports
based on anatomical structure even within the attention step via masked
attention. To address (3), we introduce an AI-evaluation protocol optimized for
assessing the capabilities of LLM. Through extensive experimental validations,
WoLF demonstrates superior performance over other models on MIMIC-CXR in the
AI-evaluation arena about VQA (up to +9.47%p mean score) and by metrics about
report generation (+7.3%p BLEU-1).
",2024-03-19 06:39:23+00:00,cs.AI
Parasitic Circus:On the Feasibility of Golden Free PCB Verification,"  Printed circuit boards (PCBs) are an integral part of electronic systems.
Hence, verifying their physical integrity in the presence of supply chain
attacks (e.g., tampering and counterfeiting) is of utmost importance. Recently,
tamper detection techniques grounded in impedance characterization of PCB's
Power Delivery Network (PDN) have gained prominence due to their global
detection coverage, non-invasive, and low-cost nature. Similar to other
physical verification methods, these techniques rely on the existence of a
physical golden sample for signature comparisons. However, having access to a
physical golden sample for golden signature extraction is not feasible in many
real-world scenarios. In this work, we assess the feasibility of eliminating a
physical golden sample and replacing it with a simulated golden signature
obtained by the PCB design files. By performing extensive simulation and
measurements on an in-house designed PCB, we demonstrate how the parasitic
impedance of the PCB components plays a major role in reaching a successful
verification. Based on the obtained results and using statistical metrics, we
show that we can mitigate the discrepancy between collected signatures from
simulation and measurements.
",2024-03-18 21:04:02+00:00,cs.CR
"Narrative Feature or Structured Feature? A Study of Large Language
  Models to Identify Cancer Patients at Risk of Heart Failure","  Cancer treatments are known to introduce cardiotoxicity, negatively impacting
outcomes and survivorship. Identifying cancer patients at risk of heart failure
(HF) is critical to improving cancer treatment outcomes and safety. This study
examined machine learning (ML) models to identify cancer patients at risk of HF
using electronic health records (EHRs), including traditional ML, Time-Aware
long short-term memory (T-LSTM), and large language models (LLMs) using novel
narrative features derived from the structured medical codes. We identified a
cancer cohort of 12,806 patients from the University of Florida Health,
diagnosed with lung, breast, and colorectal cancers, among which 1,602
individuals developed HF after cancer. The LLM, GatorTron-3.9B, achieved the
best F1 scores, outperforming the traditional support vector machines by 39%,
the T-LSTM deep learning model by 7%, and a widely used transformer model,
BERT, by 5.6%. The analysis shows that the proposed narrative features
remarkably increased feature density and improved performance.
",2024-03-18 02:42:01+00:00,cs.LG
"Data is all you need: Finetuning LLMs for Chip Design via an Automated
  design-data augmentation framework","  Recent advances in large language models have demonstrated their potential
for automated generation of hardware description language (HDL) code from
high-level prompts. Researchers have utilized fine-tuning to enhance the
ability of these large language models (LLMs) in the field of Chip Design.
However, the lack of Verilog data hinders further improvement in the quality of
Verilog generation by LLMs. Additionally, the absence of a Verilog and
Electronic Design Automation (EDA) script data augmentation framework
significantly increases the time required to prepare the training dataset for
LLM trainers. This paper proposes an automated design-data augmentation
framework, which generates high-volume and high-quality natural language
aligned with Verilog and EDA scripts. For Verilog generation, it translates
Verilog files to an abstract syntax tree and then maps nodes to natural
language with a predefined template. For Verilog repair, it uses predefined
rules to generate the wrong verilog file and then pairs EDA Tool feedback with
the right and wrong verilog file. For EDA Script generation, it uses existing
LLM(GPT-3.5) to obtain the description of the Script. To evaluate the
effectiveness of our data augmentation method, we finetune Llama2-13B and
Llama2-7B models using the dataset generated by our augmentation framework. The
results demonstrate a significant improvement in the Verilog generation tasks
with LLMs. Moreover, the accuracy of Verilog generation surpasses that of the
current state-of-the-art open-source Verilog generation model, increasing from
58.8% to 70.6% with the same benchmark. Our 13B model (ChipGPT-FT) has a pass
rate improvement compared with GPT-3.5 in Verilog generation and outperforms in
EDA script (i.e., SiliconCompiler) generation with only 200 EDA script data.
",2024-03-17 13:01:03+00:00,cs.AR
Fuzzy Rank-based Late Fusion Technique for Cytology image Segmentation,"  Cytology image segmentation is quite challenging due to its complex cellular
structure and multiple overlapping regions. On the other hand, for supervised
machine learning techniques, we need a large amount of annotated data, which is
costly. In recent years, late fusion techniques have given some promising
performances in the field of image classification. In this paper, we have
explored a fuzzy-based late fusion techniques for cytology image segmentation.
This fusion rule integrates three traditional semantic segmentation models
UNet, SegNet, and PSPNet. The technique is applied on two cytology image
datasets, i.e., cervical cytology(HErlev) and breast cytology(JUCYT-v1) image
datasets. We have achieved maximum MeanIoU score 84.27% and 83.79% on the
HErlev dataset and JUCYT-v1 dataset after the proposed late fusion technique,
respectively which are better than that of the traditional fusion rules such as
average probability, geometric mean, Borda Count, etc. The codes of the
proposed model are available on GitHub.
",2024-03-16 10:33:02+00:00,cs.CV
"SurvRNC: Learning Ordered Representations for Survival Prediction using
  Rank-N-Contrast","  Predicting the likelihood of survival is of paramount importance for
individuals diagnosed with cancer as it provides invaluable information
regarding prognosis at an early stage. This knowledge enables the formulation
of effective treatment plans that lead to improved patient outcomes. In the
past few years, deep learning models have provided a feasible solution for
assessing medical images, electronic health records, and genomic data to
estimate cancer risk scores. However, these models often fall short of their
potential because they struggle to learn regression-aware feature
representations. In this study, we propose Survival Rank-N Contrast (SurvRNC)
method, which introduces a loss function as a regularizer to obtain an ordered
representation based on the survival times. This function can handle censored
data and can be incorporated into any survival model to ensure that the learned
representation is ordinal. The model was extensively evaluated on a HEad \&
NeCK TumOR (HECKTOR) segmentation and the outcome-prediction task dataset. We
demonstrate that using the SurvRNC method for training can achieve higher
performance on different deep survival models. Additionally, it outperforms
state-of-the-art methods by 3.6% on the concordance index. The code is publicly
available on https://github.com/numanai/SurvRNC
",2024-03-15 18:00:11+00:00,cs.CV
"Deep Learning for Multi-Level Detection and Localization of Myocardial
  Scars Based on Regional Strain Validated on Virtual Patients","  How well the heart is functioning can be quantified through measurements of
myocardial deformation via echocardiography. Clinical assessment of cardiac
function is generally focused on global indices of relative shortening,
however, territorial, and segmental strain indices have shown to be abnormal in
regions of myocardial disease, such as scar. In this work, we propose a single
framework to predict myocardial disease substrates at global, territorial, and
segmental levels using regional myocardial strain traces as input to a
convolutional neural network (CNN)-based classification algorithm. An
anatomically meaningful representation of the input data from the clinically
standard bullseye representation to a multi-channel 2D image is proposed, to
formulate the task as an image classification problem, thus enabling the use of
state-of-the-art neural network configurations. A Fully Convolutional Network
(FCN) is trained to detect and localize myocardial scar from regional left
ventricular (LV) strain patterns. Simulated regional strain data from a
controlled dataset of virtual patients with varying degrees and locations of
myocardial scar is used for training and validation. The proposed method
successfully detects and localizes the scars on 98% of the 5490 left ventricle
(LV) segments of the 305 patients in the test set using strain traces only. Due
to the sparse existence of scar, only 10% of the LV segments in the virtual
patient cohort have scar. Taking the imbalance into account, the class balanced
accuracy is calculated as 95%. The performance is reported on global,
territorial, and segmental levels. The proposed method proves successful on the
strain traces of the virtual cohort and offers the potential to solve the
regional myocardial scar detection problem on the strain traces of the real
patient cohorts.
",2024-03-15 13:31:33+00:00,cs.CV
"Identifying Health Risks from Family History: A Survey of Natural
  Language Processing Techniques","  Electronic health records include information on patients' status and medical
history, which could cover the history of diseases and disorders that could be
hereditary. One important use of family history information is in precision
health, where the goal is to keep the population healthy with preventative
measures. Natural Language Processing (NLP) and machine learning techniques can
assist with identifying information that could assist health professionals in
identifying health risks before a condition is developed in their later years,
saving lives and reducing healthcare costs.
  We survey the literature on the techniques from the NLP field that have been
developed to utilise digital health records to identify risks of familial
diseases. We highlight that rule-based methods are heavily investigated and are
still actively used for family history extraction. Still, more recent efforts
have been put into building neural models based on large-scale pre-trained
language models. In addition to the areas where NLP has successfully been
utilised, we also identify the areas where more research is needed to unlock
the value of patients' records regarding data collection, task formulation and
downstream applications.
",2024-03-15 03:43:07+00:00,cs.CL
"Blockchain-enabled Circular Economy -- Collaborative Responsibility in
  Solar Panel Recycling","  The adoption of renewable energy resources, such as solar power, is on the
rise. However, the excessive installation and lack of recycling facilities pose
environmental risks. This paper suggests a circular economy approach to address
the issue. By implementing blockchain technology, the end-of-life (EOL) of
solar panels can be tracked, and responsibilities can be assigned to relevant
stakeholders. The degradation of panels can be monetized by tracking users'
energy-related activities, and these funds can be used for future recycling. A
new coin, the recycling coin (RC-Coin), incentivizes solar panel recycling and
utilizes decentralized finance to stabilize the coin price and supply issue.
",2024-03-15 00:36:59+00:00,cs.ET
"More than words: Advancements and challenges in speech recognition for
  singing","  This paper addresses the challenges and advancements in speech recognition
for singing, a domain distinctly different from standard speech recognition.
Singing encompasses unique challenges, including extensive pitch variations,
diverse vocal styles, and background music interference. We explore key areas
such as phoneme recognition, language identification in songs, keyword
spotting, and full lyrics transcription. I will describe some of my own
experiences when performing research on these tasks just as they were starting
to gain traction, but will also show how recent developments in deep learning
and large-scale datasets have propelled progress in this field. My goal is to
illuminate the complexities of applying speech recognition to singing, evaluate
current capabilities, and outline future research directions.
",2024-03-14 11:37:02+00:00,cs.SD
"Retrieval augmented text-to-SQL generation for epidemiological question
  answering using electronic health records","  Electronic health records (EHR) and claims data are rich sources of
real-world data that reflect patient health status and healthcare utilization.
Querying these databases to answer epidemiological questions is challenging due
to the intricacy of medical terminology and the need for complex SQL queries.
Here, we introduce an end-to-end methodology that combines text-to-SQL
generation with retrieval augmented generation (RAG) to answer epidemiological
questions using EHR and claims data. We show that our approach, which
integrates a medical coding step into the text-to-SQL process, significantly
improves the performance over simple prompting. Our findings indicate that
although current language models are not yet sufficiently accurate for
unsupervised use, RAG offers a promising direction for improving their
capabilities, as shown in a realistic industry setting.
",2024-03-14 09:45:05+00:00,cs.CL
"Circuit Transformer: End-to-end Circuit Design by Predicting the Next
  Gate","  Language, a prominent human ability to express through sequential symbols,
has been computationally mastered by recent advances of large language models
(LLMs). By predicting the next word recurrently with huge neural models, LLMs
have shown unprecedented capabilities in understanding and reasoning. Circuit,
as the ""language"" of electronic design, specifies the functionality of an
electronic device by cascade connections of logic gates. Then, can circuits
also be mastered by a a sufficiently large ""circuit model"", which can conquer
electronic design tasks by simply predicting the next logic gate? In this work,
we take the first step to explore such possibilities. Two primary barriers
impede the straightforward application of LLMs to circuits: their complex,
non-sequential structure, and the intolerance of hallucination due to strict
constraints (e.g., equivalence). For the first barrier, we encode a circuit as
a memory-less, depth-first traversal trajectory, which allows Transformer-based
neural models to better leverage its structural information, and predict the
next gate on the trajectory as a circuit model. For the second barrier, we
introduce an equivalence-preserving decoding process, which ensures that every
token in the generated trajectory adheres to the specified equivalence
constraints. Moreover, the circuit model can also be regarded as a stochastic
policy to tackle optimization-oriented circuit design tasks. Experimentally, we
trained a Transformer-based model of 88M parameters, named ""Circuit
Transformer"", which demonstrates impressive performance in end-to-end logic
synthesis. With Monte-Carlo tree search, Circuit Transformer significantly
improves over resyn2 while retaining strict equivalence, showcasing the
potential of generative AI in conquering electronic design challenges.
",2024-03-14 03:24:14+00:00,cs.LG
"Machine Learning Optimized Orthogonal Basis Piecewise Polynomial
  Approximation","  Piecewise Polynomials (PPs) are utilized in several engineering disciplines,
like trajectory planning, to approximate position profiles given in the form of
a set of points. While the approximation target along with domain-specific
requirements, like Ck -continuity, can be formulated as a system of equations
and a result can be computed directly, such closed-form solutions posses
limited flexibility with respect to polynomial degrees, polynomial bases or
adding further domain-specific requirements. Sufficiently complex optimization
goals soon call for the use of numerical methods, like gradient descent. Since
gradient descent lies at the heart of training Artificial Neural Networks
(ANNs), modern Machine Learning (ML) frameworks like TensorFlow come with a set
of gradient-based optimizers potentially suitable for a wide range of
optimization problems beyond the training task for ANNs. Our approach is to
utilize the versatility of PP models and combine it with the potential of
modern ML optimizers for the use in function approximation in 1D trajectory
planning in the context of electronic cam design. We utilize available
optimizers of the ML framework TensorFlow directly, outside of the scope of
ANNs, to optimize model parameters of our PP model. In this paper, we show how
an orthogonal polynomial basis contributes to improving approximation and
continuity optimization performance. Utilizing Chebyshev polynomials of the
first kind, we develop a novel regularization approach enabling clearly
improved convergence behavior. We show that, using this regularization
approach, Chebyshev basis performs better than power basis for all relevant
optimizers in the combined approximation and continuity optimization setting
and demonstrate usability of the presented approach within the electronic cam
domain.
",2024-03-13 14:34:34+00:00,cs.LG
"MorphoGear: An UAV with Multi-Limb Morphogenetic Gear for Rough-Terrain
  Locomotion","  Robots able to run, fly, and grasp have a high potential to solve a wide
scope of tasks and navigate in complex environments. Several mechatronic
designs of such robots with adaptive morphologies are emerging. However, the
task of landing on an uneven surface, traversing rough terrain, and
manipulating objects still presents high challenges.
  This paper introduces the design of a novel rotor UAV MorphoGear with
morphogenetic gear and includes a description of the robot's mechanics,
electronics, and control architecture, as well as walking behavior and an
analysis of experimental results. MorphoGear is able to fly, walk on surfaces
with several gaits, and grasp objects with four compatible robotic limbs.
Robotic limbs with three degrees of freedom (DoFs) are used by this UAV as
pedipulators when walking or flying and as manipulators when performing actions
in the environment. We performed a locomotion analysis of the landing gear of
the robot. Three types of robot gaits have been developed.
  The experimental results revealed low crosstrack error of the most accurate
gait (mean of 1.9 cm and max of 5.5 cm) and the ability of the drone to move
with a 210 mm step length. Another type of robot gait also showed low
crosstrack error (mean of 2.3 cm and max of 6.9 cm). The proposed MorphoGear
system can potentially achieve a high scope of tasks in environmental
surveying, delivery, and high-altitude operations.
",2024-03-13 08:43:06+00:00,cs.RO
"GPT, Ontology, and CAABAC: A Tripartite Personalized Access Control
  Model Anchored by Compliance, Context and Attribute","  As digital healthcare evolves, the security of electronic health records
(EHR) becomes increasingly crucial. This study presents the GPT-Onto-CAABAC
framework, integrating Generative Pretrained Transformer (GPT), medical-legal
ontologies and Context-Aware Attribute-Based Access Control (CAABAC) to enhance
EHR access security. Unlike traditional models, GPT-Onto-CAABAC dynamically
interprets policies and adapts to changing healthcare and legal environments,
offering customized access control solutions. Through empirical evaluation,
this framework is shown to be effective in improving EHR security by accurately
aligning access decisions with complex regulatory and situational requirements.
The findings suggest its broader applicability in sectors where access control
must meet stringent compliance and adaptability standards.
",2024-03-13 05:30:30+00:00,cs.CY
"A Novel Feature Learning-based Bio-inspired Neural Network for Real-time
  Collision-free Rescue of Multi-Robot Systems","  Natural disasters and urban accidents drive the demand for rescue robots to
provide safer, faster, and more efficient rescue trajectories. In this paper, a
feature learning-based bio-inspired neural network (FLBBINN) is proposed to
quickly generate a heuristic rescue path in complex and dynamic environments,
as traditional approaches usually cannot provide a satisfactory solution to
real-time responses to sudden environmental changes. The neurodynamic model is
incorporated into the feature learning method that can use environmental
information to improve path planning strategies. Task assignment and
collision-free rescue trajectory are generated through robot poses and the
dynamic landscape of neural activity. A dual-channel scale filter, a neural
activity channel, and a secondary distance fusion are employed to extract and
filter feature neurons. After completion of the feature learning process, a
neurodynamics-based feature matrix is established to quickly generate the new
heuristic rescue paths with parameter-driven topological adaptability. The
proposed FLBBINN aims to reduce the computational complexity of the neural
network-based approach and enable the feature learning method to achieve
real-time responses to environmental changes. Several simulations and
experiments have been conducted to evaluate the performance of the proposed
FLBBINN. The results show that the proposed FLBBINN would significantly improve
the speed, efficiency, and optimality for rescue operations.
",2024-03-13 04:43:10+00:00,cs.RO
"SCALHEALTH: Scalable Blockchain Integration for Secure IoT Healthcare
  Systems","  Internet of Things (IoT) devices are capable of allowing for far-reaching
access to and evaluation of patient data to monitor health and diagnose from a
distance. An electronic healthcare system that checks patient data, prepares
medicines and provides financial assistance is necessary. Providing safe data
transmission, monitoring, decentralization, preserving patient privacy, and
maintaining confidentiality are essential to an electronic healthcare system.
In this study, we introduce (SCALHEALTH) which is a blockchain-based scheme of
the Hyperledger Fabric consortium. In this study, we use authentication to
agree on a common key for data encryption to send data confidentially. Also,
sending data through IPFS is decentralized. Non-fungible token (NFT) is used to
send patient prescriptions to pharmacies and insurance companies to ensure the
authenticity of patient prescriptions. As the system's main body, blockchain
creates authorization and validation for all devices and institutions. Also,
all metadata in the system is recorded on the blockchain to maintain integrity,
transparency, and timely data monitoring. The proposed study uses two types of
blockchain: a health blockchain and a financial blockchain. The financial
blockchain is for financial transactions and is based on Ethereum. The health
blockchain also introduces a mechanism that allows several blockchains to be
active in parallel, instead of only one blockchain. The prototype of this
mechanism is simulated in two scenarios. In comparison to the normal state, the
proposed plan has superior results.
",2024-03-12 20:42:32+00:00,cs.CR
"A Machine learning and Empirical Bayesian Approach for Predictive Buying
  in B2B E-commerce","  In the context of developing nations like India, traditional business to
business (B2B) commerce heavily relies on the establishment of robust
relationships, trust, and credit arrangements between buyers and sellers.
Consequently, ecommerce enterprises frequently. Established in 2016 with a
vision to revolutionize trade in India through technology, Udaan is the
countrys largest business to business ecommerce platform. Udaan operates across
diverse product categories, including lifestyle, electronics, home and employ
telecallers to cultivate buyer relationships, streamline order placement
procedures, and promote special promotions. The accurate anticipation of buyer
order placement behavior emerges as a pivotal factor for attaining sustainable
growth, heightening competitiveness, and optimizing the efficiency of these
telecallers. To address this challenge, we have employed an ensemble approach
comprising XGBoost and a modified version of Poisson Gamma model to predict
customer order patterns with precision. This paper provides an in-depth
exploration of the strategic fusion of machine learning and an empirical
Bayesian approach, bolstered by the judicious selection of pertinent features.
This innovative approach has yielded a remarkable 3 times increase in customer
order rates, show casing its potential for transformative impact in the
ecommerce industry.
",2024-03-12 17:32:52+00:00,cs.LG
"Enhancing Readmission Prediction with Deep Learning: Extracting
  Biomedical Concepts from Clinical Texts","  Hospital readmission, defined as patients being re-hospitalized shortly after
discharge, is a critical concern as it impacts patient outcomes and healthcare
costs. Identifying patients at risk of readmission allows for timely
interventions, reducing re-hospitalization rates and overall treatment costs.
This study focuses on predicting patient readmission within less than 30 days
using text mining techniques applied to discharge report texts from electronic
health records (EHR). Various machine learning and deep learning methods were
employed to develop a classification model for this purpose. A novel aspect of
this research involves leveraging the Bio-Discharge Summary Bert (BDSS) model
along with principal component analysis (PCA) feature extraction to preprocess
data for deep learning model input. Our analysis of the MIMIC-III dataset
indicates that our approach, which combines the BDSS model with a multilayer
perceptron (MLP), outperforms state-of-the-art methods. This model achieved a
recall of 94% and an area under the curve (AUC) of 75%, showcasing its
effectiveness in predicting patient readmissions. This study contributes to the
advancement of predictive modeling in healthcare by integrating text mining
techniques with deep learning algorithms to improve patient outcomes and
optimize resource allocation.
",2024-03-12 09:03:44+00:00,cs.CL
"The Dawn of AI-Native EDA: Opportunities and Challenges of Large Circuit
  Models","  Within the Electronic Design Automation (EDA) domain, AI-driven solutions
have emerged as formidable tools, yet they typically augment rather than
redefine existing methodologies. These solutions often repurpose deep learning
models from other domains, such as vision, text, and graph analytics, applying
them to circuit design without tailoring to the unique complexities of
electronic circuits. Such an AI4EDA approach falls short of achieving a
holistic design synthesis and understanding, overlooking the intricate
interplay of electrical, logical, and physical facets of circuit data. This
paper argues for a paradigm shift from AI4EDA towards AI-native EDA,
integrating AI at the core of the design process. Pivotal to this vision is the
development of a multimodal circuit representation learning technique, poised
to provide a comprehensive understanding by harmonizing and extracting insights
from varied data sources, such as functional specifications, RTL designs,
circuit netlists, and physical layouts. We champion the creation of large
circuit models (LCMs) that are inherently multimodal, crafted to decode and
express the rich semantics and structures of circuit data, thus fostering more
resilient, efficient, and inventive design methodologies. Embracing this
AI-native philosophy, we foresee a trajectory that transcends the current
innovation plateau in EDA, igniting a profound shift-left in electronic design
methodology. The envisioned advancements herald not just an evolution of
existing EDA tools but a revolution, giving rise to novel instruments of design
tools that promise to radically enhance design productivity and inaugurate a
new epoch where the optimization of circuit performance, power, and area (PPA)
is achieved not incrementally, but through leaps that redefine the benchmarks
of electronic systems' capabilities.
",2024-03-12 02:26:30+00:00,cs.AR
"A multi-cohort study on prediction of acute brain dysfunction states
  using selective state space models","  Assessing acute brain dysfunction (ABD), including delirium and coma in the
intensive care unit (ICU), is a critical challenge due to its prevalence and
severe implications for patient outcomes. Current diagnostic methods rely on
infrequent clinical observations, which can only determine a patient's ABD
status after onset. Our research attempts to solve these problems by harnessing
Electronic Health Records (EHR) data to develop automated methods for ABD
prediction for patients in the ICU. Existing models solely predict a single
state (e.g., either delirium or coma), require at least 24 hours of observation
data to make predictions, do not dynamically predict fluctuating ABD conditions
during ICU stay (typically a one-time prediction), and use small sample size,
proprietary single-hospital datasets. Our research fills these gaps in the
existing literature by dynamically predicting delirium, coma, and mortality for
12-hour intervals throughout an ICU stay and validating on two public datasets.
Our research also introduces the concept of dynamically predicting critical
transitions from non-ABD to ABD and between different ABD states in real time,
which could be clinically more informative for the hospital staff. We compared
the predictive performance of two state-of-the-art neural network models, the
MAMBA selective state space model and the Longformer Transformer model. Using
the MAMBA model, we achieved a mean area under the receiving operator
characteristic curve (AUROC) of 0.95 on outcome prediction of ABD for 12-hour
intervals. The model achieves a mean AUROC of 0.79 when predicting transitions
between ABD states. Our study uses a curated dataset from the University of
Florida Health Shands Hospital for internal validation and two publicly
available datasets, MIMIC-IV and eICU, for external validation, demonstrating
robustness across ICU stays from 203 hospitals and 140,945 patients.
",2024-03-11 22:58:11+00:00,cs.LG
Monitoring the Venice Lagoon: an IoT Cloud-Based Sensor Nerwork Approach,"  Monitoring the coastal area of the Venice Lagoon is of significant
importance. While the impact of global warming is felt worldwide, coastal and
littoral regions bear the brunt more prominently. These areas not only face the
threat of rising sea levels but also contend with the escalating occurrence of
seaquakes and floods. Additionally, the intricate ecosystems of rivers, seas,
and lakes undergo profound transformations due to climate change and
pollutants.
  Employing devices like the SENSWICH floating wireless sensor presented in
this article and similar measurement instruments proves invaluable to automate
environmental monitoring, hence eliminating the need for manual sampling
campaigns. The utilization of wireless measurement devices offers
cost-effectiveness, real-time analysis, and a reduction in human resource
requirements. Storing data in cloud services further enhances the ability to
monitor parameter changes over extended time intervals.
  In this article, we present an enhanced sensing device aimed at automating
water quality assessment, while considering power consumption and reducing
circuit complexity. Specifically, we will introduce the new schematic and
circuit of SENSWICH which had changes in circuit and electronic aspects.
Furthermore, we outline the methodology for aggregating data in a cloud service
environment, such as Amazon Web Service (AWS), and using Grafana for
visualization.
",2024-03-11 17:04:04+00:00,cs.NI
"Integrated Control of Robotic Arm through EMG and Speech:
  Decision-Driven Multimodal Data Fusion","  Interactions with electronic devices are changing in our daily lives. The
day-to-day development brings curiosity to recent technology and challenges its
use. The gadgets are becoming cumbersome, and their usage frustrates a segment
of society. In specific scenarios, the user cannot use the modalities because
of the challenges that bring in, e.g., the usage of touch screen devices by
elderly people. The idea of multimodality provides easy access to devices of
daily use through various modalities. In this paper, we suggest a solution that
allows the operation of a microcontroller-based device using voice and speech.
The model implemented will learn from the user's behavior and decide based on
prior knowledge.
",2024-03-11 16:42:54+00:00,cs.HC
"MOAB: Multi-Modal Outer Arithmetic Block For Fusion Of Histopathological
  Images And Genetic Data For Brain Tumor Grading","  Brain tumors are an abnormal growth of cells in the brain. They can be
classified into distinct grades based on their growth. Often grading is
performed based on a histological image and is one of the most significant
predictors of a patients prognosis, the higher the grade, the more aggressive
the tumor. Correct diagnosis of a tumor grade remains challenging. Though
histopathological grading has been shown to be prognostic, results are subject
to interobserver variability, even among experienced pathologists. Recently,
the World Health Organization reported that advances in molecular genetics have
led to improvements in tumor classification. This paper seeks to integrate
histological images and genetic data for improved computer-aided diagnosis. We
propose a novel Multi-modal Outer Arithmetic Block (MOAB) based on arithmetic
operations to combine latent representations of the different modalities for
predicting the tumor grade (Grade \rom{2}, \rom{3} and \rom{4}). Extensive
experiments evaluate the effectiveness of our approach. By applying MOAB to The
Cancer Genome Atlas (TCGA) glioma dataset, we show that it can improve
separation between similar classes (Grade \rom{2} and \rom{3}) and outperform
prior state-of-the-art grade classification techniques.
",2024-03-11 00:33:28+00:00,cs.CV
"FOAA: Flattened Outer Arithmetic Attention For Multimodal Tumor
  Classification","  Fusion of multimodal healthcare data holds great promise to provide a
holistic view of a patient's health, taking advantage of the complementarity of
different modalities while leveraging their correlation. This paper proposes a
simple and effective approach, inspired by attention, to fuse discriminative
features from different modalities. We propose a novel attention mechanism,
called Flattened Outer Arithmetic Attention (FOAA), which relies on outer
arithmetic operators (addition, subtraction, product, and division) to compute
attention scores from keys, queries and values derived from flattened
embeddings of each modality. We demonstrate how FOAA can be implemented for
self-attention and cross-attention, providing a reusable component in neural
network architectures. We evaluate FOAA on two datasets for multimodal tumor
classification and achieve state-of-the-art results, and we demonstrate that
features enriched by FOAA are superior to those derived from other fusion
approaches. The code is publicly available at
\href{https://github.com/omniaalwazzan/FOAA}{https://github.com/omniaalwazzan/FOAA}
",2024-03-10 23:12:40+00:00,cs.CV
"Sistemas de información de salud en contextos extremos: Uso de
  teléfonos móviles para combatir el sida en Uganda","  The HIV/AIDS pandemic is a global issue that has unequally affected several
countries. Due to the complexity of this condition and the human drama it
represents to those most affected by it, several fields have contributed to
solving or at least alleviating this situation, and the information systems
(IS) field has not been absent from these efforts. With the importance of
antiretroviral therapy (ART) as a starting point, several initiatives in the IS
field have focused on ways to improve the adherence and effectiveness of this
therapy: mobile phone reminders (for pill intake and appointments), and mobile
interfaces between patients and health workers are popular contributions.
However, many of these solutions have been difficult to implement or deploy in
some countries in the Global South, which are among the most affected by this
pandemic. This paper presents one such case. Using a case-study approach with
an extreme-case selection technique, the paper studies an m-health system for
HIV patients in the Kalangala region of Uganda. Using Heeks' design-reality gap
model for data analysis, the paper shows that the rich interaction between
social context and technology should be considered a central concern when
designing or deploying such systems.
",2024-03-10 03:44:16+00:00,cs.CY
"High Throughput Phenotyping of Physician Notes with Large Language and
  Hybrid NLP Models","  Deep phenotyping is the detailed description of patient signs and symptoms
using concepts from an ontology. The deep phenotyping of the numerous physician
notes in electronic health records requires high throughput methods. Over the
past thirty years, progress toward making high throughput phenotyping feasible.
In this study, we demonstrate that a large language model and a hybrid NLP
model (combining word vectors with a machine learning classifier) can perform
high throughput phenotyping on physician notes with high accuracy. Large
language models will likely emerge as the preferred method for high throughput
deep phenotyping of physician notes.
",2024-03-09 14:02:59+00:00,cs.CL
Unleashing the Power of T1-cells in SFQ Arithmetic Circuits,"  Rapid single-flux quantum (RSFQ), a leading cryogenic superconductive
electronics (SCE) technology, offers extremely low power dissipation and high
speed. However, implementing RSFQ systems at VLSI complexity faces challenges,
such as substantial area overhead from gate-level pipelining and path
balancing, exacerbated by RSFQ's limited layout density. T1 flip-flop (T1-FF)
is an RSFQ logic cell operating as a pulse counter. Using T1-FF the full adder
function can be realized with only 40% of the area required by the conventional
realization. This cell however imposes complex constraints on input signal
timing, complicating its use. Multiphase clocking has been recently proposed to
alleviate gate-level pipelining overhead. The fanin signals can be efficiently
controlled using multiphase clocking. We present the novel two-stage SFQ
technology mapping methodology supporting the T1-FF. Compatible parts of the
SFQ network are first replaced by the efficient T1-FFs. Multiphase retiming is
next applied to assign clock phases to each logic gate and insert DFFs to
satisfy the input timing. Using our flow, the area of the SFQ networks is
reduced, on average, by 6% with up to 25% reduction in optimizing the 128-bit
adder.
",2024-03-09 12:38:35+00:00,cs.ET
Towards Multiphase Clocking in Single-Flux Quantum Systems,"  Rapid single-flux quantum (RSFQ) is one of the most advanced superconductive
electronics technologies. SFQ systems operate at tens of gigahertz with up to
three orders of magnitude smaller power as compared to CMOS. In conventional
SFQ systems, most gates require clock signal. Each gate should have the fanins
with equal logic depth, necessitating insertion of path-balancing (PB) DFFs,
incurring prohibitive area penalty. Multiphase clocking is the effective method
for reducing the path-balancing overhead at the cost of reduced throughput.
However, existing tools are not directly applicable for technology mapping of
multiphase systems. To overcome this limitation, in this work, we propose a
technology mapping tool for multiphase systems. Our contribution is threefold.
First, we formulate a phase assignment as a Constraint Programming with
Satisfiability (CP-SAT) problem, to determine the phase of each element within
the network. Second, we formulate the path balancing problem as a CP-SAT to
optimize the number of DFFs within an asynchronous datapath. Finally, we
integrate these methods into a technology mapping flow to convert a logic
network into a multiphase SFQ circuit. In our case studies, by using seven
phases, the size of the circuit (expressed as the number of Josephson
junctions) is reduced, on average, by 59.94 % as compared to the dual
(fast-slow) clocking method, while outperforming the state-of-the-art
single-phase SFQ mapping tools.
",2024-03-09 11:34:25+00:00,cs.ET
Using Fiber Optic Bundles to Miniaturize Vision-Based Tactile Sensors,"  Vision-based tactile sensors have recently become popular due to their
combination of low cost, very high spatial resolution, and ease of integration
using widely available miniature cameras. The associated field of view and
focal length, however, are difficult to package in a human-sized finger. In
this paper we employ optical fiber bundles to achieve a form factor that, at 15
mm diameter, is smaller than an average human fingertip. The electronics and
camera are also located remotely, further reducing package size. The sensor
achieves a spatial resolution of 0.22 mm and a minimum force resolution 5 mN
for normal and shear contact forces. With these attributes, the DIGIT Pinki
sensor is suitable for applications such as robotic and teleoperated digital
palpation. We demonstrate its utility for palpation of the prostate gland and
show that it can achieve clinically relevant discrimination of prostate
stiffness for phantom and ex vivo tissue.
",2024-03-08 18:17:56+00:00,cs.RO
"An in-Contact Robotic System for the Process of Desoldering PCB
  Components","  The disposal and recycling of electronic waste (e-waste) is a global
challenge. The disassembly of components is a crucial step towards an efficient
recycling process, avoiding the destructive methods. Although most disassembly
work is still done manually due to the diversity and complexity of components,
there is a growing interest in developing automated methods to improve
efficiency and reduce labor costs. This study aims to robotize the desoldering
process and extracting components from printed circuit boards (PCBs), with the
goal of automating the process as much as possible. The proposed strategy
consists of several phases, including the controlled contact of the robotic
tool with the PCB components. A specific tool was developed to apply a
controlled force against the PCB component, removing it from the board. The
results demonstrate that it is feasible to remove the PCB components with a
high success rate (approximately 100% for the bigger PCB components).
",2024-03-08 13:38:17+00:00,cs.RO
"Motion-Guided Dual-Camera Tracker for Low-Cost Skill Evaluation of
  Gastric Endoscopy","  Gastric simulators with objective educational feedback have been proven
useful for endoscopy training. Existing electronic simulators with feedback are
however not commonly adopted due to their high cost. In this work, a
motion-guided dual-camera tracker is proposed to provide reliable endoscope tip
position feedback at a low cost inside a mechanical simulator for endoscopy
skill evaluation, tackling several unique challenges. To address the issue of
significant appearance variation of the endoscope tip while keeping dual-camera
tracking consistency, the cross-camera mutual template strategy (CMT) is
proposed to introduce dynamic transient mutual templates to dual-camera
tracking. To alleviate disturbance from large occlusion and distortion by the
light source from the endoscope tip, the Mamba-based motion-guided prediction
head (MMH) is presented to aggregate historical motion with visual tracking. It
is the first application of Mamba for object tracking. The proposed tracker was
evaluated on datasets captured by low-cost camera pairs during endoscopy
procedures performed inside the mechanical simulator. The tracker achieves SOTA
performance with robust and consistent tracking on dual cameras. Further
downstream evaluation proves that the 3D tip position determined by the
proposed tracker enables reliable skill differentiation. The code and dataset
are available at https://github.com/PieceZhang/MotionDCTrack
",2024-03-08 08:31:46+00:00,cs.CV
CARISMA: CAR-Integrated Service Mesh Architecture,"  The amount of software in modern cars is increasing continuously with
traditional electric/electronic (E/E) architectures reaching their limit when
deploying complex applications, e.g., regarding bandwidth or computational
power. To mitigate this situation, more powerful computing platforms are being
employed and applications are developed as distributed applications, e.g.,
involving microservices. Microservices received widespread adoption and changed
the way modern applications are developed. However, they also introduce
additional complexity regarding inter-service communication. This has led to
the emergence of service meshes, a promising approach to cope with this
complexity. In this paper, we present an architecture applying the service mesh
approach to automotive E/E platforms comprising multiple interlinked
High-Performance Computers (HPCs). We validate the feasibility of our approach
through a prototypical implementation.
",2024-03-07 10:10:34+00:00,cs.DC
"MKF-ADS: Multi-Knowledge Fusion Based Self-supervised Anomaly Detection
  System for Control Area Network","  Control Area Network (CAN) is an essential communication protocol that
interacts between Electronic Control Units (ECUs) in the vehicular network.
However, CAN is facing stringent security challenges due to innate security
risks. Intrusion detection systems (IDSs) are a crucial safety component in
remediating Vehicular Electronics and Systems vulnerabilities. However,
existing IDSs fail to identify complexity attacks and have higher false alarms
owing to capability bottleneck. In this paper, we propose a self-supervised
multi-knowledge fused anomaly detection model, called MKF-ADS. Specifically,
the method designs an integration framework, including spatial-temporal
correlation with an attention mechanism (STcAM) module and patch
sparse-transformer module (PatchST). The STcAM with fine-pruning uses
one-dimensional convolution (Conv1D) to extract spatial features and
subsequently utilizes the Bidirectional Long Short Term Memory (Bi-LSTM) to
extract the temporal features, where the attention mechanism will focus on the
important time steps. Meanwhile, the PatchST captures the combined contextual
features from independent univariate time series. Finally, the proposed method
is based on knowledge distillation to STcAM as a student model for learning
intrinsic knowledge and cross the ability to mimic PatchST. We conduct
extensive experiments on six simulation attack scenarios across various CAN IDs
and time steps, and two real attack scenarios, which present a competitive
prediction and detection performance. Compared with the baseline in the same
paradigm, the error rate and FAR are 2.62\% and 2.41\% and achieve a promising
F1-score of 97.3\%.
",2024-03-07 07:40:53+00:00,cs.AI
Advancing Biomedical Text Mining with Community Challenges,"  The field of biomedical research has witnessed a significant increase in the
accumulation of vast amounts of textual data from various sources such as
scientific literatures, electronic health records, clinical trial reports, and
social media. However, manually processing and analyzing these extensive and
complex resources is time-consuming and inefficient. To address this challenge,
biomedical text mining, also known as biomedical natural language processing,
has garnered great attention. Community challenge evaluation competitions have
played an important role in promoting technology innovation and
interdisciplinary collaboration in biomedical text mining research. These
challenges provide platforms for researchers to develop state-of-the-art
solutions for data mining and information processing in biomedical research. In
this article, we review the recent advances in community challenges specific to
Chinese biomedical text mining. Firstly, we collect the information of these
evaluation tasks, such as data sources and task types. Secondly, we conduct
systematic summary and comparative analysis, including named entity
recognition, entity normalization, attribute extraction, relation extraction,
event extraction, text classification, text similarity, knowledge graph
construction, question answering, text generation, and large language model
evaluation. Then, we summarize the potential clinical applications of these
community challenge tasks from translational informatics perspective. Finally,
we discuss the contributions and limitations of these community challenges,
while highlighting future directions in the era of large language models.
",2024-03-07 06:52:51+00:00,cs.AI
"Silicon Photonic 2.5D Interposer Networks for Overcoming Communication
  Bottlenecks in Scale-out Machine Learning Hardware Accelerators","  Modern machine learning (ML) applications are becoming increasingly complex
and monolithic (single chip) accelerator architectures cannot keep up with
their energy efficiency and throughput demands. Even though modern digital
electronic accelerators are gradually adopting 2.5D architectures with multiple
smaller chiplets to improve scalability, they face fundamental limitations due
to a reliance on slow metallic interconnects. This paper outlines how optical
communication and computation can be leveraged in 2.5D platforms to realize
energy-efficient and high throughput 2.5D ML accelerator architectures.
",2024-03-07 03:38:35+00:00,cs.AR
"Automated Multi-Task Learning for Joint Disease Prediction on Electronic
  Health Records","  In the realm of big data and digital healthcare, Electronic Health Records
(EHR) have become a rich source of information with the potential to improve
patient care and medical research. In recent years, machine learning models
have proliferated for analyzing EHR data to predict patients future health
conditions. Among them, some studies advocate for multi-task learning (MTL) to
jointly predict multiple target diseases for improving the prediction
performance over single task learning. Nevertheless, current MTL frameworks for
EHR data have significant limitations due to their heavy reliance on human
experts to identify task groups for joint training and design model
architectures. To reduce human intervention and improve the framework design,
we propose an automated approach named AutoDP, which can search for the optimal
configuration of task grouping and architectures simultaneously. To tackle the
vast joint search space encompassing task combinations and architectures, we
employ surrogate model-based optimization, enabling us to efficiently discover
the optimal solution. Experimental results on real-world EHR data demonstrate
the efficacy of the proposed AutoDP framework. It achieves significant
performance improvements over both hand-crafted and automated state-of-the-art
methods, also maintains a feasible search cost at the same time.
",2024-03-06 22:32:48+00:00,cs.LG
"Temporal Cross-Attention for Dynamic Embedding and Tokenization of
  Multimodal Electronic Health Records","  The breadth, scale, and temporal granularity of modern electronic health
records (EHR) systems offers great potential for estimating personalized and
contextual patient health trajectories using sequential deep learning. However,
learning useful representations of EHR data is challenging due to its high
dimensionality, sparsity, multimodality, irregular and variable-specific
recording frequency, and timestamp duplication when multiple measurements are
recorded simultaneously. Although recent efforts to fuse structured EHR and
unstructured clinical notes suggest the potential for more accurate prediction
of clinical outcomes, less focus has been placed on EHR embedding approaches
that directly address temporal EHR challenges by learning time-aware
representations from multimodal patient time series. In this paper, we
introduce a dynamic embedding and tokenization framework for precise
representation of multimodal clinical time series that combines novel methods
for encoding time and sequential position with temporal cross-attention. Our
embedding and tokenization framework, when integrated into a multitask
transformer classifier with sliding window attention, outperformed baseline
approaches on the exemplar task of predicting the occurrence of nine
postoperative complications of more than 120,000 major inpatient surgeries
using multimodal data from three hospitals and two academic health centers in
the United States.
",2024-03-06 19:46:44+00:00,cs.LG
"Eternal Sunshine of the Mechanical Mind: The Irreconcilability of
  Machine Learning and the Right to be Forgotten","  As we keep rapidly advancing toward an era where artificial intelligence is a
constant and normative experience for most of us, we must also be aware of what
this vision and this progress entail. By first approximating neural connections
and activities in computer circuits and then creating more and more
sophisticated versions of this crude approximation, we are now facing an age to
come where modern deep learning-based artificial intelligence systems can
rightly be called thinking machines, and they are sometimes even lauded for
their emergent behavior and black-box approaches. But as we create more
powerful electronic brains, with billions of neural connections and parameters,
can we guarantee that these mammoths built of artificial neurons will be able
to forget the data that we store in them? If they are at some level like a
brain, can the right to be forgotten still be protected while dealing with
these AIs? The essential gap between machine learning and the RTBF is explored
in this article, with a premonition of far-reaching conclusions if the gap is
not bridged or reconciled any time soon. The core argument is that deep
learning models, due to their structure and size, cannot be expected to forget
or delete a data as it would be expected from a tabular database, and they
should be treated more like a mechanical brain, albeit still in development.
",2024-03-06 13:23:57+00:00,cs.GL
"IB-Net: Initial Branch Network for Variable Decision in Boolean
  Satisfiability","  Boolean Satisfiability problems are vital components in Electronic Design
Automation, particularly within the Logic Equivalence Checking process.
Currently, SAT solvers are employed for these problems and neural network is
tried as assistance to solvers. However, as SAT problems in the LEC context are
distinctive due to their predominantly unsatisfiability nature and a
substantial proportion of UNSAT-core variables, existing neural network
assistance has proven unsuccessful in this specialized domain. To tackle this
challenge, we propose IB-Net, an innovative framework utilizing graph neural
networks and novel graph encoding techniques to model unsatisfiable problems
and interact with state-of-the-art solvers. Extensive evaluations across
solvers and datasets demonstrate IB-Net's acceleration, achieving an average
runtime speedup of 5.0% on industrial data and 8.3% on SAT competition data
empirically. This breakthrough advances efficient solving in LEC workflows.
",2024-03-06 07:54:40+00:00,cs.AI
"Software-defined optical networking applications enabled by programmable
  integrated photonics","  Data center networks are experiencing unprecedented exponential growth,
mostly driven by the continuous computing demands in machine learning and
artificial intelligence algorithms. Within this realm, optical networking
offers numerous advantages, including low latency, energy efficiency, and
bandwidth transparency, positioning it as a compelling alternative to its
electronic counterparts. In this work, we showcase a range of software-defined
optical networking applications deployed on a general-purpose programmable
integrated photonic processor. Leveraging graph-based theory, we experimentally
demonstrate dynamic optical interconnects, circuit switching, and multicasting
on the same photonic platform, yielding remarkable results in terms of
crosstalk and reconfiguration speed. Our approach harnesses the benefits of
reconfigurability and reliability, paving the way for a new generation of
high-performance optical devices tailored for data center and computing
clusters.
",2024-03-04 21:13:32+00:00,cs.NI
"A Novel Hybrid Feature Importance and Feature Interaction Detection
  Framework for Predictive Optimization in Industry 4.0 Applications","  Advanced machine learning algorithms are increasingly utilized to provide
data-based prediction and decision-making support in Industry 4.0. However, the
prediction accuracy achieved by the existing models is insufficient to warrant
practical implementation in real-world applications. This is because not all
features present in real-world datasets possess a direct relevance to the
predictive analysis being conducted. Consequently, the careful incorporation of
select features has the potential to yield a substantial positive impact on the
outcome. To address the research gap, this paper proposes a novel hybrid
framework that combines the feature importance detector - local interpretable
model-agnostic explanations (LIME) and the feature interaction detector -
neural interaction detection (NID), to improve prediction accuracy. By applying
the proposed framework, unnecessary features can be eliminated, and
interactions are encoded to generate a more conducive dataset for predictive
purposes. Subsequently, the proposed model is deployed to refine the prediction
of electricity consumption in foundry processing. The experimental outcomes
reveal an augmentation of up to 9.56% in the R2 score, and a diminution of up
to 24.05% in the root mean square error.
",2024-03-04 13:22:53+00:00,cs.LG
DECOR: Enhancing Logic Locking Against Machine Learning-Based Attacks,"  Logic locking (LL) has gained attention as a promising intellectual property
protection measure for integrated circuits. However, recent attacks,
facilitated by machine learning (ML), have shown the potential to predict the
correct key in multiple LL schemes by exploiting the correlation of the correct
key value with the circuit structure. This paper presents a generic LL
enhancement method based on a randomized algorithm that can significantly
decrease the correlation between locked circuit netlist and correct key values
in an LL scheme. Numerical results show that the proposed method can
efficiently degrade the accuracy of state-of-the-art ML-based attacks down to
around 50%, resulting in negligible advantage versus random guessing.
",2024-03-04 07:31:23+00:00,cs.CR
"OSM: Leveraging Model Checking for Observing Dynamic 1 behaviors in
  Aspect-Oriented Applications","  In the intricate domain of software systems verification, dynamically model
checking multifaceted system characteristics remains paramount, yet
challenging. This research proposes the advanced observe-based statistical
model-checking (OSM) framework, devised to craft executable formal models
directly from foundational system code. Leveraging model checking predicates,
the framework melds seamlessly with aspect-oriented programming paradigms,
yielding a potent method for the analytical verification of varied behavioral
attributes. Exploiting the transformative capacity of OSM framework, primary
system code undergoes a systematic metamorphosis into multifaceted analysis
constructs. This not only simplifies the model verification process but also
orchestrates feature interactions using an innovative observing join point
abstraction mechanism. Within this framework, components encompassing parsing,
formal verification, computational analytics, and rigorous validation are
intrinsically interwoven. Marrying the principles of model checking with
aspect-oriented (AO) modularization, OSM framework stands as a paragon,
proficiently scrutinizing and affirming system specifications. This ensures the
unyielding performance of electronic health record systems amidst shifting
preconditions. OSM framework offers runtime verification of both
object-oriented and AO deployments, positioning itself as an indispensable
open-source resource, poised to automate the enhancement of system performance
and scalability.
",2024-03-03 00:03:34+00:00,cs.SE
"The Repercussions of the COVID-19 Pandemic on Higher Education and its
  implications for Syrian Refugees Students (An Analytical Descriptive Study)","  This study aims to reveal the most important challenges and difficulties that
refugee students faced in Jordanian universities (e.g., Yarmouk University, AL
Al-Bayt, and the Private Zarqa University) due to the COVID-19 pandemic through
measuring a different of indicators that are related, in addition, to identify
some of the independent variables on e-educational challenges. In the study,
the analytical description approach was used. The data collection tool is a
questionnaire, which was distributed to a random sample of students
electronically. Results show that the necessity to implement educational and
psychological counseling programs and economic support programs to support the
e-Learning costs. The study confirmed that refugees are the most affected
students with the pandemic compared to the host community.
  Keywords: Syrian refugees, COVID-19, e-learning
",2024-03-02 23:58:33+00:00,cs.SI
"Large Language Multimodal Models for 5-Year Chronic Disease Cohort
  Prediction Using EHR Data","  Chronic diseases such as diabetes are the leading causes of morbidity and
mortality worldwide. Numerous research studies have been attempted with various
deep learning models in diagnosis. However, most previous studies had certain
limitations, including using publicly available datasets (e.g. MIMIC), and
imbalanced data. In this study, we collected five-year electronic health
records (EHRs) from the Taiwan hospital database, including 1,420,596 clinical
notes, 387,392 laboratory test results, and more than 1,505 laboratory test
items, focusing on research pre-training large language models. We proposed a
novel Large Language Multimodal Models (LLMMs) framework incorporating
multimodal data from clinical notes and laboratory test results for the
prediction of chronic disease risk. Our method combined a text embedding
encoder and multi-head attention layer to learn laboratory test values,
utilizing a deep neural network (DNN) module to merge blood features with
chronic disease semantics into a latent space. In our experiments, we observe
that clinicalBERT and PubMed-BERT, when combined with attention fusion, can
achieve an accuracy of 73% in multiclass chronic diseases and diabetes
prediction. By transforming laboratory test values into textual descriptions
and employing the Flan T-5 model, we achieved a 76% Area Under the ROC Curve
(AUROC), demonstrating the effectiveness of leveraging numerical text data for
training and inference in language models. This approach significantly improves
the accuracy of early-stage diabetes prediction.
",2024-03-02 22:33:17+00:00,cs.CL
"Less is More: Hop-Wise Graph Attention for Scalable and Generalizable
  Learning on Circuits","  While graph neural networks (GNNs) have gained popularity for learning
circuit representations in various electronic design automation (EDA) tasks,
they face challenges in scalability when applied to large graphs and exhibit
limited generalizability to new designs. These limitations make them less
practical for addressing large-scale, complex circuit problems. In this work we
propose HOGA, a novel attention-based model for learning circuit
representations in a scalable and generalizable manner. HOGA first computes
hop-wise features per node prior to model training. Subsequently, the hop-wise
features are solely used to produce node representations through a gated
self-attention module, which adaptively learns important features among
different hops without involving the graph topology. As a result, HOGA is
adaptive to various structures across different circuits and can be efficiently
trained in a distributed manner. To demonstrate the efficacy of HOGA, we
consider two representative EDA tasks: quality of results (QoR) prediction and
functional reasoning. Our experimental results indicate that (1) HOGA reduces
estimation error over conventional GNNs by 46.76% for predicting QoR after
logic synthesis; (2) HOGA improves 10.0% reasoning accuracy over GNNs for
identifying functional blocks on unseen gate-level netlists after complex
technology mapping; (3) The training time for HOGA almost linearly decreases
with an increase in computing resources.
",2024-03-02 21:33:23+00:00,cs.LG
"On Robustness and Generalization of ML-Based Congestion Predictors to
  Valid and Imperceptible Perturbations","  There is substantial interest in the use of machine learning (ML)-based
techniques throughout the electronic computer-aided design (CAD) flow,
particularly methods based on deep learning. However, while deep learning
methods have achieved state-of-the-art performance in several applications,
recent work has demonstrated that neural networks are generally vulnerable to
small, carefully chosen perturbations of their input (e.g. a single pixel
change in an image). In this work, we investigate robustness in the context of
ML-based EDA tools -- particularly for congestion prediction. As far as we are
aware, we are the first to explore this concept in the context of ML-based EDA.
  We first describe a novel notion of imperceptibility designed specifically
for VLSI layout problems defined on netlists and cell placements. Our
definition of imperceptibility is characterized by a guarantee that a
perturbation to a layout will not alter its global routing. We then demonstrate
that state-of-the-art CNN and GNN-based congestion models exhibit brittleness
to imperceptible perturbations. Namely, we show that when a small number of
cells (e.g. 1%-5% of cells) have their positions shifted such that a measure of
global congestion is guaranteed to remain unaffected (e.g. 1% of the design
adversarially shifted by 0.001% of the layout space results in a predicted
decrease in congestion of up to 90%, while no change in congestion is implied
by the perturbation). In other words, the quality of a predictor can be made
arbitrarily poor (i.e. can be made to predict that a design is
""congestion-free"") for an arbitrary input layout. Next, we describe a simple
technique to train predictors that improves robustness to these perturbations.
Our work indicates that CAD engineers should be cautious when integrating
neural network-based mechanisms in EDA flows to ensure robust and high-quality
results.
",2024-02-29 20:11:47+00:00,cs.LG
An All-Optical General-Purpose CPU and Optical Computer Architecture,"  Energy efficiency of electronic digital processors is primarily limited by
the energy consumption of electronic communication and interconnects. The
industry is almost unanimously pushing towards replacing both long-haul, as
well as local chip interconnects, using optics to drastically increase
efficiency. In this paper, we explore what comes after the successful migration
to optical interconnects, as with this inefficiency solved, the main source of
energy consumption will be electronic digital computing, memory and
electro-optical conversion. Our approach attempts to address all these issues
by introducing efficient all-optical digital computing and memory, which in
turn eliminates the need for electro-optical conversions. Here, we demonstrate
for the first time a scheme to enable general purpose digital data processing
in an integrated form and present our photonic integrated circuit (PIC)
implementation. For this demonstration we implemented a URISC architecture
capable of running any classical piece of software all-optically and present a
comprehensive architectural framework for all-optical computing to go beyond.
",2024-02-29 15:49:25+00:00,cs.ET
"Always be Pre-Training: Representation Learning for Network Intrusion
  Detection with GNNs","  Graph neural network-based network intrusion detection systems have recently
demonstrated state-of-the-art performance on benchmark datasets. Nevertheless,
these methods suffer from a reliance on target encoding for data
pre-processing, limiting widespread adoption due to the associated need for
annotated labels--a cost-prohibitive requirement. In this work, we propose a
solution involving in-context pre-training and the utilization of dense
representations for categorical features to jointly overcome the
label-dependency limitation. Our approach exhibits remarkable data efficiency,
achieving over 98% of the performance of the supervised state-of-the-art with
less than 4% labeled data on the NF-UQ-NIDS-V2 dataset.
",2024-02-29 09:40:07+00:00,cs.CR
"Can GPT Improve the State of Prior Authorization via Guideline Based
  Automated Question Answering?","  Health insurance companies have a defined process called prior authorization
(PA) which is a health plan cost-control process that requires doctors and
other healthcare professionals to get clearance in advance from a health plan
before performing a particular procedure on a patient in order to be eligible
for payment coverage. For health insurance companies, approving PA requests for
patients in the medical domain is a time-consuming and challenging task. One of
those key challenges is validating if a request matches up to certain criteria
such as age, gender, etc. In this work, we evaluate whether GPT can validate
numerous key factors, in turn helping health plans reach a decision drastically
faster. We frame it as a question answering task, prompting GPT to answer a
question from patient electronic health record. We experiment with different
conventional prompting techniques as well as introduce our own novel prompting
technique. Moreover, we report qualitative assessment by humans on the natural
language generation outputs from our approach. Results show that our method
achieves superior performance with the mean weighted F1 score of 0.61 as
compared to its standard counterparts.
",2024-02-28 15:39:53+00:00,cs.CL
Neuromorphic Event-Driven Semantic Communication in Microgrids,"  Synergies between advanced communications, computing and artificial
intelligence are unraveling new directions of coordinated operation and
resiliency in microgrids. On one hand, coordination among sources is
facilitated by distributed, privacy-minded processing at multiple locations,
whereas on the other hand, it also creates exogenous data arrival paths for
adversaries that can lead to cyber-physical attacks amongst other reliability
issues in the communication layer. This long-standing problem necessitates new
intrinsic ways of exchanging information between converters through power lines
to optimize the system's control performance. Going beyond the existing power
and data co-transfer technologies that are limited by efficiency and
scalability concerns, this paper proposes neuromorphic learning to implant
communicative features using spiking neural networks (SNNs) at each node, which
is trained collaboratively in an online manner simply using the power exchanges
between the nodes. As opposed to the conventional neuromorphic sensors that
operate with spiking signals, we employ an event-driven selective process to
collect sparse data for training of SNNs. Finally, its multi-fold effectiveness
and reliable performance is validated under simulation conditions with
different microgrid topologies and components to establish a new direction in
the sense-actuate-compute cycle for power electronic dominated grids and
microgrids.
",2024-02-28 15:11:02+00:00,cs.ET
"Self-Supervised Learning with Generative Adversarial Networks for
  Electron Microscopy","  In this work, we explore the potential of self-supervised learning with
Generative Adversarial Networks (GANs) for electron microscopy datasets. We
show how self-supervised pretraining facilitates efficient fine-tuning for a
spectrum of downstream tasks, including semantic segmentation, denoising, noise
\& background removal, and super-resolution. Experimentation with varying model
complexities and receptive field sizes reveals the remarkable phenomenon that
fine-tuned models of lower complexity consistently outperform more complex
models with random weight initialization. We demonstrate the versatility of
self-supervised pretraining across various downstream tasks in the context of
electron microscopy, allowing faster convergence and better performance. We
conclude that self-supervised pretraining serves as a powerful catalyst, being
especially advantageous when limited annotated data are available and efficient
scaling of computational cost is important.
",2024-02-28 12:25:01+00:00,cs.CV
"Data augmentation method for modeling health records with applications
  to clopidogrel treatment failure detection","  We present a novel data augmentation method to address the challenge of data
scarcity in modeling longitudinal patterns in Electronic Health Records (EHR)
of patients using natural language processing (NLP) algorithms. The proposed
method generates augmented data by rearranging the orders of medical records
within a visit where the order of elements are not obvious, if any. Applying
the proposed method to the clopidogrel treatment failure detection task enabled
up to 5.3% absolute improvement in terms of ROC-AUC (from 0.908 without
augmentation to 0.961 with augmentation) when it was used during the
pre-training procedure. It was also shown that the augmentation helped to
improve performance during fine-tuning procedures, especially when the amount
of labeled training data is limited.
",2024-02-28 04:47:32+00:00,cs.LG
Research on the evolution of smart meter technology,"  Smart meter is not only a device used to measure the amount of electricity,
but also a core component of the smart grid, realizing the efficient
monitoring, prediction and management of power use. With an insight into the
evolution of smart meter technology, I realized that this change didn't happen
overnight. It has undergone a long journey from the initial mechanical
electricity meters to the electronic electricity meters, and now to the highly
intelligent electricity meters. Technological breakthroughs at each stage have
laid the foundation for the final form of smart meters. In the era of
mechanical watt-hour meters, the measurement of electric energy mainly depends
on the rotation and counting of mechanical structures. The accuracy and
stability of this method are affected by mechanical wear, environmental
interference and other factors, and it is difficult to meet the increasing
demand for power management. With the rapid development of electronic
technology, the electronic electricity meter came into being. It uses
electronic technology to sample and process the current and voltage, which
greatly improves the accuracy and stability of the measurement. At the same
time, the electronic electricity meter also has the function of remote meter
reading and data processing, which has brought great convenience to the power
management. However, there still have some limitations, such as the complexity
of data processing and the limitation of communication capacity. It is these
challenges that drive the creation of smart power meters. smart meters combine
advanced technologies such as the Internet of Things, big data and cloud
computing to realize the real-time monitoring, analysis and prediction of the
use of power.
",2024-02-28 02:49:49+00:00,cs.OH
"Collaborative learning of common latent representations in routinely
  collected multivariate ICU physiological signals","  In Intensive Care Units (ICU), the abundance of multivariate time series
presents an opportunity for machine learning (ML) to enhance patient
phenotyping. In contrast to previous research focused on electronic health
records (EHR), here we propose an ML approach for phenotyping using routinely
collected physiological time series data. Our new algorithm integrates Long
Short-Term Memory (LSTM) networks with collaborative filtering concepts to
identify common physiological states across patients. Tested on real-world ICU
clinical data for intracranial hypertension (IH) detection in patients with
brain injury, our method achieved an area under the curve (AUC) of 0.889 and
average precision (AP) of 0.725. Moreover, our algorithm outperforms
autoencoders in learning more structured latent representations of the
physiological signals. These findings highlight the promise of our methodology
for patient phenotyping, leveraging routinely collected multivariate time
series to improve clinical care practices.
",2024-02-27 22:10:51+00:00,cs.LG
"Reducing Unnecessary Alerts in Pedestrian Protection Systems Based on
  P2V Communications","  There are different proposals in the literature on how to protect pedestrians
using warning systems to alert drivers of their presence. They can be based on
onboard perception systems or wireless communications. The evaluation of these
systems has been focused on testing their ability to detect pedestrians. A
problem that has received much less attention is the possibility of generating
too many alerts in the warning systems. In this paper, we propose and analyze
four different algorithms to take the decision on generating alerts in a
warning system that is based on direct wireless communications between vehicles
and pedestrians. With the algorithms, we explore different strategies to reduce
unnecessary alerts. The feasibility of the implementation of the algorithms was
evaluated with a deployment using real equipment, and tests were carried out to
verify their behavior in real scenarios. The ability of each algorithm to
reduce unnecessary alerts was evaluated with realistic simulations in an urban
scenario, using a traffic simulator with vehicular and pedestrian flows. The
results show the importance of tackling the problem of driver overload in
warning systems, and that it is not straightforward to predict the load of
alerts generated by an algorithm in a large-scale deployment, in which there
are multiple interactions between vehicles and pedestrians.
",2024-02-27 18:55:50+00:00,cs.NI
"A Scalable Multi-Layered Blockchain Architecture for Enhanced EHR
  Sharing and Drug Supply Chain Management","  In recent years, the healthcare sector's shift to online platforms has
spotlighted challenges concerning data security, privacy, and scalability.
Blockchain technology, known for its decentralized, secure, and immutable
nature, emerges as a viable solution for these pressing issues. This article
presents an innovative Electronic Health Records (EHR) sharing and drug supply
chain management framework tailored to address scalability, security, data
integrity, traceability, and secure data sharing. The framework introduces five
layers and transactions, prioritizing patient-centric healthcare by granting
patients comprehensive access control over their health information. This
access facilitates smoother processes, such as insurance claims, while
maintaining robust security measures. Notably, our implementation of
parallelism significantly bolsters scalability and transaction throughput while
minimizing network traffic. Performance evaluations conducted through the
Caliper benchmark indicate a slight increase in processor consumption during
specific transactions, mitigated effectively by parallelization. RAM
requirements remain largely stable. Additionally, our approach notably reduces
network traffic while tripling transaction throughput. The framework ensures
patient privacy, data integrity, access control, and interoperability, aligning
with traditional healthcare systems. Moreover, it provides transparency and
real-time drug supply monitoring, empowering decision-makers with actionable
insights. As healthcare evolves, our framework sets a crucial precedent for
innovative, scalable, and secure systems. Future enhancements could focus on
scalability, real-world deployment, standardized data formats, reinforced
security protocols, privacy preservation, and IoT integration to comply with
regulations and meet evolving industry needs.
",2024-02-27 09:20:16+00:00,cs.CR
"Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer
  Medication Effects Using Natural Language Processing","  Breast cancer is a significant public health concern and is the leading cause
of cancer-related deaths among women. Despite advances in breast cancer
treatments, medication non-adherence remains a major problem. As electronic
health records do not typically capture patient-reported outcomes that may
reveal information about medication-related experiences, social media presents
an attractive resource for enhancing our understanding of the patients'
treatment experiences. In this paper, we developed natural language processing
(NLP) based methodologies to study information posted by an automatically
curated breast cancer cohort from social media. We employed a transformer-based
classifier to identify breast cancer patients/survivors on X (Twitter) based on
their self-reported information, and we collected longitudinal data from their
profiles. We then designed a multi-layer rule-based model to develop a breast
cancer therapy-associated side effect lexicon and detect patterns of medication
usage and associated side effects among breast cancer patients. 1,454,637 posts
were available from 583,962 unique users, of which 62,042 were detected as
breast cancer members using our transformer-based model. 198 cohort members
mentioned breast cancer medications with tamoxifen as the most common. Our side
effect lexicon identified well-known side effects of hormone and chemotherapy.
Furthermore, it discovered a subject feeling towards cancer and medications,
which may suggest a pre-clinical phase of side effects or emotional distress.
This analysis highlighted not only the utility of NLP techniques in
unstructured social media data to identify self-reported breast cancer posts,
medication usage patterns, and treatment side effects but also the richness of
social data on such clinical questions.
",2024-02-26 16:17:19+00:00,cs.CL
"Domain Embeddings for Generating Complex Descriptions of Concepts in
  Italian Language","  In this work, we propose a Distributional Semantic resource enriched with
linguistic and lexical information extracted from electronic dictionaries,
designed to address the challenge of bridging the gap between the continuous
semantic values represented by distributional vectors and the discrete
descriptions offered by general semantics theory. Recently, many researchers
have concentrated on the nexus between embeddings and a comprehensive theory of
semantics and meaning. This often involves decoding the representation of word
meanings in Distributional Models into a set of discrete, manually constructed
properties such as semantic primitives or features, using neural decoding
techniques. Our approach introduces an alternative strategy grounded in
linguistic data. We have developed a collection of domain-specific
co-occurrence matrices, derived from two sources: a classification of Italian
nouns categorized into 4 semantic traits and 20 concrete noun sub-categories,
and a list of Italian verbs classified according to their semantic classes. In
these matrices, the co-occurrence values for each word are calculated
exclusively with a defined set of words pertinent to a particular lexical
domain. The resource comprises 21 domain-specific matrices, one comprehensive
matrix, and a Graphical User Interface. Our model facilitates the generation of
reasoned semantic descriptions of concepts by selecting matrices directly
associated with concrete conceptual knowledge, such as a matrix based on
location nouns and the concept of animal habitats. We assessed the utility of
the resource through two experiments, achieving promising outcomes in both: the
automatic classification of animal nouns and the extraction of animal features.
",2024-02-26 15:04:35+00:00,cs.CL
"RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic
  Health Records","  We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical
predictions on Electronic Health Records (EHRs). RAM-EHR first collects
multiple knowledge sources, converts them into text format, and uses dense
retrieval to obtain information related to medical concepts. This strategy
addresses the difficulties associated with complex names for the concepts.
RAM-EHR then augments the local EHR predictive model co-trained with
consistency regularization to capture complementary information from patient
visits and summarized knowledge. Experiments on two EHR datasets show the
efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in
AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized
knowledge from RAM-EHR for clinical prediction tasks. The code will be
published at \url{https://github.com/ritaranx/RAM-EHR}.
",2024-02-25 23:10:20+00:00,cs.CL
"EHRNoteQA: An LLM Benchmark for Real-World Clinical Practice Using
  Discharge Summaries","  Discharge summaries in Electronic Health Records (EHRs) are crucial for
clinical decision-making, but their length and complexity make information
extraction challenging, especially when dealing with accumulated summaries
across multiple patient admissions. Large Language Models (LLMs) show promise
in addressing this challenge by efficiently analyzing vast and complex data.
Existing benchmarks, however, fall short in properly evaluating LLMs'
capabilities in this context, as they typically focus on single-note
information or limited topics, failing to reflect the real-world inquiries
required by clinicians. To bridge this gap, we introduce EHRNoteQA, a novel
benchmark built on the MIMIC-IV EHR, comprising 962 different QA pairs each
linked to distinct patients' discharge summaries. Every QA pair is initially
generated using GPT-4 and then manually reviewed and refined by three
clinicians to ensure clinical relevance. EHRNoteQA includes questions that
require information across multiple discharge summaries and covers eight
diverse topics, mirroring the complexity and diversity of real clinical
inquiries. We offer EHRNoteQA in two formats: open-ended and multi-choice
question answering, and propose a reliable evaluation method for each. We
evaluate 27 LLMs using EHRNoteQA and examine various factors affecting the
model performance (e.g., the length and number of discharge summaries).
Furthermore, to validate EHRNoteQA as a reliable proxy for expert evaluations
in clinical practice, we measure the correlation between the LLM performance on
EHRNoteQA, and the LLM performance manually evaluated by clinicians. Results
show that LLM performance on EHRNoteQA have higher correlation with
clinician-evaluated performance (Spearman: 0.78, Kendall: 0.62) compared to
other benchmarks, demonstrating its practical relevance in evaluating LLMs in
clinical settings.
",2024-02-25 09:41:50+00:00,cs.CL
Securing Bluetooth Low Energy: A Literature Review,"  Bluetooth Low Energy (BLE) technology, operating within the widely used 2.4
GHz ISM band, stands as a cornerstone in modern wireless communication
frameworks alongside its classic Bluetooth counterpart. This paper delves into
the foundational aspects of BLE, excluding niche components, to explore its
core functionalities and pivotal role in diverse connectivity needs. BLE's
specialization in catering to low-power devices ensures optimal energy
utilization, making it indispensable in IoT applications where energy
efficiency is paramount. Its versatility finds applications across consumer
electronics, industrial automation, and healthcare, ensuring reliability and
efficiency in safety-critical systems and enhancing user convenience through
remote control capabilities. However, the wireless nature of BLE interfaces
exposes them to cybersecurity threats, necessitating robust security measures
for mitigating risks such as sniffing, DoS attacks, and message injection.
Continuous research and development efforts are essential to stay ahead of
emerging threats and safeguard BLE-enabled systems and data.
",2024-02-24 23:08:44+00:00,cs.CR
"Understanding Missingness in Time-series Electronic Health Records for
  Individualized Representation","  With the widespread of machine learning models for healthcare applications,
there is increased interest in building applications for personalized medicine.
Despite the plethora of proposed research for personalized medicine, very few
focus on representing missingness and learning from the missingness patterns in
time-series Electronic Health Records (EHR) data. The lack of focus on
missingness representation in an individualized way limits the full utilization
of machine learning applications towards true personalization. In this brief
communication, we highlight new insights into patterns of missingness with
real-world examples and implications of missingness in EHRs. The insights in
this work aim to bridge the gap between theoretical assumptions and practical
observations in real-world EHRs. We hope this work will open new doors for
exploring directions for better representation in predictive modelling for true
personalization.
",2024-02-24 05:48:39+00:00,cs.LG
"Optimized Deployment of Deep Neural Networks for Visual Pose Estimation
  on Nano-drones","  Miniaturized autonomous unmanned aerial vehicles (UAVs) are gaining
popularity due to their small size, enabling new tasks such as indoor
navigation or people monitoring. Nonetheless, their size and simple electronics
pose severe challenges in implementing advanced onboard intelligence. This work
proposes a new automatic optimization pipeline for visual pose estimation tasks
using Deep Neural Networks (DNNs). The pipeline leverages two different Neural
Architecture Search (NAS) algorithms to pursue a vast complexity-driven
exploration in the DNNs' architectural space. The obtained networks are then
deployed on an off-the-shelf nano-drone equipped with a parallel ultra-low
power System-on-Chip leveraging a set of novel software kernels for the
efficient fused execution of critical DNN layer sequences. Our results improve
the state-of-the-art reducing inference latency by up to 3.22x at iso-error.
",2024-02-23 11:35:57+00:00,cs.CV
"A$^3$PIM: An Automated, Analytic and Accurate Processing-in-Memory
  Offloader","  The performance gap between memory and processor has grown rapidly.
Consequently, the energy and wall-clock time costs associated with moving data
between the CPU and main memory predominate the overall computational cost. The
Processing-in-Memory (PIM) paradigm emerges as a promising architecture that
mitigates the need for extensive data movements by strategically positioning
computing units proximate to the memory. Despite the abundant efforts devoted
to building a robust and highly-available PIM system, identifying PIM-friendly
segments of applications poses significant challenges due to the lack of a
comprehensive tool to evaluate the intrinsic memory access pattern of the
segment.
  To tackle this challenge, we propose A$^3$PIM: an Automated, Analytic and
Accurate Processing-in-Memory offloader. We systematically consider the
cross-segment data movement and the intrinsic memory access pattern of each
code segment via static code analyzer. We evaluate A$^3$PIM across a wide range
of real-world workloads including GAP and PrIM benchmarks and achieve an
average speedup of 2.63x and 4.45x (up to 7.14x and 10.64x) when compared to
CPU-only and PIM-only executions, respectively.
",2024-02-23 02:24:31+00:00,cs.AR
"Automated Design and Optimization of Distributed Filtering Circuits via
  Reinforcement Learning","  Designing distributed filter circuits (DFCs) is complex and time-consuming,
involving setting and optimizing multiple hyperparameters. Traditional
optimization methods, such as using the commercial finite element solver HFSS
(High-Frequency Structure Simulator) to enumerate all parameter combinations
with fixed steps and then simulate each combination, are not only
time-consuming and labor-intensive but also rely heavily on the expertise and
experience of electronics engineers, making it difficult to adapt to rapidly
changing design requirements. Additionally, these commercial tools struggle
with precise adjustments when parameters are sensitive to numerical changes,
resulting in limited optimization effectiveness. This study proposes a novel
end-to-end automated method for DFC design. The proposed method harnesses
reinforcement learning (RL) algorithms, eliminating the dependence on the
design experience of engineers. Thus, it significantly reduces the subjectivity
and constraints associated with circuit design. The experimental findings
demonstrate clear improvements in design efficiency and quality when comparing
the proposed method with traditional engineer-driven methods. Furthermore, the
proposed method achieves superior performance when designing complex or rapidly
evolving DFCs, highlighting the substantial potential of RL in circuit design
automation. In particular, compared to the existing DFC automation design
method CircuitGNN, our method achieves an average performance improvement of
8.72%. Additionally, the execution efficiency of our method is 2000 times
higher than CircuitGNN on the CPU and 241 times higher on the GPU.
",2024-02-22 02:36:14+00:00,cs.LG
"A Combined Learning and Optimization Framework to Transfer Human
  Whole-body Loco-manipulation Skills to Mobile Manipulators","  Humans' ability to smoothly switch between locomotion and manipulation is a
remarkable feature of sensorimotor coordination. Leaning and replication of
such human-like strategies can lead to the development of more sophisticated
robots capable of performing complex whole-body tasks in real-world
environments. To this end, this paper proposes a combined learning and
optimization framework for transferring human's loco-manipulation
soft-switching skills to mobile manipulators. The methodology departs from data
collection of human demonstrations for a locomotion-integrated manipulation
task through a vision system. Next, the wrist and pelvis motions are mapped to
mobile manipulators' End-Effector (EE) and mobile base. A kernelized movement
primitive algorithm learns the wrist and pelvis trajectories and generalizes to
new desired points according to task requirements. Next, the reference
trajectories are sent to a hierarchical quadratic programming controller, where
the EE and the mobile base reference trajectories are provided as the first and
second priority tasks, generating the feasible and optimal joint level
commands. A locomotion-integrated pick-and-place task is executed to validate
the proposed approach. After a human demonstrates the task, a mobile
manipulator executes the task with the same and new settings, grasping a bottle
at non-zero velocity. The results showed that the proposed approach
successfully transfers the human loco-manipulation skills to mobile
manipulators, even with different geometry.
",2024-02-21 16:31:07+00:00,cs.RO
"Design of a Miniature Underwater Vehicle and Data Collection System for
  Indoor Experimentation","  This paper describes the design of a miniature uncrewed underwater vehicle
(MiniUUV) and related instrumentation for indoor experimentation. The MiniUUV
was developed using 3D printed components and low-cost, off-the-shelf
electronics. The vehicle uses a propeller differential propulsion drive and a
peristaltic pump with a syringe for buoyancy control. A water tank with an
overhead camera system was constructed to allow for convenient indoor data
collection in a controlled environment. Several tests were conducted to
demonstrate the capabilities of the MiniUUV and data collection system,
including buoyancy pump actuation tests and straight line, circular, and
zig-zag motion tests on the surface. During each planar motion test an AprilTag
was attached to the MiniUUV and an overhead camera system obtained video
recordings that were processed offline to estimate vehicle position, surge
velocity, sway velocity, yaw angle, and yaw rate.
",2024-02-21 14:29:27+00:00,cs.RO
A unified framework of non-local parametric methods for image denoising,"  We propose a unified view of non-local methods for single-image denoising,
for which BM3D is the most popular representative, that operate by gathering
noisy patches together according to their similarities in order to process them
collaboratively. Our general estimation framework is based on the minimization
of the quadratic risk, which is approximated in two steps, and adapts to photon
and electronic noises. Relying on unbiased risk estimation (URE) for the first
step and on ``internal adaptation'', a concept borrowed from deep learning
theory, for the second, we show that our approach enables to reinterpret and
reconcile previous state-of-the-art non-local methods. Within this framework,
we propose a novel denoiser called NL-Ridge that exploits linear combinations
of patches. While conceptually simpler, we show that NL-Ridge can outperform
well-established state-of-the-art single-image denoisers.
",2024-02-21 13:55:48+00:00,cs.CV
Using Harmonics for Low-Cost Jamming,"  The digitalisation of the modern schooling system has led to multiple schools
and organisations buying similar hardware. Electronic equipment like wireless
microphones, projectors, touchscreen displays etc., have been almost
standardised with a few well-known brands leading the market. This has led to
the adoption of common frequency ranges between brands with many sticking
between 600-670 MHz. The popularity of low-cost computing devices like the
Raspberry Pi which has been used in a plethora of applications has also taken
the path of being used as low-cost transmitters. There have been many
implementations where the Raspberry Pi has been used as the target device but
few cases where the PI is the actual threat. In this paper, we explore the use
of the Raspberry Pi as a stealth radio frequency jamming device to disable
wireless conference microphones. Harmonics were used to achieve frequencies
outside the Pi's transmission frequency by taking advantage of its unfiltered
transmission.
",2024-02-21 13:15:59+00:00,cs.CR
"Multimodal Fusion of EHR in Structures and Semantics: Integrating
  Clinical Records and Notes with Hypergraph and LLM","  Electronic Health Records (EHRs) have become increasingly popular to support
clinical decision-making and healthcare in recent decades. EHRs usually contain
heterogeneous information, such as structural data in tabular form and
unstructured data in textual notes. Different types of information in EHRs can
complement each other and provide a more complete picture of the health status
of a patient. While there has been a lot of research on representation learning
of structured EHR data, the fusion of different types of EHR data (multimodal
fusion) is not well studied. This is mostly because of the complex medical
coding systems used and the noise and redundancy present in the written notes.
In this work, we propose a new framework called MINGLE, which integrates both
structures and semantics in EHR effectively. Our framework uses a two-level
infusion strategy to combine medical concept semantics and clinical note
semantics into hypergraph neural networks, which learn the complex interactions
between different types of data to generate visit representations for
downstream prediction. Experiment results on two EHR datasets, the public
MIMIC-III and private CRADLE, show that MINGLE can effectively improve
predictive performance by 11.83% relatively, enhancing semantic integration as
well as multimodal fusion for structural and textual EHR data.
",2024-02-19 23:48:40+00:00,cs.LG
A Machine Learning Ensemble Model for the Detection of Cyberbullying,"  The pervasive use of social media platforms, such as Facebook, Instagram, and
X, has significantly amplified our electronic interconnectedness. Moreover,
these platforms are now easily accessible from any location at any given time.
However, the increased popularity of social media has also led to
cyberbullying.It is imperative to address the need for finding, monitoring, and
mitigating cyberbullying posts on social media platforms. Motivated by this
necessity, we present this paper to contribute to developing an automated
system for detecting binary labels of aggressive tweets.Our study has
demonstrated remarkable performance compared to previous experiments on the
same dataset. We employed the stacking ensemble machine learning method,
utilizing four various feature extraction techniques to optimize performance
within the stacking ensemble learning framework. Combining five machine
learning algorithms,Decision Trees, Random Forest, Linear Support Vector
Classification, Logistic Regression, and K-Nearest Neighbors into an ensemble
method, we achieved superior results compared to traditional machine learning
classifier models. The stacking classifier achieved a high accuracy rate of
94.00%, outperforming traditional machine learning models and surpassing the
results of prior experiments that utilized the same dataset. The outcomes of
our experiments showcased an accuracy rate of 0.94% in detection tweets as
aggressive or non-aggressive.
",2024-02-19 20:55:12+00:00,cs.SI
"Low-power SNN-based audio source localisation using a Hilbert Transform
  spike encoding scheme","  Sound source localisation is used in many consumer electronics devices, to
help isolate audio from individual speakers and to reject noise. Localization
is frequently accomplished by ""beamforming"" algorithms, which combine
microphone audio streams to improve received signal power from particular
incident source directions. Beamforming algorithms generally use knowledge of
the frequency components of the audio source, along with the known microphone
array geometry, to analytically phase-shift microphone streams before combining
them. A dense set of band-pass filters is often used to obtain known-frequency
""narrowband"" components from wide-band audio streams. These approaches achieve
high accuracy, but state of the art narrowband beamforming algorithms are
computationally demanding, and are therefore difficult to integrate into
low-power IoT devices. We demonstrate a novel method for sound source
localisation in arbitrary microphone arrays, designed for efficient
implementation in ultra-low-power spiking neural networks (SNNs). We use a
novel short-time Hilbert transform (STHT) to remove the need for demanding
band-pass filtering of audio, and introduce a new accompanying method for audio
encoding with spiking events. Our beamforming and localisation approach
achieves state-of-the-art accuracy for SNN methods, and comparable with
traditional non-SNN super-resolution approaches. We deploy our method to
low-power SNN audio inference hardware, and achieve much lower power
consumption compared with super-resolution methods. We demonstrate that signal
processing approaches can be co-designed with spiking neural network
implementations to achieve high levels of power efficiency. Our new
Hilbert-transform-based method for beamforming promises to also improve the
efficiency of traditional DSP-based signal processing.
",2024-02-19 00:21:13+00:00,cs.SD
Publicly auditable privacy-preserving electoral rolls,"  While existing literature on electronic voting has extensively addressed
verifiability of voting protocols, the vulnerability of electoral rolls in
large public elections remains a critical concern. To ensure integrity of
electoral rolls, the current practice is to either make electoral rolls public
or share them with the political parties. However, this enables construction of
detailed voter profiles and selective targeting and manipulation of voters,
thereby undermining the fundamental principle of free and fair elections. In
this paper, we study the problem of designing publicly auditable yet
privacy-preserving electoral rolls. We first formulate a threat model and
provide formal security definitions. We then present a protocol for creation,
maintenance and usage of electoral rolls that mitigates the threats. Eligible
voters can verify their inclusion, whereas political parties and auditors can
statistically audit the electoral roll. Further, the audit can also detect
polling-day ballot stuffing and denials to eligible voters by malicious polling
officers. The entire electoral roll is never revealed, which prevents any
large-scale systematic voter targeting and manipulation.
",2024-02-18 13:11:48+00:00,cs.CR
"Point-Wise Vibration Pattern Production via a Sparse Actuator Array for
  Surface Tactile Feedback","  Surface vibration tactile feedback is capable of conveying various semantic
information to humans via the handheld electronic devices, like smartphone,
touch panel,and game controller. However, covering the whole device contacting
surface with dense actuator arrangement can affect its normal use, how to
produce desired vibration patterns at any contact point with only several
sparse actuators deployed on the handled device surface remains a significant
challenge. In this work, we develop a tactile feedback board with only five
actuators in the size of a smartphone, and achieve the precise vibration
pattern production that can focus at any desired position all over the board.
Specifically, we investigate the vibration characteristics of single passive
coil actuator, and construct its vibration pattern model at any position on the
feedback board surface. Optimal phase and amplitude modulation, found with the
simulated annealing algorithm, is employed with five actuators in a sparse
array. And all actuators' vibration patterns are superimposed linearly to
synthetically generate different onboard vibration energy distribution for
tactile sensing. Experiments demonstrated that for point-wise vibration pattern
production on our tactile board achieved an average level of about 0.9 in the
Structural Similarity Index Measure (SSIM) evaluation, when compared to the
ideal single-point-focused target vibration pattern. The sparse actuator array
can be easily embedded into usual handheld electronic devices, which shows a
good significant implication for enriching their haptic interaction
functionalities.
",2024-02-18 07:54:30+00:00,cs.RO
VoltSchemer: Use Voltage Noise to Manipulate Your Wireless Charger,"  Wireless charging is becoming an increasingly popular charging solution in
portable electronic products for a more convenient and safer charging
experience than conventional wired charging. However, our research identified
new vulnerabilities in wireless charging systems, making them susceptible to
intentional electromagnetic interference. These vulnerabilities facilitate a
set of novel attack vectors, enabling adversaries to manipulate the charger and
perform a series of attacks.
  In this paper, we propose VoltSchemer, a set of innovative attacks that grant
attackers control over commercial-off-the-shelf wireless chargers merely by
modulating the voltage from the power supply. These attacks represent the first
of its kind, exploiting voltage noises from the power supply to manipulate
wireless chargers without necessitating any malicious modifications to the
chargers themselves. The significant threats imposed by VoltSchemer are
substantiated by three practical attacks, where a charger can be manipulated
to: control voice assistants via inaudible voice commands, damage devices being
charged through overcharging or overheating, and bypass Qi-standard specified
foreign-object-detection mechanism to damage valuable items exposed to intense
magnetic fields.
  We demonstrate the effectiveness and practicality of the VoltSchemer attacks
with successful attacks on 9 top-selling COTS wireless chargers. Furthermore,
we discuss the security implications of our findings and suggest possible
countermeasures to mitigate potential threats.
",2024-02-18 01:50:27+00:00,cs.CR
"A Question Answering Based Pipeline for Comprehensive Chinese EHR
  Information Extraction","  Electronic health records (EHRs) hold significant value for research and
applications. As a new way of information extraction, question answering (QA)
can extract more flexible information than conventional methods and is more
accessible to clinical researchers, but its progress is impeded by the scarcity
of annotated data. In this paper, we propose a novel approach that
automatically generates training data for transfer learning of QA models. Our
pipeline incorporates a preprocessing module to handle challenges posed by
extraction types that are not readily compatible with extractive QA frameworks,
including cases with discontinuous answers and many-to-one relationships. The
obtained QA model exhibits excellent performance on subtasks of information
extraction in EHRs, and it can effectively handle few-shot or zero-shot
settings involving yes-no questions. Case studies and ablation studies
demonstrate the necessity of each component in our design, and the resulting
model is deemed suitable for practical use.
",2024-02-17 02:55:35+00:00,cs.CL
"A Low-Dissipation and Scalable GEMM Accelerator with Silicon Nitride
  Photonics","  Over the past few years, several microring resonator (MRR)-based analog
photonic architectures have been proposed to accelerate general matrix-matrix
multiplications (GEMMs), which are found in abundance in deep learning
workloads.These architectures have dramatically grown in popularity because
they offer exceptional throughput and energy efficiency compared to their
electronic counterparts. However, such architectures, due to their traditional
realization based on the silicon-on-insulator (SOI) material platform, face two
shortcomings. First, the high-index contrast of the SOI platform incurs high
scattering losses, which mandates the provisioning of high optical input
power.Second, SOI waveguides are susceptible to two-photon absorption, which
can incur substantial optical signal losses at moderate-to-high signal fan-in.
These shortcomings have severely detrimental effects on the achievable
parallelism, throughput, and energy efficiency of SOI MRR-based GEMM
accelerators. To address these shortcomings, we present a novel Silicon Nitride
(SiN)-Based Photonic GEMM Accelerator called SiNPhAR. SiNPhAR architecture
employs SiN-based active and passive devices to implement analog GEMM
functions. Since the SiN material exhibits lower index contrast and no TPA, the
optical signal losses in our SiNPhAR architecture are very low. This advantage
significantly enhances the achievable processing parallelism, throughput, and
energy efficiency of SiNPhAR architecture, compared to SOI-based photonic GEMM
accelerators from prior work. We quantify and compare these benefits of SiNPhAR
architecture via our cross-layer evaluation for a benchmark workload comprising
four modern deep neural network models. From the system-level performance
analysis, SiNPhAR demonstrates at least 1.7x better throughput FPS while
consuming at least 2.8x better energy efficiency (FPS/W) than prior SOI-based
GEMM accelerators.
",2024-02-16 19:50:22+00:00,cs.AR
Lightweight ciphers based on chaotic Map -- LFSR architectures,"  In this paper, we propose and analyze two different stream ciphers based on a
Skew Tent Map and a Modified Logistic Map respectively. In order to improve the
randomness of these systems, a single method for increasing the period length
of the generated sequences has been applied. The results prove that the
randomness of these systems can be severally increased by using this method,
making these systems suitable for secure communications.
",2024-02-16 18:16:31+00:00,cs.CR
"Deep Spectral Meshes: Multi-Frequency Facial Mesh Processing with Graph
  Neural Networks","  With the rising popularity of virtual worlds, the importance of data-driven
parametric models of 3D meshes has grown rapidly. Numerous applications, such
as computer vision, procedural generation, and mesh editing, vastly rely on
these models. However, current approaches do not allow for independent editing
of deformations at different frequency levels. They also do not benefit from
representing deformations at different frequencies with dedicated
representations, which would better expose their properties and improve the
generated meshes' geometric and perceptual quality. In this work, spectral
meshes are introduced as a method to decompose mesh deformations into
low-frequency and high-frequency deformations. These features of low- and
high-frequency deformations are used for representation learning with graph
convolutional networks. A parametric model for 3D facial mesh synthesis is
built upon the proposed framework, exposing user parameters that control
disentangled high- and low-frequency deformations. Independent control of
deformations at different frequencies and generation of plausible synthetic
examples are mutually exclusive objectives. A Conditioning Factor is introduced
to leverage these objectives. Our model takes further advantage of spectral
partitioning by representing different frequency levels with disparate, more
suitable representations. Low frequencies are represented with standardised
Euclidean coordinates, and high frequencies with a normalised deformation
representation (DR). This paper investigates applications of our proposed
approach in mesh reconstruction, mesh interpolation, and multi-frequency
editing. It is demonstrated that our method improves the overall quality of
generated meshes on most datasets when considering both the $L_1$ norm and
perceptual Dihedral Angle Mesh Error (DAME) metrics.
",2024-02-15 23:17:08+00:00,cs.CV
Self-consistent Validation for Machine Learning Electronic Structure,"  Machine learning has emerged as a significant approach to efficiently tackle
electronic structure problems. Despite its potential, there is less guarantee
for the model to generalize to unseen data that hinders its application in
real-world scenarios. To address this issue, a technique has been proposed to
estimate the accuracy of the predictions. This method integrates machine
learning with self-consistent field methods to achieve both low validation cost
and interpret-ability. This, in turn, enables exploration of the model's
ability with active learning and instills confidence in its integration into
real-world studies.
",2024-02-15 18:41:35+00:00,cs.LG
Towards Reducing Diagnostic Errors with Interpretable Risk Prediction,"  Many diagnostic errors occur because clinicians cannot easily access relevant
information in patient Electronic Health Records (EHRs). In this work we
propose a method to use LLMs to identify pieces of evidence in patient EHR data
that indicate increased or decreased risk of specific diagnoses; our ultimate
aim is to increase access to evidence and reduce diagnostic errors. In
particular, we propose a Neural Additive Model to make predictions backed by
evidence with individualized risk estimates at time-points where clinicians are
still uncertain, aiming to specifically mitigate delays in diagnosis and errors
stemming from an incomplete differential. To train such a model, it is
necessary to infer temporally fine-grained retrospective labels of eventual
""true"" diagnoses. We do so with LLMs, to ensure that the input text is from
before a confident diagnosis can be made. We use an LLM to retrieve an initial
pool of evidence, but then refine this set of evidence according to
correlations learned by the model. We conduct an in-depth evaluation of the
usefulness of our approach by simulating how it might be used by a clinician to
decide between a pre-defined list of differential diagnoses.
",2024-02-15 17:05:48+00:00,cs.AI
"Enabling data-driven and bidirectional model development in Verilog-A
  for photonic devices","  We present a method to model photonic components in Verilog-A by introducing
bidirectional signaling through a single port. To achieve this, the concept of
power waves and scattering parameters from electromagnetism are employed. As a
consequence, one can simultaneously transmit forward and backward propagating
waves on a single wire while also capturing realistic, measurement-backed
response of photonic components in Verilog-A. We demonstrate examples to show
the efficacy of the proposed technique in accounting for critical effects in
photonic integrated circuits such as Fabry-Perot cavity resonance, reflections
to lasers, etc. Our solution makes electronic-photonic co-simulation more
intuitive and accurate.
",2024-02-15 07:33:37+00:00,cs.ET
"GeoBotsVR: A Robotics Learning Game for Beginners with Hands-on Learning
  Simulation","  This article introduces GeoBotsVR, an easily accessible virtual reality game
that combines elements of puzzle-solving with robotics learning and aims to
cultivate interest and motivation in robotics, programming, and electronics
among individuals with limited experience in these domains. The game allows
players to build and customize a two-wheeled mobile robot using various robotic
components and use their robot to solve various procedurally-generated puzzles
in a diverse range of environments. An innovative aspect is the inclusion of a
repair feature, requiring players to address randomly generated electronics and
programming issues with their robot through hands-on manipulation. GeoBotsVR is
designed to be immersive, replayable, and practical application-based, offering
an enjoyable and accessible tool for beginners to acquaint themselves with
robotics. The game simulates a hands-on learning experience and does not
require prior technical knowledge, making it a potentially valuable resource
for beginners to get an engaging introduction to the field of robotics.
",2024-02-15 02:15:58+00:00,cs.HC
"Hybrid Machine Learning techniques in the management of harmful algal
  blooms impact","  Harmful algal blooms (HABs) are episodes of high concentrations of algae that
are potentially toxic for human consumption. Mollusc farming can be affected by
HABs because, as filter feeders, they can accumulate high concentrations of
marine biotoxins in their tissues. To avoid the risk to human consumption,
harvesting is prohibited when toxicity is detected. At present, the closure of
production areas is based on expert knowledge and the existence of a predictive
model would help when conditions are complex and sampling is not possible.
Although the concentration of toxin in meat is the method most commonly used by
experts in the control of shellfish production areas, it is rarely used as a
target by automatic prediction models. This is largely due to the irregularity
of the data due to the established sampling programs. As an alternative, the
activity status of production areas has been proposed as a target variable
based on whether mollusc meat has a toxicity level below or above the legal
limit. This new option is the most similar to the actual functioning of the
control of shellfish production areas. For this purpose, we have made a
comparison between hybrid machine learning models like Neural-Network-Adding
Bootstrap (BAGNET) and Discriminative Nearest Neighbor Classification (SVM-KNN)
when estimating the state of production areas. The study has been carried out
in several estuaries with different levels of complexity in the episodes of
algal blooms to demonstrate the generalization capacity of the models in bloom
detection. As a result, we could observe that, with an average recall value of
93.41% and without dropping below 90% in any of the estuaries, BAGNET
outperforms the other models both in terms of results and robustness.
",2024-02-14 15:59:22+00:00,cs.LG
"Machine Learning in management of precautionary closures caused by
  lipophilic biotoxins","  Mussel farming is one of the most important aquaculture industries. The main
risk to mussel farming is harmful algal blooms (HABs), which pose a risk to
human consumption. In Galicia, the Spanish main producer of cultivated mussels,
the opening and closing of the production areas is controlled by a monitoring
program. In addition to the closures resulting from the presence of toxicity
exceeding the legal threshold, in the absence of a confirmatory sampling and
the existence of risk factors, precautionary closures may be applied. These
decisions are made by experts without the support or formalisation of the
experience on which they are based. Therefore, this work proposes a predictive
model capable of supporting the application of precautionary closures.
Achieving sensitivity, accuracy and kappa index values of 97.34%, 91.83% and
0.75 respectively, the kNN algorithm has provided the best results. This allows
the creation of a system capable of helping in complex situations where
forecast errors are more common.
",2024-02-14 15:51:58+00:00,cs.AI
"Deinterleaving of Discrete Renewal Process Mixtures with Application to
  Electronic Support Measures","  In this paper, we propose a new deinterleaving method for mixtures of
discrete renewal Markov chains. This method relies on the maximization of a
penalized likelihood score. It exploits all available information about both
the sequence of the different symbols and their arrival times. A theoretical
analysis is carried out to prove that minimizing this score allows to recover
the true partition of symbols in the large sample limit, under mild conditions
on the component processes. This theoretical analysis is then validated by
experiments on synthetic data. Finally, the method is applied to deinterleave
pulse trains received from different emitters in a RESM (Radar Electronic
Support Measurements) context and we show that the proposed method competes
favorably with state-of-the-art methods on simulated warfare datasets.
",2024-02-14 13:32:23+00:00,cs.LG
Towards Realistic Landmark-Guided Facial Video Inpainting Based on GANs,"  Facial video inpainting plays a crucial role in a wide range of applications,
including but not limited to the removal of obstructions in video conferencing
and telemedicine, enhancement of facial expression analysis, privacy
protection, integration of graphical overlays, and virtual makeup. This domain
presents serious challenges due to the intricate nature of facial features and
the inherent human familiarity with faces, heightening the need for accurate
and persuasive completions. In addressing challenges specifically related to
occlusion removal in this context, our focus is on the progressive task of
generating complete images from facial data covered by masks, ensuring both
spatial and temporal coherence. Our study introduces a network designed for
expression-based video inpainting, employing generative adversarial networks
(GANs) to handle static and moving occlusions across all frames. By utilizing
facial landmarks and an occlusion-free reference image, our model maintains the
user's identity consistently across frames. We further enhance emotional
preservation through a customized facial expression recognition (FER) loss
function, ensuring detailed inpainted outputs. Our proposed framework exhibits
proficiency in eliminating occlusions from facial videos in an adaptive form,
whether appearing static or dynamic on the frames, while providing realistic
and coherent results.
",2024-02-14 11:20:47+00:00,cs.CV
"Blind Deep-Learning-Based Image Watermarking Robust Against Geometric
  Transformations","  Digital watermarking enables protection against copyright infringement of
images. Although existing methods embed watermarks imperceptibly and
demonstrate robustness against attacks, they typically lack resilience against
geometric transformations. Therefore, this paper proposes a new watermarking
method that is robust against geometric attacks. The proposed method is based
on the existing HiDDeN architecture that uses deep learning for watermark
encoding and decoding. We add new noise layers to this architecture, namely for
a differentiable JPEG estimation, rotation, rescaling, translation, shearing
and mirroring. We demonstrate that our method outperforms the state of the art
when it comes to geometric robustness. In conclusion, the proposed method can
be used to protect images when viewed on consumers' devices.
",2024-02-14 10:18:00+00:00,cs.MM
TurtleRabbit 2024 SSL Team Description Paper,"  TurtleRabbit is a new RoboCup SSL team from Western Sydney University. This
team description paper presents our approach in navigating some of the
challenges in developing a new SSL team from scratch. SSL is dominated by teams
with extensive experience and customised equipment that has been developed over
many years. Here, we outline our approach in overcoming some of the
complexities associated with replicating advanced open-sourced designs and
managing the high costs of custom components. Opting for simplicity and
cost-effectiveness, our strategy primarily employs off-the-shelf electronics
components and ``hobby'' brushless direct current (BLDC) motors, complemented
by 3D printing and CNC milling. This approach helped us to streamline the
development process and, with our open-sourced hardware design, hopefully will
also lower the bar for other teams to enter RoboCup SSL in the future. The
paper details the specific hardware choices, their approximate costs, the
integration of electronics and mechanics, and the initial steps taken in
software development, for our entry into SSL that aims to be simple yet
competitive.
",2024-02-13 04:09:26+00:00,cs.RO
"Evaluation of a Smart Mobile Robotic System for Industrial Plant
  Inspection and Supervision","  Automated and autonomous industrial inspection is a longstanding research
field, driven by the necessity to enhance safety and efficiency within
industrial settings. In addressing this need, we introduce an autonomously
navigating robotic system designed for comprehensive plant inspection. This
innovative system comprises a robotic platform equipped with a diverse array of
sensors integrated to facilitate the detection of various process and
infrastructure parameters. These sensors encompass optical (LiDAR, Stereo,
UV/IR/RGB cameras), olfactory (electronic nose), and acoustic (microphone
array) capabilities, enabling the identification of factors such as methane
leaks, flow rates, and infrastructural anomalies. The proposed system underwent
individual evaluation at a wastewater treatment site within a chemical plant,
providing a practical and challenging environment for testing. The evaluation
process encompassed key aspects such as object detection, 3D localization, and
path planning. Furthermore, specific evaluations were conducted for optical
methane leak detection and localization, as well as acoustic assessments
focusing on pump equipment and gas leak localization.
",2024-02-12 14:57:51+00:00,cs.RO
"Detecting the Clinical Features of Difficult-to-Treat Depression using
  Synthetic Data from Large Language Models","  Difficult-to-treat depression (DTD) has been proposed as a broader and more
clinically comprehensive perspective on a person's depressive disorder where
despite treatment, they continue to experience significant burden. We sought to
develop a Large Language Model (LLM)-based tool capable of interrogating
routinely-collected, narrative (free-text) electronic health record (EHR) data
to locate published prognostic factors that capture the clinical syndrome of
DTD. In this work, we use LLM-generated synthetic data (GPT3.5) and a
Non-Maximum Suppression (NMS) algorithm to train a BERT-based span extraction
model. The resulting model is then able to extract and label spans related to a
variety of relevant positive and negative factors in real clinical data (i.e.
spans of text that increase or decrease the likelihood of a patient matching
the DTD syndrome). We show it is possible to obtain good overall performance
(0.70 F1 across polarity) on real clinical data on a set of as many as 20
different factors, and high performance (0.85 F1 with 0.95 precision) on a
subset of important DTD factors such as history of abuse, family history of
affective disorder, illness severity and suicidality by training the model
exclusively on synthetic data. Our results show promise for future healthcare
applications especially in applications where traditionally, highly
confidential medical data and human-expert annotation would normally be
required.
",2024-02-12 13:34:33+00:00,cs.CL
"TeMPO: Efficient Time-Multiplexed Dynamic Photonic Tensor Core for Edge
  AI with Compact Slow-Light Electro-Optic Modulator","  Electronic-photonic computing systems offer immense potential in
energy-efficient artificial intelligence (AI) acceleration tasks due to the
superior computing speed and efficiency of optics, especially for real-time,
low-energy deep neural network (DNN) inference tasks on resource-restricted
edge platforms. However, current optical neural accelerators based on
foundry-available devices and conventional system architecture still encounter
a performance gap compared to highly customized electronic counterparts. To
bridge the performance gap due to lack of domain specialization, we present a
time-multiplexed dynamic photonic tensor accelerator, dubbed TeMPO, with
cross-layer device/circuit/architecture customization. At the device level, we
present foundry-compatible, customized photonic devices, including a slow-light
electro-optic modulator with experimental demonstration, optical splitters, and
phase shifters that significantly reduce the footprint and power in input
encoding and dot-product calculation. At the circuit level, partial products
are hierarchically accumulated via parallel photocurrent aggregation,
lightweight capacitive temporal integration, and sequential digital summation,
considerably relieving the analog-to-digital conversion bottleneck. We also
employ a multi-tile, multi-core architecture to maximize hardware sharing for
higher efficiency. Across diverse edge AI workloads, TeMPO delivers
digital-comparable task accuracy with superior quantization/noise tolerance. We
achieve a 368.6 TOPS peak performance, 22.3 TOPS/W energy efficiency, and 1.2
TOPS/mm$^2$ compute density, pushing the Pareto frontier in edge AI hardware.
This work signifies the power of cross-layer co-design and domain-specific
customization, paving the way for future electronic-photonic accelerators with
even greater performance and efficiency.
",2024-02-12 03:40:32+00:00,cs.ET
"Design of a W-band High-PAE Class A&AB Power Amplifier in 150nm GaAs
  Technology","  Nanometer scale power amplifiers (PA) at sub-THz suffer from severe parasitic
effects that lead to experience limited maximum frequency and reduced power
performance at the device transceiver front end. The integrated circuits
researchers proposed different PA design architecture combinations at scaled
down technologies to overcome these limitations. Although the designs meet the
minimum requirements, the power added efficiency (PAE) of PA is still quite
low. In this paper, a W-band single-ended common-source (CS) and cascode
integrated 3-stage 2-way PA design is proposed. The design integrated different
key design methodologies to mitigate the parasitic; such as combined Class AB
and Class A stages for gain-boosting and efficiency enhancement, Wilkinson
power combiner for higher output power, linearity, and bandwidth, and
transmission line (TL)-based wide band matching network for better inter-stage
matching and compact size. The proposed PA design is validated using UMS 150-nm
GaAs pHEMT using advanced design system (ADS) simulator. The results show that
the proposed PA achieved a gain of 20.1 dB, an output power of 17.2 dBm, a PAE
of 33 % and a 21 GHz bandwidth at 90 GHz Sub-THz band. The PA layout consumes
only 5.66 X 2.51 mm2 die space including pads. Our proposed PA design will
boost the research on sub-THz integrated circuits research and will smooth the
wide spread adoption of 6G in near future.
",2024-02-11 02:55:03+00:00,cs.NI
"REALM: RAG-Driven Enhancement of Multimodal Electronic Health Records
  Analysis via Large Language Models","  The integration of multimodal Electronic Health Records (EHR) data has
significantly improved clinical predictive capabilities. Leveraging clinical
notes and multivariate time-series EHR, existing models often lack the medical
context relevent to clinical tasks, prompting the incorporation of external
knowledge, particularly from the knowledge graph (KG). Previous approaches with
KG knowledge have primarily focused on structured knowledge extraction,
neglecting unstructured data modalities and semantic high dimensional medical
knowledge. In response, we propose REALM, a Retrieval-Augmented Generation
(RAG) driven framework to enhance multimodal EHR representations that address
these limitations. Firstly, we apply Large Language Model (LLM) to encode long
context clinical notes and GRU model to encode time-series EHR data. Secondly,
we prompt LLM to extract task-relevant medical entities and match entities in
professionally labeled external knowledge graph (PrimeKG) with corresponding
medical knowledge. By matching and aligning with clinical standards, our
framework eliminates hallucinations and ensures consistency. Lastly, we propose
an adaptive multimodal fusion network to integrate extracted knowledge with
multimodal EHR data. Our extensive experiments on MIMIC-III mortality and
readmission tasks showcase the superior performance of our REALM framework over
baselines, emphasizing the effectiveness of each module. REALM framework
contributes to refining the use of multimodal EHR data in healthcare and
bridging the gap with nuanced medical context essential for informed clinical
predictions.
",2024-02-10 18:27:28+00:00,cs.AI
Neural Rendering based Urban Scene Reconstruction for Autonomous Driving,"  Dense 3D reconstruction has many applications in automated driving including
automated annotation validation, multimodal data augmentation, providing ground
truth annotations for systems lacking LiDAR, as well as enhancing auto-labeling
accuracy. LiDAR provides highly accurate but sparse depth, whereas camera
images enable estimation of dense depth but noisy particularly at long ranges.
In this paper, we harness the strengths of both sensors and propose a
multimodal 3D scene reconstruction using a framework combining neural implicit
surfaces and radiance fields. In particular, our method estimates dense and
accurate 3D structures and creates an implicit map representation based on
signed distance fields, which can be further rendered into RGB images, and
depth maps. A mesh can be extracted from the learned signed distance field and
culled based on occlusion. Dynamic objects are efficiently filtered on the fly
during sampling using 3D object detection models. We demonstrate qualitative
and quantitative results on challenging automotive scenes.
",2024-02-09 23:20:23+00:00,cs.CV
"What is Hiding in Medicine's Dark Matter? Learning with Missing Data in
  Medical Practices","  Electronic patient records (EPRs) produce a wealth of data but contain
significant missing information. Understanding and handling this missing data
is an important part of clinical data analysis and if left unaddressed could
result in bias in analysis and distortion in critical conclusions. Missing data
may be linked to health care professional practice patterns and imputation of
missing data can increase the validity of clinical decisions. This study
focuses on statistical approaches for understanding and interpreting the
missing data and machine learning based clinical data imputation using a single
centre's paediatric emergency data and the data from UK's largest clinical
audit for traumatic injury database (TARN). In the study of 56,961 data points
related to initial vital signs and observations taken on children presenting to
an Emergency Department, we have shown that missing data are likely to be
non-random and how these are linked to health care professional practice
patterns. We have then examined 79 TARN fields with missing values for 5,791
trauma cases. Singular Value Decomposition (SVD) and k-Nearest Neighbour (kNN)
based missing data imputation methods are used and imputation results against
the original dataset are compared and statistically tested. We have concluded
that the 1NN imputer is the best imputation which indicates a usual pattern of
clinical decision making: find the most similar patients and take their
attributes as imputation.
",2024-02-09 17:27:35+00:00,cs.LG
"TEE4EHR: Transformer Event Encoder for Better Representation Learning in
  Electronic Health Records","  Irregular sampling of time series in electronic health records (EHRs) is one
of the main challenges for developing machine learning models. Additionally,
the pattern of missing data in certain clinical variables is not at random but
depends on the decisions of clinicians and the state of the patient. Point
process is a mathematical framework for analyzing event sequence data that is
consistent with irregular sampling patterns. Our model, TEE4EHR, is a
transformer event encoder (TEE) with point process loss that encodes the
pattern of laboratory tests in EHRs. The utility of our TEE has been
investigated in a variety of benchmark event sequence datasets. Additionally,
we conduct experiments on two real-world EHR databases to provide a more
comprehensive evaluation of our model. Firstly, in a self-supervised learning
approach, the TEE is jointly learned with an existing attention-based deep
neural network which gives superior performance in negative log-likelihood and
future event prediction. Besides, we propose an algorithm for aggregating
attention weights that can reveal the interaction between the events. Secondly,
we transfer and freeze the learned TEE to the downstream task for the outcome
prediction, where it outperforms state-of-the-art models for handling
irregularly sampled time series. Furthermore, our results demonstrate that our
approach can improve representation learning in EHRs and can be useful for
clinical prediction tasks.
",2024-02-09 12:19:06+00:00,cs.LG
TimEHR: Image-based Time Series Generation for Electronic Health Records,"  Time series in Electronic Health Records (EHRs) present unique challenges for
generative models, such as irregular sampling, missing values, and high
dimensionality. In this paper, we propose a novel generative adversarial
network (GAN) model, TimEHR, to generate time series data from EHRs. In
particular, TimEHR treats time series as images and is based on two conditional
GANs. The first GAN generates missingness patterns, and the second GAN
generates time series values based on the missingness pattern. Experimental
results on three real-world EHR datasets show that TimEHR outperforms
state-of-the-art methods in terms of fidelity, utility, and privacy metrics.
",2024-02-09 10:57:14+00:00,cs.LG
"Multimodal Interpretable Data-Driven Models for Early Prediction of
  Antimicrobial Multidrug Resistance Using Multivariate Time-Series","  Electronic health records (EHR) is an inherently multimodal register of the
patient's health status characterized by static data and multivariate time
series (MTS). While MTS are a valuable tool for clinical prediction, their
fusion with other data modalities can possibly result in more thorough insights
and more accurate results. Deep neural networks (DNNs) have emerged as
fundamental tools for identifying and defining underlying patterns in the
healthcare domain. However, fundamental improvements in interpretability are
needed for DNN models to be widely used in the clinical setting. In this study,
we present an approach built on a collection of interpretable multimodal
data-driven models that may anticipate and understand the emergence of
antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU)
of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and
initial health status of the patient are modeled using static variables, while
the evolution of the patient's health status during the ICU stay is modeled
using several MTS, including mechanical ventilation and antibiotics intake. The
multimodal DNNs models proposed in this paper include interpretable principles
in addition to being effective at predicting AMR and providing an explainable
prediction support system for AMR in the ICU. Furthermore, our proposed
methodology based on multimodal models and interpretability schemes can be
leveraged in additional clinical problems dealing with EHR data, broadening the
impact and applicability of our results.
",2024-02-09 10:16:58+00:00,cs.LG
"Jointly Learning Representations for Map Entities via Heterogeneous
  Graph Contrastive Learning","  The electronic map plays a crucial role in geographic information systems,
serving various urban managerial scenarios and daily life services. Developing
effective Map Entity Representation Learning (MERL) methods is crucial to
extracting embedding information from electronic maps and converting map
entities into representation vectors for downstream applications. However,
existing MERL methods typically focus on one specific category of map entities,
such as POIs, road segments, or land parcels, which is insufficient for
real-world diverse map-based applications and might lose latent structural and
semantic information interacting between entities of different types. Moreover,
using representations generated by separate models for different map entities
can introduce inconsistencies. Motivated by this, we propose a novel method
named HOME-GCL for learning representations of multiple categories of map
entities. Our approach utilizes a heterogeneous map entity graph (HOME graph)
that integrates both road segments and land parcels into a unified framework. A
HOME encoder with parcel-segment joint feature encoding and heterogeneous graph
transformer is then deliberately designed to convert segments and parcels into
representation vectors. Moreover, we introduce two types of contrastive
learning tasks, namely intra-entity and inter-entity tasks, to train the
encoder in a self-supervised manner. Extensive experiments on three large-scale
datasets covering road segment-based, land parcel-based, and trajectory-based
tasks demonstrate the superiority of our approach. To the best of our
knowledge, HOME-GCL is the first attempt to jointly learn representations for
road segments and land parcels using a unified model.
",2024-02-09 01:47:18+00:00,cs.LG
"Unsupervised Discovery of Clinical Disease Signatures Using
  Probabilistic Independence","  Insufficiently precise diagnosis of clinical disease is likely responsible
for many treatment failures, even for common conditions and treatments. With a
large enough dataset, it may be possible to use unsupervised machine learning
to define clinical disease patterns more precisely. We present an approach to
learning these patterns by using probabilistic independence to disentangle the
imprint on the medical record of causal latent sources of disease. We inferred
a broad set of 2000 clinical signatures of latent sources from 9195 variables
in 269,099 Electronic Health Records. The learned signatures produced better
discrimination than the original variables in a lung cancer prediction task
unknown to the inference algorithm, predicting 3-year malignancy in patients
with no history of cancer before a solitary lung nodule was discovered. More
importantly, the signatures' greater explanatory power identified pre-nodule
signatures of apparently undiagnosed cancer in many of those patients.
",2024-02-08 16:41:03+00:00,cs.LG
"Dual-modal Tactile E-skin: Enabling Bidirectional Human-Robot
  Interaction via Integrated Tactile Perception and Feedback","  To foster an immersive and natural human-robot interaction, the
implementation of tactile perception and feedback becomes imperative,
effectively bridging the conventional sensory gap. In this paper, we propose a
dual-modal electronic skin (e-skin) that integrates magnetic tactile sensing
and vibration feedback for enhanced human-robot interaction. The dual-modal
tactile e-skin offers multi-functional tactile sensing and programmable haptic
feedback, underpinned by a layered structure comprised of flexible magnetic
films, soft silicone, a Hall sensor and actuator array, and a microcontroller
unit. The e-skin captures the magnetic field changes caused by subtle
deformations through Hall sensors, employing deep learning for accurate tactile
perception. Simultaneously, the actuator array generates mechanical vibrations
to facilitate haptic feedback, delivering diverse mechanical stimuli. Notably,
the dual-modal e-skin is capable of transmitting tactile information
bidirectionally, enabling object recognition and fine-weighing operations. This
bidirectional tactile interaction framework will enhance the immersion and
efficiency of interactions between humans and robots.
",2024-02-08 14:56:40+00:00,cs.RO
"A Solution for Commercializing, Decentralizing and Storing Electronic
  Medical Records by Integrating Proxy Re-Encryption, IPFS, and Blockchain","  The rapid expansion of user medical records across global systems presents
not only opportunities but also new challenges in maintaining effective
application models that ensure user privacy, controllability, and the ability
to commercialize patient medical records. Moreover, the proliferation of data
analysis models in healthcare institutions necessitates the decentralization
and restorability of medical record data. It is imperative that user medical
data collected from these systems can be easily analyzed and utilized even
years after collection, without the risk of data loss due to numerous factors.
Additionally, medical information must be authorized by the data owner,
granting patients the right to accept or decline data usage requests from
medical research agencies. In response, we propose an innovative solution for
implementing a decentralized system utilizing an EVM-compatible blockchain and
IPFS for decentralized storage. To ensure privacy and control, we employ Proxy
Re-Encryption (PRE), a cryptographic authorized method, within the medical data
marketplace. Our proposed architecture significantly reduces costs associated
with granting read access to healthcare research agencies by minimizing the
encryption and decryption time of stored records. Furthermore, it empowers
users with enhanced control over their health data through tamperproof
blockchain smart contracts and IPFS, safeguarding the integrity and privacy of
their medical records.
",2024-02-08 09:09:03+00:00,cs.CR
"A Comprehensive Analysis of Secondary Coexistence in a Real-World CBRS
  Deployment","  The Federal Communications Commission (FCC) in the U.S. has made the Citizens
Broadband Radio Service (CBRS) band (3.55 - 3.7 GHz) available for commercial
wireless usage under a shared approach using a three-tier hierarchical
architecture, where the federal incumbent is the highest priority Tier 1 user,
Priority Access License (PAL) holders, who have paid for licenses, are Tier 2
users and Tier 3 users operate under General Authorized Access (GAA), without
license fees or protection from higher priority users. The Spectrum Access
System (SAS) ensures that higher priority users are protected from interference
from lower priority users. However, the lowest priority GAA users are not given
any protection from each other by the SAS and are expected to not cause any
harmful interference to Tier 1 and Tier 2 users. As the deployments of GAA
devices grow, the potential for secondary interference between GAA users
increases, especially since the SAS architecture does not allow dynamic channel
switching when faced with interference. In this paper, we present a
first-of-its-kind extensive measurement campaign of a commercial CBRS network
deployed in the city of South Bend, IN, that quantifies both co-channel
interference (CCI) and adjacent channel interference (ACI) caused by competing
GAA devices and C-band 5G, respectively. We (i) identify a particular CCI
scenario and improve performance by changing the frequency allocation based on
our study of other allocations in the vicinity and (ii) quantify ACI from 5G in
C-band (3.7 GHz) on CBRS throughput. We conclude that (i) CCI and ACI for GAA
users is not handled well by the SAS, (ii) proper frequency allocation for GAA
requires additional analysis of interference from other GAA users followed by
dynamical channel selection, and (iii) utilization of immediate adjacent
channels by high power 5G deployments limits the performance of CBRS.
",2024-02-07 20:04:54+00:00,cs.NI
"A Masked language model for multi-source EHR trajectories contextual
  representation learning","  Using electronic health records data and machine learning to guide future
decisions needs to address challenges, including 1) long/short-term
dependencies and 2) interactions between diseases and interventions.
Bidirectional transformers have effectively addressed the first challenge. Here
we tackled the latter challenge by masking one source (e.g., ICD10 codes) and
training the transformer to predict it using other sources (e.g., ATC codes).
",2024-02-07 15:38:29+00:00,cs.LG
"Charting the COVID Long Haul Experience -- A Longitudinal Exploration of
  Symptoms, Activity, and Clinical Adherence","  COVID Long Haul (CLH) is an emerging chronic illness with varied patient
experiences. Our understanding of CLH is often limited to data from electronic
health records (EHRs), such as diagnoses or problem lists, which do not capture
the volatility and severity of symptoms or their impact. To better understand
the unique presentation of CLH, we conducted a 3-month long cohort study with
14 CLH patients, collecting objective (EHR, daily Fitbit logs) and subjective
(weekly surveys, interviews) data. Our findings reveal a complex presentation
of symptoms, associated uncertainty, and the ensuing impact CLH has on
patients' personal and professional lives. We identify patient needs,
practices, and challenges around adhering to clinical recommendations, engaging
with health data, and establishing ""new normals"" post COVID. We reflect on the
potential found at the intersection of these various data streams and the
persuasive heuristics possible when designing for this new population and their
specific needs.
",2024-02-07 15:15:14+00:00,cs.HC
"A Perspective on Individualized Treatment Effects Estimation from
  Time-series Health Data","  The burden of diseases is rising worldwide, with unequal treatment efficacy
for patient populations that are underrepresented in clinical trials.
Healthcare, however, is driven by the average population effect of medical
treatments and, therefore, operates in a ""one-size-fits-all"" approach, not
necessarily what best fits each patient. These facts suggest a pressing need
for methodologies to study individualized treatment effects (ITE) to drive
personalized treatment. Despite the increased interest in
machine-learning-driven ITE estimation models, the vast majority focus on
tabular data with limited review and understanding of methodologies proposed
for time-series electronic health records (EHRs). To this end, this work
provides an overview of ITE works for time-series data and insights into future
research. The work summarizes the latest work in the literature and reviews it
in light of theoretical assumptions, types of treatment settings, and
computational frameworks. Furthermore, this work discusses challenges and
future research directions for ITEs in a time-series setting. We hope this work
opens new directions and serves as a resource for understanding one of the
exciting yet under-studied research areas.
",2024-02-07 08:53:46+00:00,cs.LG
"A Lightweight Inception Boosted U-Net Neural Network for Routability
  Prediction","  As the modern CPU, GPU, and NPU chip design complexity and transistor counts
keep increasing, and with the relentless shrinking of semiconductor technology
nodes to nearly 1 nanometer, the placement and routing have gradually become
the two most pivotal processes in modern very-large-scale-integrated (VLSI)
circuit back-end design. How to evaluate routability efficiently and accurately
in advance (at the placement and global routing stages) has grown into a
crucial research area in the field of artificial intelligence (AI) assisted
electronic design automation (EDA). In this paper, we propose a novel U-Net
variant model boosted by an Inception embedded module to predict Routing
Congestion (RC) and Design Rule Checking (DRC) hotspots. Experimental results
on the recently published CircuitNet dataset benchmark show that our proposed
method achieves up to 5% (RC) and 20% (DRC) rate reduction in terms of
Avg-NRMSE (Average Normalized Root Mean Square Error) compared to the classic
architecture. Furthermore, our approach consistently outperforms the prior
model on the SSIM (Structural Similarity Index Measure) metric.
",2024-02-07 07:32:03+00:00,cs.AR
Automating the audit of electronic invoices with a soft robot,"  Taiwan's Chi Mei Medical Center has completed four challenges mentioned in
published robotic process automation (RPA) studies including automating a
dynamic process, designing feasible human-robot collaboration, incorporating
other emerging technologies, and bringing positive business impacts. Its
executives called a committee to implement the electronic invoicing. This
implementation includes the creation of a software robot to download
automatically cloud electronic invoice (E-invoice) data from Taiwan's E-invoice
platform and detect the inconsistency between them and on-premise data. This
bot operates when internal auditors are off their office. They satisfied this
software robot since the remaining work is only verifying the resulting
inconsistency. The Chi Mei Medical Center measured the time and costs before
and after adopting software robots to audit E-invoice; consequently, it
welcomed more bots automating other business processes. In conclusion,
integrating a software robot with other emerging technologies mitigates the
possible errors provided by this bot. A good human-robot collaboration relies
on the consideration of human perspective in choosing RPA tasks. Free bot
creators are sufficient to verify that automating a business process using a
bot is a reasonable investment.
",2024-02-07 01:55:17+00:00,cs.RO
"CEHR-GPT: Generating Electronic Health Records with Chronological
  Patient Timelines","  Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in
advancing healthcare applications and machine learning models, particularly for
researchers without direct access to healthcare data. Although existing
methods, like rule-based approaches and generative adversarial networks (GANs),
generate synthetic data that resembles real-world EHR data, these methods often
use a tabular format, disregarding temporal dependencies in patient histories
and limiting data replication. Recently, there has been a growing interest in
leveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables
applications like disease progression analysis, population estimation,
counterfactual reasoning, and synthetic data generation. In this work, we focus
on synthetic data generation and demonstrate the capability of training a GPT
model using a particular patient representation derived from CEHR-BERT,
enabling us to generate patient sequences that can be seamlessly converted to
the Observational Medical Outcomes Partnership (OMOP) data format.
",2024-02-06 20:58:36+00:00,cs.LG
"Intelligent Collective Escape of Swarm Robots Based on a Novel
  Fish-inspired Self-adaptive Approach with Neurodynamic Models","  Fish schools present high-efficiency group behaviors through simple
individual interactions to collective migration and dynamic escape from the
predator. The school behavior of fish is usually a good inspiration to design
control architecture for swarm robots. In this paper, a novel fish-inspired
self-adaptive approach is proposed for collective escape for the swarm robots.
In addition, a bio-inspired neural network (BINN) is introduced to generate
collision-free escape robot trajectories through the combination of attractive
and repulsive forces. Furthermore, to cope with dynamic environments, a
neurodynamics-based self-adaptive mechanism is proposed to improve the
self-adaptive performance of the swarm robots in the changing environment.
Similar to fish escape maneuvers, simulation and experimental results show that
the swarm robots are capable of collectively leaving away from the threats.
Several comparison studies demonstrated that the proposed approach can
significantly improve the effectiveness and efficiency of system performance,
and the flexibility and robustness in complex environments.
",2024-02-06 18:36:44+00:00,cs.RO
"HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible
  Dataflows for Energy-Efficient CNN Inference","  Several photonic microring resonators (MRRs) based analog accelerators have
been proposed to accelerate the inference of integer-quantized CNNs with
remarkably higher throughput and energy efficiency compared to their electronic
counterparts. However, the existing analog photonic accelerators suffer from
three shortcomings: (i) severe hampering of wavelength parallelism due to
various crosstalk effects, (ii) inflexibility of supporting various dataflows
other than the weight-stationary dataflow, and (iii) failure in fully
leveraging the ability of photodetectors to perform in-situ accumulations.
These shortcomings collectively hamper the performance and energy efficiency of
prior accelerators. To tackle these shortcomings, we present a novel Hybrid
timE Amplitude aNalog optical Accelerator, called HEANA. HEANA employs hybrid
time-amplitude analog optical multipliers (TAOMs) that increase the flexibility
of HEANA to support multiple dataflows. A spectrally hitless arrangement of
TAOMs significantly reduces the crosstalk effects, thereby increasing the
wavelength parallelism in HEANA. Moreover, HEANA employs our invented balanced
photo-charge accumulators (BPCAs) that enable buffer-less, in-situ, temporal
accumulations to eliminate the need to use reduction networks in HEANA,
relieving it from related latency and energy overheads. Our evaluation for the
inference of four modern CNNs indicates that HEANA provides improvements of
atleast 66x and 84x in frames-per-second (FPS) and FPS/W (energy-efficiency),
respectively, for equal-area comparisons, on gmean over two MRR-based analog
CNN accelerators from prior work.
",2024-02-05 18:05:34+00:00,cs.AR
"A Comprehensive Study of the Current State-of-the-Art in Nepali
  Automatic Speech Recognition Systems","  In this paper, we examine the research conducted in the field of Nepali
Automatic Speech Recognition (ASR). The primary objective of this survey is to
conduct a comprehensive review of the works on Nepali Automatic Speech
Recognition Systems completed to date, explore the different datasets used,
examine the technology utilized, and take account of the obstacles encountered
in implementing the Nepali ASR system. In tandem with the global trends of
ever-increasing research on speech recognition based research, the number of
Nepalese ASR-related projects are also growing. Nevertheless, the investigation
of language and acoustic models of the Nepali language has not received
adequate attention compared to languages that possess ample resources. In this
context, we provide a framework as well as directions for future
investigations.
",2024-02-05 14:34:14+00:00,cs.SD
"Embedding Hardware Approximations in Discrete Genetic-based Training for
  Printed MLPs","  Printed Electronics (PE) stands out as a promisingtechnology for widespread
computing due to its distinct attributes, such as low costs and flexible
manufacturing. Unlike traditional silicon-based technologies, PE enables
stretchable, conformal,and non-toxic hardware. However, PE are constrained by
larger feature sizes, making it challenging to implement complex circuits such
as machine learning (ML) classifiers. Approximate computing has been proven to
reduce the hardware cost of ML circuits such as Multilayer Perceptrons (MLPs).
In this paper, we maximize the benefits of approximate computing by integrating
hardware approximation into the MLP training process. Due to the discrete
nature of hardware approximation, we propose and implement a genetic-based,
approximate, hardware-aware training approach specifically designed for printed
MLPs. For a 5% accuracy loss, our MLPs achieve over 5x area and power reduction
compared to the baseline while outperforming state of-the-art approximate and
stochastic printed MLPs.
",2024-02-05 11:52:23+00:00,cs.AR
Design of an Analog Memory Cell in 0.25 micron CMOS process,"  CMOS VLSI technology is the most dominant integration methodology prevailing
in the world today. Various signal-processing blocks are made using analog or
digital design techniques in MOS VLSI. An important component is the Memory
unit used to store data. In the project a memory cell has been built up using
analog design method. A capacitor is used as the basic storage device. The main
idea behind analog memory is that the analog value of the charge or voltage
stored in the capacitor is the data stored. So the dielectric quality of the
capacitor becomes important here to determine how effectively it can store some
charge. Analog memory is a trade off between hardware cost, chip area and
accuracy or quality of storage. The circuit of analog memory cell was developed
starting from the idea that required voltage will be stored in a capacitor and
MOS transistors were used as switches. A given technology of integration was
used and hence the dielectric property of the capacitor was fixed. By suitable
circuit configuration the analog voltage value was written to the capacitor,
read out when required and the charge loss was also refreshed. The results
obtained are as given in the thesis.
",2024-02-04 23:51:02+00:00,cs.OH
"Feasibility of Identifying Factors Related to Alzheimer's Disease and
  Related Dementia in Real-World Data","  A comprehensive view of factors associated with AD/ADRD will significantly
aid in studies to develop new treatments for AD/ADRD and identify high-risk
populations and patients for prevention efforts. In our study, we summarized
the risk factors for AD/ADRD by reviewing existing meta-analyses and review
articles on risk and preventive factors for AD/ADRD. In total, we extracted 477
risk factors in 10 categories from 537 studies. We constructed an interactive
knowledge map to disseminate our study results. Most of the risk factors are
accessible from structured Electronic Health Records (EHRs), and clinical
narratives show promise as information sources. However, evaluating genomic
risk factors using RWD remains a challenge, as genetic testing for AD/ADRD is
still not a common practice and is poorly documented in both structured and
unstructured EHRs. Considering the constantly evolving research on AD/ADRD risk
factors, literature mining via NLP methods offers a solution to automatically
update our knowledge map.
",2024-02-03 18:17:19+00:00,cs.AI
"Invisible Finger: Practical Electromagnetic Interference Attack on
  Touchscreen-based Electronic Devices","  Touchscreen-based electronic devices such as smart phones and smart tablets
are widely used in our daily life. While the security of electronic devices
have been heavily investigated recently, the resilience of touchscreens against
various attacks has yet to be thoroughly investigated. In this paper, for the
first time, we show that touchscreen-based electronic devices are vulnerable to
intentional electromagnetic interference (IEMI) attacks in a systematic way and
how to conduct this attack in a practical way. Our contribution lies in not
just demonstrating the attack, but also analyzing and quantifying the
underlying mechanism allowing the novel IEMI attack on touchscreens in detail.
We show how to calculate both the minimum amount of electric field and signal
frequency required to induce touchscreen ghost touches. We further analyze our
IEMI attack on real touchscreens with different magnitudes, frequencies,
duration, and multitouch patterns. The mechanism of controlling the
touchscreen-enabled electronic devices with IEMI signals is also elaborated. We
design and evaluate an out-of-sight touchscreen locator and touch injection
feedback mechanism to assist a practical IEMI attack. Our attack works directly
on the touchscreen circuit regardless of the touchscreen scanning mechanism or
operating system. Our attack can inject short-tap, long-press, and
omni-directional gestures on touchscreens from a distance larger than the
average thickness of common tabletops. Compared with the state-of-the-art
touchscreen attack, ours can accurately inject different types of touch events
without the need for sensing signal synchronization, which makes our attack
more robust and practical. In addition, rather than showing a simple
proof-of-concept attack, we present and demonstrate the first ready-to-use IEMI
based touchscreen attack vector with end-to-end attack scenarios.
",2024-02-03 18:06:15+00:00,cs.CR
BetterV: Controlled Verilog Generation with Discriminative Guidance,"  Due to the growing complexity of modern Integrated Circuits (ICs), there is a
need for automated circuit design methods. Recent years have seen rising
research in hardware design language generation to facilitate the design
process. In this work, we propose a Verilog generation framework, BetterV,
which fine-tunes the large language models (LLMs) on processed domain-specific
datasets and incorporates generative discriminators for guidance on particular
design demands. The Verilog modules are collected, filtered and processed from
internet to form a clean and abundant dataset. Instruct-tuning methods are
specially designed to fine-tune the LLMs to understand the knowledge about
Verilog. Furthermore, data are augmented to enrich the training set and also
used to train a generative discriminator on particular downstream task, which
leads a guidance for the LLMs to optimize the Verilog implementation. BetterV
has the ability to generate syntactically and functionally correct Verilog,
which can outperform GPT-4 on the VerilogEval benchmark. With the help of
task-specific generative discriminator, BetterV can achieve remarkable
improvement on various electronic design automation (EDA) downstream tasks,
including the netlist node reduction for synthesis and verification runtime
reduction with Boolean Satisfiability (SAT) solving.
",2024-02-03 08:00:12+00:00,cs.AI
"Low-power scalable multilayer optoelectronic neural networks enabled
  with incoherent light","  Optical approaches have made great strides towards the goal of high-speed,
energy-efficient computing necessary for modern deep learning and AI
applications. Read-in and read-out of data, however, limit the overall
performance of existing approaches. This study introduces a multilayer
optoelectronic computing framework that alternates between optical and
optoelectronic layers to implement matrix-vector multiplications and rectified
linear functions, respectively. Our framework is designed for real-time,
parallelized operations, leveraging 2D arrays of LEDs and photodetectors
connected via independent analog electronics. We experimentally demonstrate
this approach using a system with a three-layer network with two hidden layers
and operate it to recognize images from the MNIST database with a recognition
accuracy of 92% and classify classes from a nonlinear spiral data with 86%
accuracy. By implementing multiple layers of a deep neural network
simultaneously, our approach significantly reduces the number of read-ins and
read-outs required and paves the way for scalable optical accelerators
requiring ultra low energy.
",2024-02-03 02:14:37+00:00,cs.ET
Online Transfer Learning for RSV Case Detection,"  Transfer learning has become a pivotal technique in machine learning and has
proven to be effective in various real-world applications. However, utilizing
this technique for classification tasks with sequential data often faces
challenges, primarily attributed to the scarcity of class labels. To address
this challenge, we introduce Multi-Source Adaptive Weighting (MSAW), an online
multi-source transfer learning method. MSAW integrates a dynamic weighting
mechanism into an ensemble framework, enabling automatic adjustment of weights
based on the relevance and contribution of each source (representing historical
knowledge) and target model (learning from newly acquired data). We demonstrate
the effectiveness of MSAW by applying it to detect Respiratory Syncytial Virus
cases within Emergency Department visits, utilizing multiple years of
electronic health records from the University of Pittsburgh Medical Center. Our
method demonstrates performance improvements over many baselines, including
refining pre-trained models with online learning as well as three static
weighting approaches, showing MSAW's capacity to integrate historical knowledge
with progressively accumulated new data. This study indicates the potential of
online transfer learning in healthcare, particularly for developing machine
learning models that dynamically adapt to evolving situations where new data is
incrementally accumulated.
",2024-02-03 02:13:08+00:00,cs.LG
"EBV: Electronic Bee-Veterinarian for Principled Mining and Forecasting
  of Honeybee Time Series","  Honeybees are vital for pollination and food production. Among many factors,
extreme temperature (e.g., due to climate change) is particularly dangerous for
bee health. Anticipating such extremities would allow beekeepers to take early
preventive action. Thus, given sensor (temperature) time series data from
beehives, how can we find patterns and do forecasting? Forecasting is crucial
as it helps spot unexpected behavior and thus issue warnings to the beekeepers.
In that case, what are the right models for forecasting? ARIMA, RNNs, or
something else?
  We propose the EBV (Electronic Bee-Veterinarian) method, which has the
following desirable properties: (i) principled: it is based on a) diffusion
equations from physics and b) control theory for feedback-loop controllers;
(ii) effective: it works well on multiple, real-world time sequences, (iii)
explainable: it needs only a handful of parameters (e.g., bee strength) that
beekeepers can easily understand and trust, and (iv) scalable: it performs
linearly in time. We applied our method to multiple real-world time sequences,
and found that it yields accurate forecasting (up to 49% improvement in RMSE
compared to baselines), and segmentation. Specifically, discontinuities
detected by EBV mostly coincide with domain expert's opinions, showcasing our
approach's potential and practical feasibility. Moreover, EBV is scalable and
fast, taking about 20 minutes on a stock laptop for reconstructing two months
of sensor data.
",2024-02-02 21:05:56+00:00,cs.LG
Recent Advances in Predictive Modeling with Electronic Health Records,"  The development of electronic health records (EHR) systems has enabled the
collection of a vast amount of digitized patient data. However, utilizing EHR
data for predictive modeling presents several challenges due to its unique
characteristics. With the advancements in machine learning techniques, deep
learning has demonstrated its superiority in various applications, including
healthcare. This survey systematically reviews recent advances in deep
learning-based predictive models using EHR data. Specifically, we begin by
introducing the background of EHR data and providing a mathematical definition
of the predictive modeling task. We then categorize and summarize predictive
deep models from multiple perspectives. Furthermore, we present benchmarks and
toolkits relevant to predictive modeling in healthcare. Finally, we conclude
this survey by discussing open challenges and suggesting promising directions
for future research.
",2024-02-02 00:31:01+00:00,cs.LG
"FairEHR-CLP: Towards Fairness-Aware Clinical Predictions with
  Contrastive Learning in Multimodal Electronic Health Records","  In the high-stakes realm of healthcare, ensuring fairness in predictive
models is crucial. Electronic Health Records (EHRs) have become integral to
medical decision-making, yet existing methods for enhancing model fairness
restrict themselves to unimodal data and fail to address the multifaceted
social biases intertwined with demographic factors in EHRs. To mitigate these
biases, we present FairEHR-CLP: a general framework for Fairness-aware Clinical
Predictions with Contrastive Learning in EHRs. FairEHR-CLP operates through a
two-stage process, utilizing patient demographics, longitudinal data, and
clinical notes. First, synthetic counterparts are generated for each patient,
allowing for diverse demographic identities while preserving essential health
information. Second, fairness-aware predictions employ contrastive learning to
align patient representations across sensitive attributes, jointly optimized
with an MLP classifier with a softmax layer for clinical classification tasks.
Acknowledging the unique challenges in EHRs, such as varying group sizes and
class imbalance, we introduce a novel fairness metric to effectively measure
error rate disparities across subgroups. Extensive experiments on three diverse
EHR datasets on three tasks demonstrate the effectiveness of FairEHR-CLP in
terms of fairness and utility compared with competitive baselines. FairEHR-CLP
represents an advancement towards ensuring both accuracy and equity in
predictive healthcare models.
",2024-02-01 19:24:45+00:00,cs.LG
Nanomechanically Induced Transparency,"  In this paper, we investigate a nanomechanically induced transparency (NIT)
effects that arises from the coupling of a nanoelectromechanical system and a
trapped ion. By confining the ion in mesoscopic traps and capacitively coupling
it with a nanoelectromechanical system suspended as electrodes, the research is
intricately focussed on the implications of including the ion's degrees of
freedom. The Lamb--Dicke approximation is crucial to understanding the effects
of phonon exchange with electronic qubits and revealing transparency phenomena
in this unique coupling. The results underline the importance of the
Lamb--Dicke approximation in modelling the effects of transparency windows in
nanoelectromechanical systems.
",2024-02-01 19:05:06+00:00,cs.IT
"Decentralised, Collaborative, and Privacy-preserving Machine Learning
  for Multi-Hospital Data","  Machine Learning (ML) has demonstrated its great potential on medical data
analysis. Large datasets collected from diverse sources and settings are
essential for ML models in healthcare to achieve better accuracy and
generalizability. Sharing data across different healthcare institutions is
challenging because of complex and varying privacy and regulatory requirements.
Hence, it is hard but crucial to allow multiple parties to collaboratively
train an ML model leveraging the private datasets available at each party
without the need for direct sharing of those datasets or compromising the
privacy of the datasets through collaboration. In this paper, we address this
challenge by proposing Decentralized, Collaborative, and Privacy-preserving ML
for Multi-Hospital Data (DeCaPH). It offers the following key benefits: (1) it
allows different parties to collaboratively train an ML model without
transferring their private datasets; (2) it safeguards patient privacy by
limiting the potential privacy leakage arising from any contents shared across
the parties during the training process; and (3) it facilitates the ML model
training without relying on a centralized server. We demonstrate the
generalizability and power of DeCaPH on three distinct tasks using real-world
distributed medical datasets: patient mortality prediction using electronic
health records, cell-type classification using single-cell human genomes, and
pathology identification using chest radiology images. We demonstrate that the
ML models trained with DeCaPH framework have an improved utility-privacy
trade-off, showing it enables the models to have good performance while
preserving the privacy of the training data points. In addition, the ML models
trained with DeCaPH framework in general outperform those trained solely with
the private datasets from individual parties, showing that DeCaPH enhances the
model generalizability.
",2024-01-31 22:06:10+00:00,cs.LG
Error-Tolerant E-Discovery Protocols,"  We consider the multi-party classification problem introduced by Dong,
Hartline, and Vijayaraghavan (2022) in the context of electronic discovery
(e-discovery). Based on a request for production from the requesting party, the
responding party is required to provide documents that are responsive to the
request except for those that are legally privileged. Our goal is to find a
protocol that verifies that the responding party sends almost all responsive
documents while minimizing the disclosure of non-responsive documents. We
provide protocols in the challenging non-realizable setting, where the instance
may not be perfectly separated by a linear classifier. We demonstrate
empirically that our protocol successfully manages to find almost all relevant
documents, while incurring only a small disclosure of non-responsive documents.
We complement this with a theoretical analysis of our protocol in the
single-dimensional setting, and other experiments on simulated data which
suggest that the non-responsive disclosure incurred by our protocol may be
unavoidable.
",2024-01-31 15:59:16+00:00,cs.CY
"QTFlow: Quantitative Timing-Sensitive Information Flow for
  Security-Aware Hardware Design on RTL","  In contemporary Electronic Design Automation (EDA) tools, security often
takes a backseat to the primary goals of power, performance, and area
optimization. Commonly, the security analysis is conducted by hand, leading to
vulnerabilities in the design remaining unnoticed. Security-aware EDA tools
assist the designer in the identification and removal of security threats while
keeping performance and area in mind. Cutting-edge methods employ information
flow analysis to identify inadvertent information leaks in design structures.
Current information leakage detection methods use quantitative information flow
analysis to quantify the leaks. However, handling sequential circuits poses
challenges for state-of-the-art techniques due to their time-agnostic nature,
overlooking timing channels, and introducing false positives. To address this,
we introduce QTFlow, a timing-sensitive framework for quantifying hardware
information leakages during the design phase. Illustrating its effectiveness on
open-source benchmarks, QTFlow autonomously identifies timing channels and
diminishes all false positives arising from time-agnostic analysis when
contrasted with current state-of-the-art techniques.
",2024-01-31 13:22:57+00:00,cs.CR
Haris: an Advanced Autonomous Mobile Robot for Smart Parking Assistance,"  This paper presents Haris, an advanced autonomous mobile robot system for
tracking the location of vehicles in crowded car parks using license plate
recognition. The system employs simultaneous localization and mapping (SLAM)
for autonomous navigation and precise mapping of the parking area, eliminating
the need for GPS dependency. In addition, the system utilizes a sophisticated
framework using computer vision techniques for object detection and automatic
license plate recognition (ALPR) for reading and associating license plate
numbers with location data. This information is subsequently synchronized with
a back-end service and made accessible to users via a user-friendly mobile app,
offering effortless vehicle location and alleviating congestion within the
parking facility. The proposed system has the potential to improve the
management of short-term large outdoor parking areas in crowded places such as
sports stadiums. The demo of the robot can be found on
https://youtu.be/ZkTCM35fxa0?si=QjggJuN7M1o3oifx.
",2024-01-31 11:00:26+00:00,cs.RO
"A Cradle-to-Gate Life Cycle Analysis of Bitcoin Mining Equipment Using
  Sphera LCA and ecoinvent Databases","  Bitcoin mining is regularly pointed out for its massive energy consumption
and associated greenhouse gas emissions, hence contributing significantly to
climate change. However, most studies ignore the environmental impacts of
producing mining equipment, which is problematic given the short lifespan of
such highly specific hardware. In this study, we perform a cradle-to-gate life
cycle assessment (LCA) of dedicated Bitcoin mining equipment, considering their
specific architecture. Our results show that the application-specific
integrated circuit designed for Bitcoin mining is the main contributor to
production-related impacts. This observation applies to most impact categories,
including the global warming potential. In addition, this finding stresses out
the necessity to carefully consider the specificity of the hardware. By
comparing these results with several usage scenarios, we also demonstrate that
the impacts of producing this type of equipment can be significant (up to 80%
of the total life cycle impacts), depending on the sources of electricity
supply for the use phase. Therefore, we highlight the need to consider the
production phase when assessing the environmental impacts of Bitcoin mining
hardware. To test the validity of our results, we use the Sphera LCA and
ecoinvent databases for the background modeling of our system. Surprisingly, it
leads to results with variations of up to 4 orders of magnitude for
toxicity-related indicators, despite using the same foreground modeling. This
database mismatch phenomenon, already identified in previous studies, calls for
better understanding, consideration and discussion of environmental impacts in
the field of electronics, going well beyond climate change indicators.
",2024-01-31 00:13:31+00:00,cs.CY
"LLaMP: Large Language Model Made Powerful for High-fidelity Materials
  Knowledge Retrieval and Distillation","  Reducing hallucination of Large Language Models (LLMs) is imperative for use
in the sciences, where reliability and reproducibility are crucial. However,
LLMs inherently lack long-term memory, making it a nontrivial, ad hoc, and
inevitably biased task to fine-tune them on domain-specific literature and
data. Here we introduce LLaMP, a multimodal retrieval-augmented generation
(RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can
dynamically and recursively interact with computational and experimental data
on Materials Project (MP) and run atomistic simulations via high-throughput
workflow interface. Without fine-tuning, LLaMP demonstrates strong tool usage
ability to comprehend and integrate various modalities of materials science
concepts, fetch relevant data stores on the fly, process higher-order data
(such as crystal structure and elastic tensor), and streamline complex tasks in
computational materials and chemistry. We propose a simple metric combining
uncertainty and confidence estimates to evaluate the self-consistency of
responses by LLaMP and vanilla LLMs. Our benchmark shows that LLaMP effectively
mitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli,
electronic bandgaps, and formation energies that seem to derive from mixed data
sources. We also demonstrate LLaMP's capability to edit crystal structures and
run annealing molecular dynamics simulations using pre-trained machine-learning
force fields. The framework offers an intuitive and nearly hallucination-free
approach to exploring and scaling materials informatics, and establishes a
pathway for knowledge distillation and fine-tuning other language models. Code
and live demo are available at https://github.com/chiang-yuan/llamp
",2024-01-30 18:37:45+00:00,cs.CL
"Learnable Prompt as Pseudo-Imputation: Reassessing the Necessity of
  Traditional EHR Data Imputation in Downstream Clinical Prediction","  Analyzing the health status of patients based on Electronic Health Records
(EHR) is a fundamental research problem in medical informatics. The presence of
extensive missing values in EHR makes it challenging for deep neural networks
to directly model the patient's health status based on EHR. Existing deep
learning training protocols require the use of statistical information or
imputation models to reconstruct missing values; however, the protocols inject
non-realistic data into downstream EHR analysis models, significantly limiting
model performance. This paper introduces Learnable Prompt as Pseudo Imputation
(PAI) as a new training protocol. PAI no longer introduces any imputed data but
constructs a learnable prompt to model the implicit preferences of the
downstream model for missing values, resulting in a significant performance
improvement for all EHR analysis models. Additionally, our experiments show
that PAI exhibits higher robustness in situations of data insufficiency and
high missing rates. More importantly, in a real-world application involving
cross-institutional data with zero-shot evaluation, PAI demonstrates stronger
model generalization capabilities for non-overlapping features.
",2024-01-30 07:19:36+00:00,cs.LG
"Characterization of Magnetic Labyrinthine Structures Through Junctions
  and Terminals Detection Using Template Matching and CNN","  Defects influence diverse properties of materials, shaping their structural,
mechanical, and electronic characteristics. Among a variety of materials
exhibiting unique defects, magnets exhibit diverse nano- to micro-scale defects
and have been intensively studied in materials science. Specifically, defects
in magnetic labyrinthine patterns, called junctions and terminals are
ubiquitous and serve as points of interest. While detecting and characterizing
such defects is crucial for understanding magnets, systematically investigating
large-scale images containing over a thousand closely packed junctions and
terminals remains a formidable challenge. This study introduces a new technique
called TM-CNN (Template Matching - Convolutional Neural Network) designed to
detect a multitude of small objects in images, such as the defects in magnetic
labyrinthine patterns. TM-CNN was used to identify 641,649 such structures in
444 experimental images, and the results were explored to deepen understanding
of magnetic materials. It employs a two-stage detection approach combining
template matching, used in initial detection, with a convolutional neural
network, used to eliminate incorrect identifications. To train a CNN
classifier, it is necessary to annotate a large number of training images. This
difficulty prevents the use of CNN in many practical applications. TM-CNN
significantly reduces the manual workload for creating training images by
automatically making most of the annotations and leaving only a small number of
corrections to human reviewers. In testing, TM-CNN achieved an impressive F1
score of 0.991, far outperforming traditional template matching and CNN-based
object detection algorithms.
",2024-01-30 02:23:07+00:00,cs.CV
A blockchain-based e-goverment service for Quantity Surveyors,"  In Spain, quantity surveyors are entitled to carry out official cadastral
surveys, attestations, and certificate issuing according to a well-defined
professional code. Official Associations of Quantity Surveyors and Technical
Architects (COAAT) are responsible for endorsing the documentation related to
actions performed on buildings. An e-platform that enables immutability,
traceability, and a unique property record among all the Spanish COAATs, with
an affordable cost, is essential to streamline the involved processes.
  The blockchain technology and smart contracts have recently emerged as
promising solutions for e-government services due to the inherent features
provided by the technology. In this paper, we identify the design goals and
propose a blockchain-based e-government system for the electronic management of
the documentation generated, submitted, and validated by the Spanish COAATs,
namely, the COAATChain. The proposal has been deployed and evaluated on the
Binance testnet blockchain, in order to assess its affordability.
",2024-01-29 10:24:51+00:00,cs.NI
"HICH Image/Text (HICH-IT): Comprehensive Text and Image Datasets for
  Hypertensive Intracerebral Hemorrhage Research","  In this paper, we introduce a new dataset in the medical field of
hypertensive intracerebral hemorrhage (HICH), called HICH-IT, which includes
both electronic medical records (EMRs) and head CT images. This dataset is
designed to enhance the accuracy of artificial intelligence in the diagnosis
and treatment of HICH. This dataset, built upon the foundation of standard text
and image data, incorporates specific annotations within the EMRs, extracting
key content from the text information, and categorizes the annotation content
of imaging data into four types: brain midline, hematoma, left and right
cerebral ventricle. HICH-IT aims to be a foundational dataset for feature
learning in image segmentation tasks and named entity recognition. To further
understand the dataset, we have trained deep learning algorithms to observe the
performance. The pretrained models have been released at both www.daip.club and
github.com/Deep-AI-Application-DAIP. The dataset has been uploaded to
https://github.com/CYBUS123456/HICH-IT-Datasets.
  Index Terms-HICH, Deep learning, Intraparenchymal hemorrhage, named entity
recognition, novel dataset
",2024-01-29 07:44:09+00:00,cs.CV
"OntoMedRec: Logically-Pretrained Model-Agnostic Ontology Encoders for
  Medication Recommendation","  Most existing medication recommendation models learn representations for
medical concepts based on electronic health records (EHRs) and make
recommendations with learnt representations. However, most medications appear
in the dataset for limited times, resulting in insufficient learning of their
representations. Medical ontologies are the hierarchical classification systems
for medical terms where similar terms are in the same class on a certain level.
In this paper, we propose OntoMedRec, the logically-pretrained and
model-agnostic medical Ontology Encoders for Medication Recommendation that
addresses data sparsity problem with medical ontologies. We conduct
comprehensive experiments on benchmark datasets to evaluate the effectiveness
of OntoMedRec, and the result shows the integration of OntoMedRec improves the
performance of various models in both the entire EHR datasets and the
admissions with few-shot medications. We provide the GitHub repository for the
source code on https://anonymous.4open.science/r/OntoMedRec-D123
",2024-01-29 00:29:39+00:00,cs.LG
Programmable biomolecule-mediated processors,"  Programmable biomolecule-mediated computing is a new computing paradigm as
compared to contemporary electronic computing. It employs nucleic acids and
analogous biomolecular structures as information-storing and -processing
substrates to tackle computational problems. It is of great significance to
investigate the various issues of programmable biomolecule-mediated processors
that are capable of automatically processing, storing, and displaying
information. This Perspective provides several conceptual designs of
programmable biomolecule-mediated processors and provides some insights into
potential future research directions for programmable biomolecule-mediated
processors.
",2024-01-28 14:27:02+00:00,cs.ET
"Anomaly Detection of Particle Orbit in Accelerator using LSTM Deep
  Learning Technology","  A stable, reliable, and controllable orbit lock system is crucial to an
electron (or ion) accelerator because the beam orbit and beam energy
instability strongly affect the quality of the beam delivered to experimental
halls. Currently, when the orbit lock system fails operators must manually
intervene. This paper develops a Machine Learning based fault detection
methodology to identify orbit lock anomalies and notify accelerator operations
staff of the off-normal behavior. Our method is unsupervised, so it does not
require labeled data. It uses Long-Short Memory Networks (LSTM) Auto Encoder to
capture normal patterns and predict future values of monitoring sensors in the
orbit lock system. Anomalies are detected when the prediction error exceeds a
threshold. We conducted experiments using monitoring data from Jefferson Lab's
Continuous Electron Beam Accelerator Facility (CEBAF). The results are
promising: the percentage of real anomalies identified by our solution is
68.6%-89.3% using monitoring data of a single component in the orbit lock
control system. The accuracy can be as high as 82%.
",2024-01-28 02:09:26+00:00,cs.LG
"Deep Learning with Information Fusion and Model Interpretation for
  Health Monitoring of Fetus based on Long-term Prenatal Electronic Fetal Heart
  Rate Monitoring Data","  Long-term fetal heart rate (FHR) monitoring during the antepartum period,
increasingly popularized by electronic FHR monitoring, represents a growing
approach in FHR monitoring. This kind of continuous monitoring, in contrast to
the short-term one, collects an extended period of fetal heart data. This
offers a more comprehensive understanding of fetus's conditions. However, the
interpretation of long-term antenatal fetal heart monitoring is still in its
early stages, lacking corresponding clinical standards. Furthermore, the
substantial amount of data generated by continuous monitoring imposes a
significant burden on clinical work when analyzed manually. To address above
challenges, this study develops an automatic analysis system named LARA
(Long-term Antepartum Risk Analysis system) for continuous FHR monitoring,
combining deep learning and information fusion methods. LARA's core is a
well-established convolutional neural network (CNN) model. It processes
long-term FHR data as input and generates a Risk Distribution Map (RDM) and
Risk Index (RI) as the analysis results. We evaluate LARA on inner test
dataset, the performance metrics are as follows: AUC 0.872, accuracy 0.816,
specificity 0.811, sensitivity 0.806, precision 0.271, and F1 score 0.415. In
our study, we observe that long-term FHR monitoring data with higher RI is more
likely to result in adverse outcomes (p=0.0021). In conclusion, this study
introduces LARA, the first automated analysis system for long-term FHR
monitoring, initiating the further explorations into its clinical value in the
future.
",2024-01-27 07:59:54+00:00,cs.LG
"Benchmarking with MIMIC-IV, an irregular, spare clinical time series
  dataset","  Electronic health record (EHR) is more and more popular, and it comes with
applying machine learning solutions to resolve various problems in the domain.
This growing research area also raises the need for EHRs accessibility. Medical
Information Mart for Intensive Care (MIMIC) dataset is a popular, public, and
free EHR dataset in a raw format that has been used in numerous studies.
However, despite of its popularity, it is lacking benchmarking work, especially
with recent state of the art works in the field of deep learning with
time-series tabular data. The aim of this work is to fill this lack by
providing a benchmark for latest version of MIMIC dataset, MIMIC-IV. We also
give a detailed literature survey about studies that has been already done for
MIIMIC-III.
",2024-01-27 04:09:41+00:00,cs.LG
Emulating Complex Synapses Using Interlinked Proton Conductors,"  In terms of energy efficiency and computational speed, neuromorphic
electronics based on non-volatile memory devices is expected to be one of most
promising hardware candidates for future artificial intelligence (AI). However,
catastrophic forgetting, networks rapidly overwriting previously learned
weights when learning new tasks, remains as a pivotal hurdle in either digital
or analog AI chips for unleashing the true power of brain-like computing. To
address catastrophic forgetting in the context of online memory storage, a
complex synapse model (the Benna-Fusi model) has been proposed recently[1],
whose synaptic weight and internal variables evolve following a diffusion
dynamics. In this work, by designing a proton transistor with a series of
charge-diffusion-controlled storage components, we have experimentally realized
the Benna-Fusi artificial complex synapse. The memory consolidation from
coupled storage components is revealed by both numerical simulations and
experimental observations. Different memory timescales for the complex synapse
are engineered by the diffusion length of charge carriers, the capacity and
number of coupled storage components. The advantage of the demonstrated complex
synapse in both memory capacity and memory consolidation is revealed by neural
network simulations of face familiarity detection. Our experimental realization
of the complex synapse suggests a promising approach to enhance memory capacity
and to enable continual learning.
",2024-01-26 18:16:06+00:00,cs.NE
"Physical Layer Encryption for Industrial Ethernet in Gigabit Optical
  Links","  Industrial Ethernet is a technology widely spread in factory floors and
critical infrastructures where a high amount of data need to be collected and
transported. Fiber optic networks at gigabit rates fit well with that type of
environments where speed, system performance and reliability are critical. In
this work a new encryption method for high speed optical communications
suitable for such kind of networks is proposed. This new encryption method
consists of a symmetric streaming encryption of the 8b/10b data flow at PCS
(Physical Coding Sublayer) level. It is carried out thanks to an FPE (Format
Preserving Encryption) blockcipher working in CTR (Counter) mode. The overall
system has been simulated and implemented in an FPGA (Field Programmable Gate
Array). Thanks to experimental results it can be concluded that it is possible
to cipher traffic at this physical level in a secure way. In addition, no
overhead is introduced during encryption, getting minimum latency and maximum
throughput.
",2024-01-26 18:01:59+00:00,cs.CR
A High-Performance SurfaceNets Discrete Isocontouring Algorithm,"  Isocontouring is one of the most widely used visualization techniques.
However, many popular contouring algorithms were created prior to the advent of
ubiquitous parallel approaches, such as multi-core, shared memory computing
systems. With increasing data sizes and computational loads, it is essential to
reimagine such algorithms to leverage the increased computing capabilities
available today. To this end we have redesigned the SurfaceNets algorithm, a
powerful technique which is often employed to isocontour non-continuous,
discrete, volumetric scalar fields such as segmentation label maps. Label maps
are ubiquitous to medical computing and biological analysis, used in
applications ranging from anatomical atlas creation to brain connectomics. This
novel Parallel SurfaceNets algorithm has been redesigned using concepts from
the high-performance Flying Edges continuous isocontouring algorrithm. It
consists of two basic steps, surface extraction followed by constrained
smoothing, parallelized over volume edges and employing a double-buffering
smoothing approach to guarantee determinism. The algorithm can extract and
smooth multiple segmented objects in a single execution, producing a polygonal
(triangular/quadrilateral) mesh with points and polygons fully shared between
neighboring objects. Performance is typically one to two orders of magnitude
faster than the current sequential algorithms for discrete isosurface
extraction on small core-count commodity CPU hardware. We demonstrate the
effectiveness of the algorithm on five different datasets including human torso
and brain atlases, mouse brain segmentation, and electron microscopy
connectomics. The software is currently available under a permissive, open
source license in the VTK visualization system.
",2024-01-26 14:38:24+00:00,cs.GR
"TA-RNN: an Attention-based Time-aware Recurrent Neural Network
  Architecture for Electronic Health Records","  Motivation: Electronic Health Records (EHR) represent a comprehensive
resource of a patient's medical history. EHR are essential for utilizing
advanced technologies such as deep learning (DL), enabling healthcare providers
to analyze extensive data, extract valuable insights, and make precise and
data-driven clinical decisions. DL methods such as Recurrent Neural Networks
(RNN) have been utilized to analyze EHR to model disease progression and
predict diagnosis. However, these methods do not address some inherent
irregularities in EHR data such as irregular time intervals between clinical
visits. Furthermore, most DL models are not interpretable. In this study, we
propose two interpretable DL architectures based on RNN, namely Time-Aware RNN
(TA-RNN) and TA-RNN-Autoencoder (TA-RNN-AE) to predict patient's clinical
outcome in EHR at next visit and multiple visits ahead, respectively. To
mitigate the impact of irregular time intervals, we propose incorporating time
embedding of the elapsed times between visits. For interpretability, we propose
employing a dual-level attention mechanism that operates between visits and
features within each visit.
  Results: The results of the experiments conducted on Alzheimer's Disease
Neuroimaging Initiative (ADNI) and National Alzheimer's Coordinating Center
(NACC) datasets indicated superior performance of proposed models for
predicting Alzheimer's Disease (AD) compared to state-of-the-art and baseline
approaches based on F2 and sensitivity. Additionally, TA-RNN showed superior
performance on Medical Information Mart for Intensive Care (MIMIC-III) dataset
for mortality prediction. In our ablation study, we observed enhanced
predictive performance by incorporating time embedding and attention
mechanisms. Finally, investigating attention weights helped identify
influential visits and features in predictions.
",2024-01-26 07:34:53+00:00,cs.LG
"AVELA -- A Vision for Engineering Literacy & Access: Understanding Why
  Technology Alone Is Not Enough","  Unequal technology access for Black and Latine communities has been a
persistent economic, social justice, and human rights issue despite increased
technology accessibility due to advancements in consumer electronics like
phones, tablets, and computers. We contextualize socio-technical access
inequalities for Black and Latine urban communities and find that many students
are hesitant to engage with available technologies due to a lack of engaging
support systems. We present a holistic student-led STEM engagement model
through AVELA - A Vision for Engineering Literacy and Access leveraging
culturally responsive lessons, mentor embodied community representation, and
service learning. To evaluate the model's impact after 4 years of mentoring
200+ university student instructors in teaching to 2,500+ secondary school
students in 100+ classrooms, we conducted 24 semi-structured interviews with
college AnonymizedOrganization members. We identify access barriers and provide
principled recommendations for designing future STEM education programs.
",2024-01-26 00:52:51+00:00,cs.CY
"Prompting Large Language Models for Zero-Shot Clinical Prediction with
  Structured Longitudinal Electronic Health Record Data","  The inherent complexity of structured longitudinal Electronic Health Records
(EHR) data poses a significant challenge when integrated with Large Language
Models (LLMs), which are traditionally tailored for natural language
processing. Motivated by the urgent need for swift decision-making during new
disease outbreaks, where traditional predictive models often fail due to a lack
of historical data, this research investigates the adaptability of LLMs, like
GPT-4, to EHR data. We particularly focus on their zero-shot capabilities,
which enable them to make predictions in scenarios in which they haven't been
explicitly trained. In response to the longitudinal, sparse, and
knowledge-infused nature of EHR data, our prompting approach involves taking
into account specific EHR characteristics such as units and reference ranges,
and employing an in-context learning strategy that aligns with clinical
contexts. Our comprehensive experiments on the MIMIC-IV and TJH datasets
demonstrate that with our elaborately designed prompting framework, LLMs can
improve prediction performance in key tasks such as mortality, length-of-stay,
and 30-day readmission by about 35\%, surpassing ML models in few-shot
settings. Our research underscores the potential of LLMs in enhancing clinical
decision-making, especially in urgent healthcare situations like the outbreak
of emerging diseases with no labeled data. The code is publicly available at
https://github.com/yhzhu99/llm4healthcare for reproducibility.
",2024-01-25 20:14:50+00:00,cs.CL
"TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation
  in VEM images","  While imaging techniques at macro and mesoscales have garnered substantial
attention and resources, microscale Volume Electron Microscopy (vEM) imaging,
capable of revealing intricate vascular details, has lacked the necessary
benchmarking infrastructure. In this paper, we address a significant gap in
this field of neuroimaging by introducing the first-in-class public benchmark,
BvEM, designed specifically for cortical blood vessel segmentation in vEM
images. Our BvEM benchmark is based on vEM image volumes from three mammals:
adult mouse, macaque, and human. We standardized the resolution, addressed
imaging variations, and meticulously annotated blood vessels through
semi-automatic, manual, and quality control processes, ensuring high-quality 3D
segmentation. Furthermore, we developed a zero-shot cortical blood vessel
segmentation method named TriSAM, which leverages the powerful segmentation
model SAM for 3D segmentation. To extend SAM from 2D to 3D volume segmentation,
TriSAM employs a multi-seed tracking framework, leveraging the reliability of
certain image planes for tracking while using others to identify potential
turning points. This approach effectively achieves long-term 3D blood vessel
segmentation without model training or fine-tuning. Experimental results show
that TriSAM achieved superior performances on the BvEM benchmark across three
species. Our dataset, code, and model are available online at
\url{https://jia-wan.github.io/bvem}.
",2024-01-25 05:50:48+00:00,cs.CV
"Precise Robotic Weed Spot-Spraying for Reduced Herbicide Usage and
  Improved Environmental Outcomes -- A Real-World Case Study","  Precise robotic weed control plays an essential role in precision
agriculture. It can help significantly reduce the environmental impact of
herbicides while reducing weed management costs for farmers. In this paper, we
demonstrate that a custom-designed robotic spot spraying tool based on computer
vision and deep learning can significantly reduce herbicide usage on sugarcane
farms. We present results from field trials that compare robotic spot spraying
against industry-standard broadcast spraying, by measuring the weed control
efficacy, the reduction in herbicide usage, and the water quality improvements
in irrigation runoff. The average results across 25 hectares of field trials
show that spot spraying on sugarcane farms is 97% as effective as broadcast
spraying and reduces herbicide usage by 35%, proportionally to the weed
density. For specific trial strips with lower weed pressure, spot spraying
reduced herbicide usage by up to 65%. Water quality measurements of
irrigation-induced runoff, three to six days after spraying, showed reductions
in the mean concentration and mean load of herbicides of 39% and 54%,
respectively, compared to broadcast spraying. These promising results reveal
the capability of spot spraying technology to reduce herbicide usage on
sugarcane farms without impacting weed control and potentially providing
sustained water quality benefits.
",2024-01-25 04:04:44+00:00,cs.RO
"Inadequacy of common stochastic neural networks for reliable clinical
  decision support","  Widespread adoption of AI for medical decision making is still hindered due
to ethical and safety-related concerns. For AI-based decision support systems
in healthcare settings it is paramount to be reliable and trustworthy. Common
deep learning approaches, however, have the tendency towards overconfidence
under data shift. Such inappropriate extrapolation beyond evidence-based
scenarios may have dire consequences. This highlights the importance of
reliable estimation of local uncertainty and its communication to the end user.
While stochastic neural networks have been heralded as a potential solution to
these issues, this study investigates their actual reliability in clinical
applications. We centered our analysis on the exemplary use case of mortality
prediction for ICU hospitalizations using EHR from MIMIC3 study. For
predictions on the EHR time series, Encoder-Only Transformer models were
employed. Stochasticity of model functions was achieved by incorporating common
methods such as Bayesian neural network layers and model ensembles. Our models
achieve state of the art performance in terms of discrimination performance
(AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality
prediction benchmark. However, epistemic uncertainty is critically
underestimated by the selected stochastic deep learning methods. A heuristic
proof for the responsible collapse of the posterior distribution is provided.
Our findings reveal the inadequacy of commonly used stochastic deep learning
approaches to reliably recognize OoD samples. In both methods, unsubstantiated
model confidence is not prevented due to strongly biased functional posteriors,
rendering them inappropriate for reliable clinical decision support. This
highlights the need for approaches with more strictly enforced or inherent
distance-awareness to known data points, e.g., using kernel-based techniques.
",2024-01-24 18:49:30+00:00,cs.LG
"Evaluation of General Large Language Models in Contextually Assessing
  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record
  Notes","  The field of healthcare has increasingly turned its focus towards Large
Language Models (LLMs) due to their remarkable performance. However, their
performance in actual clinical applications has been underexplored. Traditional
evaluations based on question-answering tasks don't fully capture the nuanced
contexts. This gap highlights the need for more in-depth and practical
assessments of LLMs in real-world healthcare settings. Objective: We sought to
evaluate the performance of LLMs in the complex clinical context of adult
critical care medicine using systematic and comprehensible analytic methods,
including clinician annotation and adjudication. Methods: We investigated the
performance of three general LLMs in understanding and processing real-world
clinical notes. Concepts from 150 clinical notes were identified by MetaMap and
then labeled by 9 clinicians. Each LLM's proficiency was evaluated by
identifying the temporality and negation of these concepts using different
prompts for an in-depth analysis. Results: GPT-4 showed overall superior
performance compared to other LLMs. In contrast, both GPT-3.5 and
text-davinci-003 exhibit enhanced performance when the appropriate prompting
strategies are employed. The GPT family models have demonstrated considerable
efficiency, evidenced by their cost-effectiveness and time-saving capabilities.
Conclusion: A comprehensive qualitative performance evaluation framework for
LLMs is developed and operationalized. This framework goes beyond singular
performance aspects. With expert annotations, this methodology not only
validates LLMs' capabilities in processing complex medical data but also
establishes a benchmark for future LLM evaluations across specialized domains.
",2024-01-24 16:52:37+00:00,cs.CL
"SpecLLM: Exploring Generation and Review of VLSI Design Specification
  with Large Language Model","  The development of architecture specifications is an initial and fundamental
stage of the integrated circuit (IC) design process. Traditionally,
architecture specifications are crafted by experienced chip architects, a
process that is not only time-consuming but also error-prone. Mistakes in these
specifications may significantly affect subsequent stages of chip design.
Despite the presence of advanced electronic design automation (EDA) tools,
effective solutions to these specification-related challenges remain scarce.
Since writing architecture specifications is naturally a natural language
processing (NLP) task, this paper pioneers the automation of architecture
specification development with the advanced capabilities of large language
models (LLMs). Leveraging our definition and dataset, we explore the
application of LLMs in two key aspects of architecture specification
development: (1) Generating architecture specifications, which includes both
writing specifications from scratch and converting RTL code into detailed
specifications. (2) Reviewing existing architecture specifications. We got
promising results indicating that LLMs may revolutionize how these critical
specification documents are developed in IC design nowadays. By reducing the
effort required, LLMs open up new possibilities for efficiency and accuracy in
this crucial aspect of chip design.
",2024-01-24 07:13:03+00:00,cs.AR
"Nonlinear dynamics in neuromorphic photonic networks: physical
  simulation in Verilog-A","  Advances in silicon photonics technology have enabled the field of
neuromorphic photonics, where analog neuron-like processing elements are
implemented in silicon photonics technology. Accurate and scalable simulation
tools for photonic integrated circuits are critical for designing neuromorphic
photonic circuits. This is especially important when designing networks with
recurrent connections, where the dynamics of the system may give rise to
unstable and oscillatory solutions which need to be accurately modelled. These
tools must simultaneously simulate the analog electronics and the multi-channel
(wavelength-division-multiplexed) photonics contained in a photonic neuron to
accurately predict on-chip behaviour. In this paper, we utilize a Verilog-A
model of the photonic neural network to investigate the dynamics of recurrent
integrated circuits. We begin by reviewing the theory of continuous-time
recurrent neural networks as dynamical systems and the relation of these
dynamics to important physical features of photonic neurons such as
cascadability. We then present the neural dynamics of systems of one and two
neurons in the simulated Verilog-A circuit, which are compared to the expected
dynamics of the abstract CTRNN model. Due to the presence of parasitic circuit
elements in the Verilog-A simulation, it is seen that there is a topological
equivalence, but not an exact isomorphism, between the theoretical model and
the simulated model. The implications of these discrepancies for the design of
neuromorphic photonic circuits are discussed. Our findings pave the way for the
practical implementation of large-scale silicon photonic recurrent neural
networks.
",2024-01-23 17:58:55+00:00,cs.ET
"Availability-aware Service Placement Policy in Fog Computing Based on
  Graph Partitions","  This paper presents a policy for service placement of fog applications
inspired on complex networks and graph theory. We propose a twofold partition
process based on communities for the partition of the fog devices and based on
transitive closures for the application services partition. The allocation of
the services is performed sequentially by, firstly, mapping applications to
device communities and, secondly, mapping service transitive closures to fog
devices in the community. The underlying idea is to place as many inter-related
services as possible in the most nearby devices to the users. The optimization
objectives are the availability of the applications and the Quality of Service
(QoS) of the system, measured as the number of requests that are executed
before the application deadlines. We compared our solution with an Integer
Linear Programming approach, and the simulation results showed that our
proposal obtains higher QoS and availability when fails in the nodes are
considered.
",2024-01-23 11:55:40+00:00,cs.NI
"Development of an NLP-driven computer-based test guide for visually
  impaired students","  In recent years, advancements in Natural Language Processing (NLP) techniques
have revolutionized the field of accessibility and exclusivity of testing,
particularly for visually impaired students (VIS). CBT has shown in years back
its relevance in terms of administering exams electronically, making the test
process easier, providing quicker and more accurate results, and offering
greater flexibility and accessibility for candidates. Yet, its relevance was
not felt by the visually impaired students as they cannot access printed
documents. Hence, in this paper, we present an NLP-driven Computer-Based Test
guide for visually impaired students. It employs a speech technology
pre-trained methods to provide real-time assistance and support to visually
impaired students. The system utilizes NLP technologies to convert the
text-based questions and the associated options in a machine-readable format.
Subsequently, the speech technology pre-trained model processes the converted
text enabling the VIS to comprehend and analyze the content. Furthermore, we
validated that this pre-trained model is not perverse by testing for accuracy
using sample audio datasets labels (A, B, C, D, E, F, G) to compare with the
voice recordings obtained from 20 VIS which is been predicted by the system to
attain values for precision, recall, and F1-scores. These metrics are used to
assess the performance of the pre-trained model and have indicated that it is
proficient enough to give its better performance to the evaluated system. The
methodology adopted for this system is Object Oriented Analysis and Design
Methodology (OOADM) where Objects are discussed and built by modeling
real-world instances.
",2024-01-22 21:59:00+00:00,cs.CL
"Contrastive Learning and Cycle Consistency-based Transductive Transfer
  Learning for Target Annotation","  Annotating automatic target recognition (ATR) is a highly challenging task,
primarily due to the unavailability of labeled data in the target domain.
Hence, it is essential to construct an optimal target domain classifier by
utilizing the labeled information of the source domain images. The transductive
transfer learning (TTL) method that incorporates a CycleGAN-based unpaired
domain translation network has been previously proposed in the literature for
effective ATR annotation. Although this method demonstrates great potential for
ATR, it severely suffers from lower annotation performance, higher Fr\'echet
Inception Distance (FID) score, and the presence of visual artifacts in the
synthetic images. To address these issues, we propose a hybrid contrastive
learning base unpaired domain translation (H-CUT) network that achieves a
significantly lower FID score. It incorporates both attention and entropy to
emphasize the domain-specific region, a noisy feature mixup module to generate
high variational synthetic negative patches, and a modulated noise contrastive
estimation (MoNCE) loss to reweight all negative patches using optimal
transport for better performance. Our proposed contrastive learning and
cycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks
and two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and
identity losses. In C3TTL, two H-CUT networks have been employed through a
bijection mapping to feed the reconstructed source domain images into a
pretrained classifier to guide the optimal target domain classifier. Extensive
experimental analysis conducted on three ATR datasets demonstrates that the
proposed C3TTL method is effective in annotating civilian and military
vehicles, as well as ship targets.
",2024-01-22 20:08:57+00:00,cs.CV
HgbNet: predicting hemoglobin level/anemia degree from EHR data,"  Anemia is a prevalent medical condition that typically requires invasive
blood tests for diagnosis and monitoring. Electronic health records (EHRs) have
emerged as valuable data sources for numerous medical studies. EHR-based
hemoglobin level/anemia degree prediction is non-invasive and rapid but still
faces some challenges due to the fact that EHR data is typically an irregular
multivariate time series containing a significant number of missing values and
irregular time intervals. To address these issues, we introduce HgbNet, a
machine learning-based prediction model that emulates clinicians'
decision-making processes for hemoglobin level/anemia degree prediction. The
model incorporates a NanDense layer with a missing indicator to handle missing
values and employs attention mechanisms to account for both local irregularity
and global irregularity. We evaluate the proposed method using two real-world
datasets across two use cases. In our first use case, we predict hemoglobin
level/anemia degree at moment T+1 by utilizing records from moments prior to
T+1. In our second use case, we integrate all historical records with
additional selected test results at moment T+1 to predict hemoglobin
level/anemia degree at the same moment, T+1. HgbNet outperforms the best
baseline results across all datasets and use cases. These findings demonstrate
the feasibility of estimating hemoglobin levels and anemia degree from EHR
data, positioning HgbNet as an effective non-invasive anemia diagnosis solution
that could potentially enhance the quality of life for millions of affected
individuals worldwide. To our knowledge, HgbNet is the first machine learning
model leveraging EHR data for hemoglobin level/anemia degree prediction.
",2024-01-22 14:52:34+00:00,cs.LG
"Effective Intrusion Detection in Heterogeneous Internet-of-Things
  Networks via Ensemble Knowledge Distillation-based Federated Learning","  With the rapid development of low-cost consumer electronics and cloud
computing, Internet-of-Things (IoT) devices are widely adopted for supporting
next-generation distributed systems such as smart cities and industrial control
systems. IoT devices are often susceptible to cyber attacks due to their open
deployment environment and limited computing capabilities for stringent
security controls. Hence, Intrusion Detection Systems (IDS) have emerged as one
of the effective ways of securing IoT networks by monitoring and detecting
abnormal activities. However, existing IDS approaches rely on centralized
servers to generate behaviour profiles and detect anomalies, causing high
response time and large operational costs due to communication overhead.
Besides, sharing of behaviour data in an open and distributed IoT network
environment may violate on-device privacy requirements. Additionally, various
IoT devices tend to capture heterogeneous data, which complicates the training
of behaviour models. In this paper, we introduce Federated Learning (FL) to
collaboratively train a decentralized shared model of IDS, without exposing
training data to others. Furthermore, we propose an effective method called
Federated Learning Ensemble Knowledge Distillation (FLEKD) to mitigate the
heterogeneity problems across various clients. FLEKD enables a more flexible
aggregation method than conventional model fusion techniques. Experiment
results on the public dataset CICIDS2019 demonstrate that the proposed approach
outperforms local training and traditional FL in terms of both speed and
performance and significantly improves the system's ability to detect unknown
attacks. Finally, we evaluate our proposed framework's performance in three
potential real-world scenarios and show FLEKD has a clear advantage in
experimental results.
",2024-01-22 14:16:37+00:00,cs.CR
Toward Semantic Interoperability of Electronic Health Records,"  Although the goal of achieving semantic interoperability of electronic health
records (EHRs) is pursued by many researchers, it has not been accomplished
yet. In this paper, we present a proposal that smoothes out the way toward the
achievement of that goal. In particular, our study focuses on medical diagnoses
statements. In summary, the main contributions of our ontology-based proposal
are the following: first, it includes a canonical ontology whose EHR-related
terms focus on semantic aspects. As a result, their descriptions are
independent of languages and technology aspects used in different organizations
to represent EHRs. Moreover, those terms are related to their corresponding
codes in well-known medical terminologies. Second, it deals with modules that
allow obtaining rich ontological representations of EHR information managed by
proprietary models of health information systems. The features of one specific
module are shown as reference. Third, it considers the necessary mapping axioms
between ontological terms enhanced with so-called path mappings. This feature
smoothes out structural differences between heterogeneous EHR representations,
allowing proper alignment of information.
",2024-01-22 11:39:55+00:00,cs.AI
"Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal
  Contrastive EHR Modelling with Hierarchical Regularisation","  Predicting next visit diagnosis using Electronic Health Records (EHR) is an
essential task in healthcare, critical for devising proactive future plans for
both healthcare providers and patients. Nonetheless, many preceding studies
have not sufficiently addressed the heterogeneous and hierarchical
characteristics inherent in EHR data, inevitably leading to sub-optimal
performance. To this end, we propose NECHO, a novel medical code-centric
multimodal contrastive EHR learning framework with hierarchical regularisation.
First, we integrate multifaceted information encompassing medical codes,
demographics, and clinical notes using a tailored network design and a pair of
bimodal contrastive losses, all of which pivot around a medical codes
representation. We also regularise modality-specific encoders using a parental
level information in medical ontology to learn hierarchical structure of EHR
data. A series of experiments on MIMIC-III data demonstrates effectiveness of
our approach.
",2024-01-22 01:58:32+00:00,cs.LG
"Understanding users negative emotions and continuous usage intention in
  short video platforms","  While short videos bring a lot of information and happiness to users, they
also occupy users time and short videos gradually change peoples living habits.
This paper studies the negative effects and negative emotions of users caused
by using short video platforms, as well as the users intention to continue
using the short video platform when they have negative emotions. Therefore,
this study uses flow theory and illusion of control theory to construct a
research hypothesis model and preliminarily confirms six influencing factors,
and uses sequential mixed research method to conduct quantitative and
qualitative research. The results show that users use of short video platforms
will have negative emotions and negative emotions will affect users intention
to continue to use short video platforms. This study expands the breadth and
depth of research on short videos and enriches the research of negative
emotions on the intention to continue using human computer interaction
software. Additionally, illusion of control theory is introduced into the field
of human computer interaction for the first time, which enriches the
application scenarios of control illusion theory.
",2024-01-20 15:34:16+00:00,cs.HC
"Automated Fusion of Multimodal Electronic Health Records for Better
  Medical Predictions","  The widespread adoption of Electronic Health Record (EHR) systems in
healthcare institutes has generated vast amounts of medical data, offering
significant opportunities for improving healthcare services through deep
learning techniques. However, the complex and diverse modalities and feature
structures in real-world EHR data pose great challenges for deep learning model
design. To address the multi-modality challenge in EHR data, current approaches
primarily rely on hand-crafted model architectures based on intuition and
empirical experiences, leading to sub-optimal model architectures and limited
performance. Therefore, to automate the process of model design for mining EHR
data, we propose a novel neural architecture search (NAS) framework named
AutoFM, which can automatically search for the optimal model architectures for
encoding diverse input modalities and fusion strategies. We conduct thorough
experiments on real-world multi-modal EHR data and prediction tasks, and the
results demonstrate that our framework not only achieves significant
performance improvement over existing state-of-the-art methods but also
discovers meaningful network architectures effectively.
",2024-01-20 15:14:14+00:00,cs.LG
"Collaborative consumption for low and high trust requiring business
  models: from fare sharing to supporting the elderly and people with
  disability","  This paper offers an overview of collaborative consumption (CC), the related
business models (BM), the value added (VA) from the consumer's perspective and
the role of trust. CC is expanding but it is unclear what opportunities it
offers and what the challenges will be. This research evaluates the current CC
BMs and identifies 13 ways they add value from the consumer's perspective. This
research further explores whether CC BMs fall into two categories in terms of
what the consumer values. In the first category, the CC BMs require a low level
of trust while in the second category of CC BMs a higher level of trust is
necessary. It was found that 13 VA by CC BMs could be grouped into personal
interest, communal interest and trust building. It is important for
organisations to acknowledge how their CC BM relates to these dimensions.
",2024-01-20 13:53:59+00:00,cs.HC
Dynamic Q&A of Clinical Documents with Large Language Models,"  Electronic health records (EHRs) house crucial patient data in clinical
notes. As these notes grow in volume and complexity, manual extraction becomes
challenging. This work introduces a natural language interface using large
language models (LLMs) for dynamic question-answering on clinical notes. Our
chatbot, powered by Langchain and transformer-based LLMs, allows users to query
in natural language, receiving relevant answers from clinical notes.
Experiments, utilizing various embedding models and advanced LLMs, show Wizard
Vicuna's superior accuracy, albeit with high compute demands. Model
optimization, including weight quantization, improves latency by approximately
48 times. Promising results indicate potential, yet challenges such as model
hallucinations and limited diverse medical case evaluations remain. Addressing
these gaps is crucial for unlocking the value in clinical notes and advancing
AI-driven clinical decision-making.
",2024-01-19 14:50:22+00:00,cs.IR
"No-Clean-Reference Image Super-Resolution: Application to Electron
  Microscopy","  The inability to acquire clean high-resolution (HR) electron microscopy (EM)
images over a large brain tissue volume hampers many neuroscience studies. To
address this challenge, we propose a deep-learning-based image super-resolution
(SR) approach to computationally reconstruct clean HR 3D-EM with a large field
of view (FoV) from noisy low-resolution (LR) acquisition. Our contributions are
I) Investigating training with no-clean references for $\ell_2$ and $\ell_1$
loss functions; II) Introducing a novel network architecture, named EMSR, for
enhancing the resolution of LR EM images while reducing inherent noise; and,
III) Comparing different training strategies including using acquired LR and HR
image pairs, i.e., real pairs with no-clean references contaminated with real
corruptions, the pairs of synthetic LR and acquired HR, as well as acquired LR
and denoised HR pairs. Experiments with nine brain datasets showed that
training with real pairs can produce high-quality super-resolved results,
demonstrating the feasibility of training with non-clean references for both
loss functions. Additionally, comparable results were observed, both visually
and numerically, when employing denoised and noisy references for training.
Moreover, utilizing the network trained with synthetically generated LR images
from HR counterparts proved effective in yielding satisfactory SR results, even
in certain cases, outperforming training with real pairs. The proposed SR
network was compared quantitatively and qualitatively with several established
SR techniques, showcasing either the superiority or competitiveness of the
proposed method in mitigating noise while recovering fine details.
",2024-01-16 05:05:08+00:00,cs.CV
"Preserving Power Optimizations Across the High Level Synthesis of
  Distinct Application-Specific Circuits","  We evaluate the use of software interpretation to push High Level Synthesis
of application-specific accelerators toward a higher level of abstraction. Our
methodology is supported by a formal power consumption model that computes the
power consumption of accelerator components, accurately predicting the power
consumption on new designs from prior optimization estimations. We demonstrate
how our approach simplifies the re-use of power optimizations across distinct
designs, by leveraging the higher level of design abstraction, using two
accelerators representative of the robotics domain, implemented through the
Bambu High Level Synthesis tool. Results support the research hypothesis,
achieving predictions accurate within +/- 1%.
",2024-01-15 14:40:28+00:00,cs.PL
"Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep
  Learning","  The risk of hardware Trojans being inserted at various stages of chip
production has increased in a zero-trust fabless era. To counter this, various
machine learning solutions have been developed for the detection of hardware
Trojans. While most of the focus has been on either a statistical or deep
learning approach, the limited number of Trojan-infected benchmarks affects the
detection accuracy and restricts the possibility of detecting zero-day Trojans.
To close the gap, we first employ generative adversarial networks to amplify
our data in two alternative representation modalities, a graph and a tabular,
ensuring that the dataset is distributed in a representative manner. Further,
we propose a multimodal deep learning approach to detect hardware Trojans and
evaluate the results from both early fusion and late fusion strategies. We also
estimate the uncertainty quantification metrics of each prediction for
risk-aware decision-making. The outcomes not only confirms the efficacy of our
proposed hardware Trojan detection method but also opens a new door for future
studies employing multimodality and uncertainty quantification to address other
hardware security challenges.
",2024-01-15 05:45:51+00:00,cs.CR
"EHRAgent: Code Empowers Large Language Models for Few-shot Complex
  Tabular Reasoning on Electronic Health Records","  Large language models (LLMs) have demonstrated exceptional capabilities in
planning and tool utilization as autonomous agents, but few have been developed
for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a
code interface, to autonomously generate and execute code for multi-tabular
reasoning within electronic health records (EHRs). First, we formulate an EHR
question-answering task into a tool-use planning process, efficiently
decomposing a complicated task into a sequence of manageable actions. By
integrating interactive coding and execution feedback, EHRAgent learns from
error messages and improves the originally generated code through iterations.
Furthermore, we enhance the LLM agent by incorporating long-term memory, which
allows EHRAgent to effectively select and build upon the most relevant
successful cases from past experiences. Experiments on three real-world
multi-tabular EHR datasets show that EHRAgent outperforms the strongest
baseline by up to 29.6% in success rate. EHRAgent leverages the emerging
few-shot learning capabilities of LLMs, enabling autonomous code generation and
execution to tackle complex clinical tasks with minimal demonstrations.
",2024-01-13 18:09:05+00:00,cs.CL
"Classification of Volatile Organic Compounds by Differential Mobility
  Spectrometry Based on Continuity of Alpha Curves","  Background: Classification of volatile organic compounds (VOCs) is of
interest in many fields. Examples include but are not limited to medicine,
detection of explosives, and food quality control. Measurements collected with
electronic noses can be used for classification and analysis of VOCs. One type
of electronic noses that has seen considerable development in recent years is
Differential Mobility Spectrometry (DMS). DMS yields measurements that are
visualized as dispersion plots that contain traces, also known as alpha curves.
Current methods used for analyzing DMS dispersion plots do not usually utilize
the information stored in the continuity of these traces, which suggests that
alternative approaches should be investigated.
  Results: In this work, for the first time, dispersion plots were interpreted
as a series of measurements evolving sequentially. Thus, it was hypothesized
that time-series classification algorithms can be effective for classification
and analysis of dispersion plots. An extensive dataset of 900 dispersion plots
for five chemicals measured at five flow rates and two concentrations was
collected. The data was used to analyze the classification performance of six
algorithms. According to our hypothesis, the highest classification accuracy of
88\% was achieved by a Long-Short Term Memory neural network, which supports
our hypothesis.
  Significance: A new concept for approaching classification tasks of
dispersion plots is presented and compared with other well-known classification
algorithms. This creates a new angle of view for analysis and classification of
the dispersion plots. In addition, a new dataset of dispersion plots is openly
shared to public.
",2024-01-13 12:56:04+00:00,cs.LG
"Secure Targeted Message Dissemination in IoT Using Blockchain Enabled
  Edge Computing","  Smart devices are considered as an integral part of Internet of Things (IoT),
have an aim to make a dynamic network to exchange information, collect data,
analysis, and make optimal decisions in an autonomous way to achieve more
efficient, automatic, and economical services. Message dissemination among
these smart devices allows adding new features, sending updated instructions,
alerts or safety messages, informing the pricing information or billing amount,
incentives, and installing security patches. On one hand, such message
disseminations are directly beneficial to the all parties involved in the IoT
system. On the other hand, due to remote procedure, smart devices, vendors, and
other involved authorities might have to meet a number of security, privacy,
and performance related concerns while disseminating messages among targeted
devices. To this end, in this paper, we design STarEdgeChain, a security and
privacy aware targeted message dissemination in IoT to show how blockchain
along with advanced cryptographic techniques are devoted to address such
concerns. In fact, the STarEdgeChain employs a permissioned blockchain assisted
edge computing in order to expedite a single signcrypted message dissemination
among targeted groups of devices, at the same time avoiding the dependency of
utilizing multiple unicasting approaches. Finally, we develop a software
prototype of STarEdgeChain and show it's practicability for smart devices. The
codes are publicly available at https://github.com/mbaqer/Blockchain-IoT
",2024-01-12 05:19:51+00:00,cs.CR
"Send Message to the Future? Blockchain-based Time Machines for
  Decentralized Reveal of Locked Information","  Conditional information reveal systems automate the release of information
upon meeting specific predefined conditions, such as time or location. This
paper introduces a breakthrough in the understanding, design and application of
conditional information reveal systems that are highly secure and
decentralized. By designing a new practical timed-release cryptography system
and a verifiable secret sharing scheme, a novel data sharing system is devised
on the blockchain that `sends messages in the future' with highly accurate
decryption times. This paper provides a complete evaluation portfolio of this
pioneering paradigm, including analytical results, a validation of its
robustness in the Tamarin Prover and a performance evaluation of a real-world,
open-source system prototype deployed across the globe. Using real-world
election data, we also demonstrate the applicability of this innovative system
in e-voting, illustrating its capacity to secure and ensure fair electronic
voting processes.
",2024-01-11 14:34:56+00:00,cs.CR
"MatSAM: Efficient Extraction of Microstructures of Materials via Visual
  Large Model","  Efficient and accurate extraction of microstructures in micrographs of
materials is essential in process optimization and the exploration of
structure-property relationships. Deep learning-based image segmentation
techniques that rely on manual annotation are laborious and time-consuming and
hardly meet the demand for model transferability and generalization on various
source images. Segment Anything Model (SAM), a large visual model with powerful
deep feature representation and zero-shot generalization capabilities, has
provided new solutions for image segmentation. In this paper, we propose
MatSAM, a general and efficient microstructure extraction solution based on
SAM. A simple yet effective point-based prompt generation strategy is designed,
grounded on the distribution and shape of microstructures. Specifically, in an
unsupervised and training-free way, it adaptively generates prompt points for
different microscopy images, fuses the centroid points of the coarsely
extracted region of interest (ROI) and native grid points, and integrates
corresponding post-processing operations for quantitative characterization of
microstructures of materials. For common microstructures including grain
boundary and multiple phases, MatSAM achieves superior zero-shot segmentation
performance to conventional rule-based methods and is even preferable to
supervised learning methods evaluated on 16 microscopy datasets whose
micrographs are imaged by the optical microscope (OM) and scanning electron
microscope (SEM). Especially, on 4 public datasets, MatSAM shows unexpected
competitive segmentation performance against their specialist models. We
believe that, without the need for human labeling, MatSAM can significantly
reduce the cost of quantitative characterization and statistical analysis of
extensive microstructures of materials, and thus accelerate the design of new
materials.
",2024-01-11 03:18:18+00:00,cs.CV
"SpatialVisVR: An Immersive, Multiplexed Medical Image Viewer With
  Contextual Similar-Patient Search","  In contemporary pathology, multiplexed immunofluorescence (mIF) and multiplex
immunohistochemistry (mIHC) present both significant opportunities and
challenges. These methodologies shed light on intricate tumor microenvironment
interactions, emphasizing the need for intuitive visualization tools to analyze
vast biological datasets effectively. As electronic health records (EHR)
proliferate and physicians face increasing information overload, the
integration of advanced technologies becomes imperative. SpatialVisVR emerges
as a versatile VR platform tailored for comparing medical images, with
adaptability for data privacy on embedded hardware. Clinicians can capture
pathology slides in real-time via mobile devices, leveraging SpatialVisVR's
deep learning algorithm to match and display similar mIF images. This interface
supports the manipulation of up to 100 multiplexed protein channels, thereby
assisting in immuno-oncology decision-making. Ultimately, SpatialVisVR aims to
streamline diagnostic processes, advocating for a comprehensive and efficient
approach to immuno-oncology research and treatment.
",2024-01-05 16:22:58+00:00,cs.HC
"Bespoke Approximation of Multiplication-Accumulation and Activation
  Targeting Printed Multilayer Perceptrons","  Printed Electronics (PE) feature distinct and remarkable characteristics that
make them a prominent technology for achieving true ubiquitous computing. This
is particularly relevant in application domains that require conformal and
ultra-low cost solutions, which have experienced limited penetration of
computing until now. Unlike silicon-based technologies, PE offer unparalleled
features such as non-recurring engineering costs, ultra-low manufacturing cost,
and on-demand fabrication of conformal, flexible, non-toxic, and stretchable
hardware. However, PE face certain limitations due to their large feature
sizes, that impede the realization of complex circuits, such as machine
learning classifiers. In this work, we address these limitations by leveraging
the principles of Approximate Computing and Bespoke (fully-customized) design.
We propose an automated framework for designing ultra-low power Multilayer
Perceptron (MLP) classifiers which employs, for the first time, a holistic
approach to approximate all functions of the MLP's neurons: multiplication,
accumulation, and activation. Through comprehensive evaluation across various
MLPs of varying size, our framework demonstrates the ability to enable
battery-powered operation of even the most intricate MLP architecture examined,
significantly surpassing the current state of the art.
",2023-12-29 14:16:11+00:00,cs.AR
"README: Bridging Medical Jargon and Lay Understanding for Patient
  Education through Data-Centric NLP","  The advancement in healthcare has shifted focus toward patient-centric
approaches, particularly in self-care and patient education, facilitated by
access to Electronic Health Records (EHR). However, medical jargon in EHRs
poses significant challenges in patient comprehension. To address this, we
introduce a new task of automatically generating lay definitions, aiming to
simplify complex medical terms into patient-friendly lay language. We first
created the README dataset, an extensive collection of over 50,000 unique
(medical term, lay definition) pairs and 300,000 mentions, each offering
context-aware lay definitions manually annotated by domain experts. We have
also engineered a data-centric Human-AI pipeline that synergizes data
filtering, augmentation, and selection to improve data quality. We then used
README as the training data for models and leveraged a Retrieval-Augmented
Generation method to reduce hallucinations and improve the quality of model
outputs. Our extensive automatic and human evaluations demonstrate that
open-source mobile-friendly models, when fine-tuned with high-quality data, are
capable of matching or even surpassing the performance of state-of-the-art
closed-source large language models like ChatGPT. This research represents a
significant stride in closing the knowledge gap in patient education and
advancing patient-centric healthcare solutions.
",2023-12-24 23:01:00+00:00,cs.CL
"MixEHR-SurG: a joint proportional hazard and guided topic model for
  inferring mortality-associated topics from electronic health records","  Survival models can help medical practitioners to evaluate the prognostic
importance of clinical variables to patient outcomes such as mortality or
hospital readmission and subsequently design personalized treatment regimes.
Electronic Health Records (EHRs) hold the promise for large-scale survival
analysis based on systematically recorded clinical features for each patient.
However, existing survival models either do not scale to high dimensional and
multi-modal EHR data or are difficult to interpret. In this study, we present a
supervised topic model called MixEHR-SurG to simultaneously integrate
heterogeneous EHR data and model survival hazard. Our contributions are
three-folds: (1) integrating EHR topic inference with Cox proportional hazards
likelihood; (2) integrating patient-specific topic hyperparameters using the
PheCode concepts such that each topic can be identified with exactly one
PheCode-associated phenotype; (3) multi-modal survival topic inference. This
leads to a highly interpretable survival topic model that can infer
PheCode-specific phenotype topics associated with patient mortality. We
evaluated MixEHR-SurG using a simulated dataset and two real-world EHR
datasets: the Quebec Congenital Heart Disease (CHD) data consisting of 8,211
subjects with 75,187 outpatient claim records of 1,767 unique ICD codes; the
MIMIC-III consisting of 1,458 subjects with multi-modal EHR records. Compared
to the baselines, MixEHR-SurG achieved a superior dynamic AUROC for mortality
prediction, with a mean AUROC score of 0.89 in the simulation dataset and a
mean AUROC of 0.645 on the CHD dataset. Qualitatively, MixEHR-SurG associates
severe cardiac conditions with high mortality risk among the CHD patients after
the first heart failure hospitalization and critical brain injuries with
increased mortality among the MIMIC-III patients after their ICU discharge.
",2023-12-20 22:13:45+00:00,cs.LG
"CABBA: Compatible Authenticated Bandwidth-efficient Broadcast protocol
  for ADS-B","  The Automatic Dependent Surveillance-Broadcast (ADS-B) is a surveillance
technology that becomes mandatory in many airspaces. It improves safety,
increases efficiency and reduces air traffic congestion by broadcasting
aircraft navigation data. Yet, ADS-B is vulnerable to spoofing attacks as it
lacks mechanisms to ensure the integrity and authenticity of the data being
supplied. None of the existing cryptographic solutions fully meet the backward
compatibility and bandwidth preservation requirements of the standard. Hence,
we propose the Compatible Authenticated Bandwidth-efficient Broadcast protocol
for ADS-B (CABBA), an improved approach that integrates TESLA, phase-overlay
modulation techniques and certificate-based PKI. As a result, entity
authentication, data origin authentication, and data integrity are the security
services that CABBA offers. To assess compliance with the standard, we designed
an SDR-based implementation of CABBA and performed backward compatibility tests
on commercial and general aviation (GA) ADS-B in receivers. Besides, we
calculated the 1090ES band's activity factor and analyzed the channel occupancy
rate according to ITU-R SM.2256-1 recommendation. Also, we performed a bit
error rate analysis of CABBA messages. The results suggest that CABBA is
backward compatible, does not incur significant communication overhead, and has
an error rate that is acceptable for Eb/No values above 14 dB.
",2023-12-15 15:17:41+00:00,cs.CR
A Machine Learning Approach Towards SKILL Code Autocompletion,"  As Moore's Law continues to increase the complexity of electronic systems,
Electronic Design Automation (EDA) must advance to meet global demand. An
important example of an EDA technology is SKILL, a scripting language used to
customize and extend EDA software. Recently, code generation models using the
transformer architecture have achieved impressive results in academic settings
and have even been used in commercial developer tools to improve developer
productivity. To the best of our knowledge, this study is the first to apply
transformers to SKILL code autocompletion towards improving the productivity of
hardware design engineers. In this study, a novel, data-efficient methodology
for generating SKILL code is proposed and experimentally validated. More
specifically, we propose a novel methodology for (i) creating a high-quality
SKILL dataset with both unlabeled and labeled data, (ii) a training strategy
where T5 models pre-trained on general programming language code are fine-tuned
on our custom SKILL dataset using unsupervised and supervised learning, and
(iii) evaluating synthesized SKILL code. We show that models trained using the
proposed methodology outperform baselines in terms of human-judgment score and
BLEU score. A major challenge faced was the extremely small amount of available
SKILL code data that can be used to train a transformer model to generate SKILL
code. Despite our validated improvements, the extremely small dataset available
to us was still not enough to train a model that can reliably autocomplete
SKILL code. We discuss this and other limitations as well as future work that
could address these limitations.
",2023-12-04 14:29:28+00:00,cs.SE
"Extrapolatable Transformer Pre-training for Ultra Long Time-Series
  Forecasting","  Large-scale pre-trained models (PTMs) such as BERT and GPT have recently
achieved great success in Natural Language Processing and Computer Vision
domains. However, the development of PTMs on time-series data is lagging
behind. This underscores the limitations of the existing transformer-based
architectures, particularly their scalability to handle large-scale data and
ability to capture long-term temporal dependencies. In this study, we present
Timely Generative Pre-trained Transformer (TimelyGPT). TimelyGPT employs an
extrapolatable position (xPos) embedding to encode trend and periodic patterns
into time-series representations. It also integrates recurrent attention and
temporal convolution modules to effectively capture global-local temporal
dependencies. Our experiments show that TimelyGPT excels in modeling
continuously monitored biosignals and irregularly-sampled time series data
commonly observed in longitudinal electronic health records (EHRs). In
ultra-long-term forecasting experiment, TimelyGPT achieves accurate
extrapolation up to 6,000 timesteps of body temperature during the sleep stage
transition given a short look-up window (i.e., prompt) containing only 2,000
timesteps. We further demonstrated TimelyGPT's forecasting capabilities on a
preprocessed longitudinal healthcare administrative database called PopHR
consisting of 489,000 patients randomly sampled from Montreal population.
Together, we envision TimelyGPT to be useful in a broad spectrum of health
domains including long-term patient health state forecasting and patient risk
trajectory prediction.
",2023-11-29 19:09:28+00:00,cs.LG
"Keeping Users Engaged During Repeated Administration of the Same
  Questionnaire: Using Large Language Models to Reliably Diversify Questions","  Standardized, validated questionnaires are vital tools in research and
healthcare, offering dependable self-report data. Prior work has revealed that
virtual agent-administered questionnaires are almost equivalent to
self-administered ones in an electronic form. Despite being an engaging method,
repeated use of virtual agent-administered questionnaires in longitudinal or
pre-post studies can induce respondent fatigue, impacting data quality via
response biases and decreased response rates. We propose using large language
models (LLMs) to generate diverse questionnaire versions while retaining good
psychometric properties. In a longitudinal study, participants interacted with
our agent system and responded daily for two weeks to one of the following
questionnaires: a standardized depression questionnaire, question variants
generated by LLMs, or question variants accompanied by LLM-generated small
talk. The responses were compared to a validated depression questionnaire.
Psychometric testing revealed consistent covariation between the external
criterion and focal measure administered across the three conditions,
demonstrating the reliability and validity of the LLM-generated variants.
Participants found that the variants were significantly less repetitive than
repeated administrations of the same standardized questionnaire. Our findings
highlight the potential of LLM-generated variants to invigorate
agent-administered questionnaires and foster engagement and interest, without
compromising their validity.
",2023-11-21 16:20:49+00:00,cs.HC
"A Multi-Center Study on the Adaptability of a Shared Foundation Model
  for Electronic Health Records","  Foundation models hold promise for transforming AI in healthcare by providing
modular components that are easily adaptable to downstream healthcare tasks,
making AI development more scalable and cost-effective. Structured EHR
foundation models, trained on coded medical records from millions of patients,
demonstrated benefits including increased performance with fewer training
labels, and improved robustness to distribution shifts. However, questions
remain on the feasibility of sharing these models across different hospitals
and their performance for local task adaptation. This multi-center study
examined the adaptability of a recently released structured EHR foundation
model ($FM_{SM}$), trained on longitudinal medical record data from 2.57M
Stanford Medicine patients. Experiments were conducted using EHR data at The
Hospital for Sick Children and MIMIC-IV. We assessed both adaptability via
continued pretraining on local data, and task adaptability compared to
baselines of training models from scratch at each site, including a local
foundation model. We evaluated the performance of these models on 8 clinical
prediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$
matched the performance of GBM models locally trained on all data while
providing a 13% improvement in settings with few task-specific training labels.
With continued pretraining on local data, label efficiency substantially
improved, such that $FM_{SM}$ required fewer than 1% of training examples to
match the fully trained GBM's performance. Continued pretraining was also 60 to
90% more sample-efficient than training local foundation models from scratch.
Our findings show that adapting shared EHR foundation models across hospitals
provides improved prediction performance at less cost, underscoring the utility
of base foundation models as modular components to streamline the development
of healthcare AI.
",2023-11-20 01:58:27+00:00,cs.LG
Invariant subspaces and PCA in nearly matrix multiplication time,"  Approximating invariant subspaces of generalized eigenvalue problems (GEPs)
is a fundamental computational problem at the core of machine learning and
scientific computing. It is, for example, the root of Principal Component
Analysis (PCA) for dimensionality reduction, data visualization, and noise
filtering, and of Density Functional Theory (DFT), arguably the most popular
method to calculate the electronic structure of materials. For a Hermitian
definite GEP $HC=SC\Lambda$, let $\Pi_k$ be the true spectral projector on the
invariant subspace that is associated with the $k$ smallest (or largest)
eigenvalues. Given $H,$ $S$, an integer $k$, and accuracy
$\varepsilon\in(0,1)$, we show that we can compute a matrix $\widetilde\Pi_k$
such that $\lVert\Pi_k-\widetilde\Pi_k\rVert_2\leq \varepsilon$, in $O\left(
n^{\omega+\eta}\mathrm{polylog}(n,\varepsilon^{-1},\kappa(S),\mathrm{gap}_k^{-1})
\right)$ bit operations in the floating point model with probability $1-1/n$.
Here, $\eta>0$ is arbitrarily small, $\omega\lesssim 2.372$ is the matrix
multiplication exponent, $\kappa(S)=\lVert S\rVert_2\lVert S^{-1}\rVert_2$, and
$\mathrm{gap}_k$ is the gap between eigenvalues $k$ and $k+1$. To the best of
our knowledge, this is the first end-to-end analysis achieving such
""forward-error"" approximation guarantees with nearly $O(n^{\omega+\eta})$ bit
complexity, improving classical $\widetilde O(n^3)$ eigensolvers, even for the
regular case $(S=I)$. Our methods rely on a new $O(n^{\omega+\eta})$ stability
analysis for the Cholesky factorization, and a new smoothed analysis for
computing spectral gaps, which can be of independent interest. Ultimately, we
obtain new matrix multiplication-type bit complexity upper bounds for PCA
problems, including classical PCA and (randomized) low-rank approximation.
",2023-11-17 11:28:34+00:00,cs.DS
"A Deep Learning Method for Simultaneous Denoising and Missing Wedge
  Reconstruction in Cryogenic Electron Tomography","  Cryogenic electron tomography is a technique for imaging biological samples
in 3D. A microscope collects a series of 2D projections of the sample, and the
goal is to reconstruct the 3D density of the sample called the tomogram.
Reconstruction is difficult as the 2D projections are noisy and can not be
recorded from all directions, resulting in a missing wedge of information.
Tomograms conventionally reconstructed with filtered back-projection suffer
from noise and strong artifacts due to the missing wedge. Here, we propose a
deep-learning approach for simultaneous denoising and missing wedge
reconstruction called DeepDeWedge. The algorithm requires no ground truth data
and is based on fitting a neural network to the 2D projections using a
self-supervised loss. DeepDeWedge performs better than CryoCARE and IsoNet,
which are state-of-the-art methods for denoising and missing wedge
reconstruction, and similarly and, in some cases, better than the combination
of the two methods. At the same time, DeepDeWedge is simpler than this two-step
approach, as it does denoising and missing wedge reconstruction simultaneously
rather than sequentially.
",2023-11-09 17:34:57+00:00,cs.CV
"SugarViT -- Multi-objective Regression of UAV Images with Vision
  Transformers and Deep Label Distribution Learning Demonstrated on Disease
  Severity Prediction in Sugar Beet","  Remote sensing and artificial intelligence are pivotal technologies of
precision agriculture nowadays. The efficient retrieval of large-scale field
imagery combined with machine learning techniques shows success in various
tasks like phenotyping, weeding, cropping, and disease control. This work will
introduce a machine learning framework for automatized large-scale
plant-specific trait annotation for the use case disease severity scoring for
Cercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label
Distribution Learning (DLDL), special loss functions, and a tailored model
architecture, we develop an efficient Vision Transformer based model for
disease severity scoring called SugarViT. One novelty in this work is the
combination of remote sensing data with environmental parameters of the
experimental sites for disease severity prediction. Although the model is
evaluated on this special use case, it is held as generic as possible to also
be applicable to various image-based classification and regression tasks. With
our framework, it is even possible to learn models on multi-objective problems
as we show by a pretraining on environmental metadata.
",2023-11-06 13:01:17+00:00,cs.CV
"Estimating treatment effects from single-arm trials via latent-variable
  modeling","  Randomized controlled trials (RCTs) are the accepted standard for treatment
effect estimation but they can be infeasible due to ethical reasons and
prohibitive costs. Single-arm trials, where all patients belong to the
treatment group, can be a viable alternative but require access to an external
control group. We propose an identifiable deep latent-variable model for this
scenario that can also account for missing covariate observations by modeling
their structured missingness patterns. Our method uses amortized variational
inference to learn both group-specific and identifiable shared latent
representations, which can subsequently be used for {\em (i)} patient matching
if treatment outcomes are not available for the treatment group, or for {\em
(ii)} direct treatment effect estimation assuming outcomes are available for
both groups. We evaluate the model on a public benchmark as well as on a data
set consisting of a published RCT study and real-world electronic health
records. Compared to previous methods, our results show improved performance
both for direct treatment effect estimation as well as for effect estimation
via patient matching.
",2023-11-06 10:12:54+00:00,cs.LG
"APRICOT-Mamba: Acuity Prediction in Intensive Care Unit (ICU):
  Development and Validation of a Stability, Transitions, and Life-Sustaining
  Therapies Prediction Model","  The acuity state of patients in the intensive care unit (ICU) can quickly
change from stable to unstable. Early detection of deteriorating conditions can
result in providing timely interventions and improved survival rates. In this
study, we propose APRICOT-M (Acuity Prediction in Intensive Care Unit-Mamba), a
150k-parameter state space-based neural network to predict acuity state,
transitions, and the need for life-sustaining therapies in real-time in ICU
patients. The model uses data obtained in the prior four hours in the ICU and
patient information obtained at admission to predict the acuity outcomes in the
next four hours. We validated APRICOT-M externally on data from hospitals not
used in development (75,668 patients from 147 hospitals), temporally on data
from a period not used in development (12,927 patients from one hospital from
2018-2019), and prospectively on data collected in real-time (215 patients from
one hospital from 2021-2023) using three large datasets: the University of
Florida Health (UFH) dataset, the electronic ICU Collaborative Research
Database (eICU), and the Medical Information Mart for Intensive Care
(MIMIC)-IV. The area under the receiver operating characteristic curve (AUROC)
of APRICOT-M for mortality (external 0.94-0.95, temporal 0.97-0.98, prospective
0.96-1.00) and acuity (external 0.95-0.95, temporal 0.97-0.97, prospective
0.96-0.96) shows comparable results to state-of-the-art models. Furthermore,
APRICOT-M can predict transitions to instability (external 0.81-0.82, temporal
0.77-0.78, prospective 0.68-0.75) and need for life-sustaining therapies,
including mechanical ventilation (external 0.82-0.83, temporal 0.87-0.88,
prospective 0.67-0.76), and vasopressors (external 0.81-0.82, temporal
0.73-0.75, prospective 0.66-0.74). This tool allows for real-time acuity
monitoring in critically ill patients and can help clinicians make timely
interventions.
",2023-11-03 16:52:27+00:00,cs.AI
"Detecting Visual Cues in the Intensive Care Unit and Association with
  Patient Clinical Status","  Intensive Care Units (ICU) provide close supervision and continuous care to
patients with life-threatening conditions. However, continuous patient
assessment in the ICU is still limited due to time constraints and the workload
on healthcare providers. Existing patient assessments in the ICU such as pain
or mobility assessment are mostly sporadic and administered manually, thus
introducing the potential for human errors. Developing Artificial intelligence
(AI) tools that can augment human assessments in the ICU can be beneficial for
providing more objective and granular monitoring capabilities. For example,
capturing the variations in a patient's facial cues related to pain or
agitation can help in adjusting pain-related medications or detecting
agitation-inducing conditions such as delirium. Additionally, subtle changes in
visual cues during or prior to adverse clinical events could potentially aid in
continuous patient monitoring when combined with high-resolution physiological
signals and Electronic Health Record (EHR) data. In this paper, we examined the
association between visual cues and patient condition including acuity status,
acute brain dysfunction, and pain. We leveraged our AU-ICU dataset with 107,064
frames collected in the ICU annotated with facial action units (AUs) labels by
trained annotators. We developed a new ""masked loss computation"" technique that
addresses the data imbalance problem by maximizing data resource utilization.
We trained the model using our AU-ICU dataset in conjunction with three
external datasets to detect 18 AUs. The SWIN Transformer model achieved 0.57
mean F1-score and 0.89 mean accuracy on the test set. Additionally, we
performed AU inference on 634,054 frames to evaluate the association between
facial AUs and clinically important patient conditions such as acuity status,
acute brain dysfunction, and pain.
",2023-11-01 15:07:03+00:00,cs.CV
"General-Purpose Retrieval-Enhanced Medical Prediction Model Using
  Near-Infinite History","  Machine learning (ML) has recently shown promising results in medical
predictions using electronic health records (EHRs). However, since ML models
typically have a limited capability in terms of input sizes, selecting specific
medical events from EHRs for use as input is necessary. This selection process,
often relying on expert opinion, can cause bottlenecks in development. We
propose Retrieval-Enhanced Medical prediction model (REMed) to address such
challenges. REMed can essentially evaluate unlimited medical events, select the
relevant ones, and make predictions. This allows for an unrestricted input
size, eliminating the need for manual event selection. We verified these
properties through experiments involving 27 clinical prediction tasks across
four independent cohorts, where REMed outperformed the baselines. Notably, we
found that the preferences of REMed align closely with those of medical
experts. We expect our approach to significantly expedite the development of
EHR prediction models by minimizing clinicians' need for manual involvement.
",2023-10-31 06:04:18+00:00,cs.LG
"Unmasking Bias in AI: A Systematic Review of Bias Detection and
  Mitigation Strategies in Electronic Health Record-based Models","  Objectives: Leveraging artificial intelligence (AI) in conjunction with
electronic health records (EHRs) holds transformative potential to improve
healthcare. Yet, addressing bias in AI, which risks worsening healthcare
disparities, cannot be overlooked. This study reviews methods to detect and
mitigate diverse forms of bias in AI models developed using EHR data. Methods:
We conducted a systematic review following the Preferred Reporting Items for
Systematic Reviews and Meta-analyses (PRISMA) guidelines, analyzing articles
from PubMed, Web of Science, and IEEE published between January 1, 2010, and
Dec 17, 2023. The review identified key biases, outlined strategies for
detecting and mitigating bias throughout the AI model development process, and
analyzed metrics for bias assessment. Results: Of the 450 articles retrieved,
20 met our criteria, revealing six major bias types: algorithmic, confounding,
implicit, measurement, selection, and temporal. The AI models were primarily
developed for predictive tasks in healthcare settings. Four studies
concentrated on the detection of implicit and algorithmic biases employing
fairness metrics like statistical parity, equal opportunity, and predictive
equity. Sixty proposed various strategies for mitigating biases, especially
targeting implicit and selection biases. These strategies, evaluated through
both performance (e.g., accuracy, AUROC) and fairness metrics, predominantly
involved data collection and preprocessing techniques like resampling,
reweighting, and transformation. Discussion: This review highlights the varied
and evolving nature of strategies to address bias in EHR-based AI models,
emphasizing the urgent needs for the establishment of standardized,
generalizable, and interpretable methodologies to foster the creation of
ethical AI systems that promote fairness and equity in healthcare.
",2023-10-30 18:29:15+00:00,cs.AI
"Self Attention with Temporal Prior: Can We Learn More from Arrow of
  Time?","  Many diverse phenomena in nature often inherently encode both short- and
long-term temporal dependencies, which especially result from the direction of
the flow of time. In this respect, we discovered experimental evidence
suggesting that interrelations of these events are higher for closer time
stamps. However, to be able for attention-based models to learn these
regularities in short-term dependencies, it requires large amounts of data,
which are often infeasible. This is because, while they are good at learning
piece-wise temporal dependencies, attention-based models lack structures that
encode biases in time series. As a resolution, we propose a simple and
efficient method that enables attention layers to better encode the short-term
temporal bias of these data sets by applying learnable, adaptive kernels
directly to the attention matrices. We chose various prediction tasks for the
experiments using Electronic Health Records (EHR) data sets since they are
great examples with underlying long- and short-term temporal dependencies. Our
experiments show exceptional classification results compared to best-performing
models on most tasks and data sets.
",2023-10-29 08:00:13+00:00,cs.AI
DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU,"  Survival analysis focuses on estimating time-to-event distributions which can
help in dynamic risk prediction in healthcare. Extending beyond the classical
Cox model, deep learning techniques have been developed which moved away from
the constraining assumptions of proportional hazards. Traditional statistical
models often only include static information where, in this work, we propose a
novel conditional variational autoencoder-based method called DySurv, which
uses a combination of static and time-series measurements from patient
electronic health records to estimate the risk of death dynamically. DySurv has
been tested on several time-to-event benchmarks where it outperforms existing
methods, including deep learning methods, and we evaluate it on real-world
intensive care unit data from MIMIC-IV and eICU. The predictive capacity of
DySurv is consistent and the survival estimates remain disentangled across
different datasets supporting the idea that dynamic deep learning models based
on conditional variational inference in multi-task cases can be robust models
for survival analysis.
",2023-10-28 11:29:09+00:00,cs.LG
"Using Buckingham's $π$ Theorem for Multi-System Learning Transfer: a
  Case-study with 3 Vehicles Sharing a Database","  Many advanced driver assistance schemes or autonomous vehicle controllers are
based on a motion model of the vehicle behavior, i.e., a function predicting
how the vehicle will react to a given control input. Data-driven models, based
on experimental or simulated data, are very useful, especially for vehicles
difficult to model analytically, for instance, ground vehicles for which the
ground-tire interaction is hard to model from first principles. However,
learning schemes are limited by the difficulty of collecting large amounts of
experimental data or having to rely on high-fidelity simulations. This paper
explores the potential of an approach that uses dimensionless numbers based on
Buckingham's $\pi$ theorem to improve the efficiency of data for learning
models, with the goal of facilitating knowledge sharing between similar
systems. A case study using car-like vehicles compares traditional and
dimensionless models on simulated and experimental data to validate the
benefits of the new dimensionless learning approach. Prediction accuracy
improvements with the dimensionless scheme when using a shared database, that
is, predicting the motion of a vehicle based on data from various different
vehicles was found to be 480\% more accurate for predicting a simple no-slip
maneuver based on simulated data and 11\% more accurate to predict a highly
dynamic braking maneuver based on experimental data. A modified
physics-informed learning scheme with hand-crafted dimensionless features was
also shown to increase the improvement to precision gains of 917\% and 28\%
respectively. A comparative study also shows that using Buckingham's $\pi$
theorem is a much more effective preprocessing step for this task than
principal component analysis (PCA) or simply normalizing the data.
",2023-10-26 16:42:13+00:00,cs.RO
KirchhoffNet: A Scalable Ultra Fast Analog Neural Network,"  In this paper, we leverage a foundational principle of analog electronic
circuitry, Kirchhoff's current and voltage laws, to introduce a distinctive
class of neural network models termed KirchhoffNet. Essentially, KirchhoffNet
is an analog circuit that can function as a neural network, utilizing its
initial node voltages as the neural network input and the node voltages at a
specific time point as the output. The evolution of node voltages within the
specified time is dictated by learnable parameters on the edges connecting
nodes. We demonstrate that KirchhoffNet is governed by a set of ordinary
differential equations (ODEs), and notably, even in the absence of traditional
layers (such as convolution layers), it attains state-of-the-art performances
across diverse and complex machine learning tasks. Most importantly,
KirchhoffNet can be potentially implemented as a low-power analog integrated
circuit, leading to an appealing property -- irrespective of the number of
parameters within a KirchhoffNet, its on-chip forward calculation can always be
completed within a short time. This characteristic makes KirchhoffNet a
promising and fundamental paradigm for implementing large-scale neural
networks, opening a new avenue in analog neural networks for AI.
",2023-10-24 14:28:00+00:00,cs.LG
"Knowledge-Induced Medicine Prescribing Network for Medication
  Recommendation","  Extensive adoption of electronic health records (EHRs) offers opportunities
for their use in various downstream clinical analyses. To accomplish this
purpose, enriching an EHR cohort with external knowledge (e.g., standardized
medical ontology and wealthy semantics) could help us reveal more comprehensive
insights via a spectrum of informative relations among medical codes.
Nevertheless, harnessing those beneficial interconnections was scarcely
exercised, especially in the medication recommendation task. This study
proposes a novel Knowledge-Induced Medicine Prescribing Network (KindMed) to
recommend medicines by inducing knowledge from myriad medical-related external
sources upon the EHR cohort and rendering interconnected medical codes as
medical knowledge graphs (KGs). On top of relation-aware graph representation
learning to obtain an adequate embedding over such KGs, we leverage
hierarchical sequence learning to discover and fuse temporal dynamics of
clinical (i.e., diagnosis and procedures) and medicine streams across patients'
historical admissions to foster personalized recommendations. Eventually, we
employ attentive prescribing that accounts for three essential patient
representations, i.e., a summary of joint historical medical records, clinical
progression, and the current clinical state of patients. We validated the
effectiveness of our KindMed on the augmented real-world EHR cohorts, achieving
improved recommendation performances against a handful of graph-driven
baselines.
",2023-10-23 04:15:39+00:00,cs.LG
"Survey on Near-Space Information Networks: Channel Modeling, Networking,
  and Transmission Perspectives","  Near-space information networks (NSINs) composed of high-altitude platforms
(HAPs) and high- and low-altitude unmanned aerial vehicles (UAVs) are a new
regime for providing quick, robust, and cost-efficient sensing and
communication services. Precipitated by innovations and breakthroughs in
manufacturing, materials, communications, electronics, and control techniques,
NSINs have been envisioned as an essential component of the emerging
sixth-generation of mobile communication systems. This article reveals some
critical issues needing to be tackled in NSINs through conducting experiments
and discusses the latest advances in NSINs in the research areas of channel
modeling, networking, and transmission from a forward-looking, comparative, and
technical evolutionary perspective. In this article, we highlight the
characteristics of NSINs and present the promising use cases of NSINs. The
impact of airborne platforms' unstable movements on the phase delays of onboard
antenna arrays with diverse structures is mathematically analyzed. The recent
advances in HAP channel modeling are elaborated on, along with the significant
differences between HAP and UAV channel modeling. A comprehensive review of the
networking techniques of NSINs in network deployment, handoff management, and
network management aspects is provided. Besides, the promising techniques and
communication protocols of the physical (PHY) layer, medium access control
(MAC) layer, network layer, and transport layer of NSINs for achieving
efficient transmission over NSINs are reviewed, and we have conducted
experiments with practical NSINs to verify the performance of some techniques.
Finally, we outline some open issues and promising directions for NSINs
deserved for future study and discuss the corresponding challenges.
",2023-10-13 11:37:09+00:00,cs.NI
"Domain-invariant Clinical Representation Learning by Bridging Data
  Distribution Shift across EMR Datasets","  Due to the limited information about emerging diseases, symptoms are hard to
be noticed and recognized, so that the window for clinical intervention could
be ignored. An effective prognostic model is expected to assist doctors in
making right diagnosis and designing personalized treatment plan, so to
promptly prevent unfavorable outcomes. However, in the early stage of a
disease, limited data collection and clinical experiences, plus the concern out
of privacy and ethics, may result in restricted data availability for
reference, to the extent that even data labels are difficult to mark correctly.
In addition, Electronic Medical Record (EMR) data of different diseases or of
different sources of the same disease can prove to be having serious
cross-dataset feature misalignment problems, greatly mutilating the efficiency
of deep learning models. This article introduces a domain-invariant
representation learning method to build a transition model from source dataset
to target dataset. By way of constraining the distribution shift of features
generated in disparate domains, domain-invariant features that are exclusively
relative to downstream tasks are captured, so to cultivate a unified
domain-invariant encoder across various task domains to achieve better feature
representation. Experimental results of several target tasks demonstrate that
our proposed model outperforms competing baseline methods and has higher rate
of training convergence, especially in dealing with limited data amount. A
multitude of experiences have proven the efficacy of our method to provide more
accurate predictions concerning newly emergent pandemics and other diseases.
",2023-10-11 18:32:21+00:00,cs.LG
"DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis
  Prediction","  Multi-label text classification (MLTC) tasks in the medical domain often face
the long-tail label distribution problem. Prior works have explored
hierarchical label structures to find relevant information for few-shot
classes, but mostly neglected to incorporate external knowledge from medical
guidelines. This paper presents DKEC, Domain Knowledge Enhanced Classification
for diagnosis prediction with two innovations: (1) automated construction of
heterogeneous knowledge graphs from external sources to capture semantic
relations among diverse medical entities, (2) incorporating the heterogeneous
knowledge graphs in few-shot classification using a label-wise attention
mechanism. We construct DKEC using three online medical knowledge sources and
evaluate it on a real-world Emergency Medical Services (EMS) dataset and a
public electronic health record (EHR) dataset. Results show that DKEC
outperforms the state-of-the-art label-wise attention networks and transformer
models of different sizes, particularly for the few-shot classes. More
importantly, it helps the smaller language models achieve comparable
performance to large language models.
",2023-10-10 22:53:15+00:00,cs.CL
SWoTTeD: An Extension of Tensor Decomposition to Temporal Phenotyping,"  Tensor decomposition has recently been gaining attention in the machine
learning community for the analysis of individual traces, such as Electronic
Health Records (EHR). However, this task becomes significantly more difficult
when the data follows complex temporal patterns. This paper introduces the
notion of a temporal phenotype as an arrangement of features over time and it
proposes SWoTTeD (Sliding Window for Temporal Tensor Decomposition), a novel
method to discover hidden temporal patterns. SWoTTeD integrates several
constraints and regularizations to enhance the interpretability of the
extracted phenotypes. We validate our proposal using both synthetic and
real-world datasets, and we present an original usecase using data from the
Greater Paris University Hospital. The results show that SWoTTeD achieves at
least as accurate reconstruction as recent state-of-the-art tensor
decomposition models, and extracts temporal phenotypes that are meaningful for
clinicians.
",2023-10-02 13:42:11+00:00,cs.LG
"Bridging the complexity gap in Tbps-achieving THz-band baseband
  processing","  Recent advances in electronic and photonic technologies have allowed
efficient signal generation and transmission at terahertz (THz) frequencies.
However, as the gap in THz-operating devices narrows, the demand for
terabit-per-second (Tbps)-achieving circuits is increasing. Translating the
available hundreds of gigahertz (GHz) of bandwidth into a Tbps data rate
requires processing thousands of information bits per clock cycle at
state-of-the-art clock frequencies of digital baseband processing circuitry of
a few GHz. This paper addresses these constraints and emphasizes the importance
of parallelization in signal processing, particularly for channel code
decoding. By leveraging structured sub-spaces of THz channels, we propose
mapping bits to transmission resources using shorter code-words, extending
parallelizability across all baseband processing blocks. THz channels exhibit
quasi-deterministic frequency, time, and space structures that enable efficient
parallel bit mapping at the source and provide pseudo-soft bit reliability
information for efficient detection and decoding at the receiver.
",2023-09-27 21:06:14+00:00,cs.IT
"Implementation of digital MemComputing using standard electronic
  components","  Digital MemComputing machines (DMMs), which employ nonlinear dynamical
systems with memory (time non-locality), have proven to be a robust and
scalable unconventional computing approach for solving a wide variety of
combinatorial optimization problems. However, most of the research so far has
focused on the numerical simulations of the equations of motion of DMMs. This
inevitably subjects time to discretization, which brings its own (numerical)
issues that would be otherwise absent in actual physical systems operating in
continuous time. Although hardware realizations of DMMs have been previously
suggested, their implementation would require materials and devices that are
not so easy to integrate with traditional electronics. Addressing this, our
study introduces a novel hardware design for DMMs, utilizing readily available
electronic components. This approach not only significantly boosts
computational speed compared to current models but also exhibits remarkable
robustness against additive noise. Crucially, it circumvents the limitations
imposed by numerical noise, ensuring enhanced stability and reliability during
extended operations. This paves a new path for tackling increasingly complex
problems, leveraging the inherent advantages of DMMs in a more practical and
accessible framework.
",2023-09-21 19:11:34+00:00,cs.ET
Human Movement Forecasting with Loose Clothing,"  Human motion prediction and trajectory forecasting are essential in human
motion analysis. Nowadays, sensors can be seamlessly integrated into clothing
using cutting-edge electronic textile (e-textile) technology, allowing
long-term recording of human movements outside the laboratory. Motivated by the
recent findings that clothing-attached sensors can achieve higher activity
recognition accuracy than body-attached sensors. This work investigates the
performance of human motion prediction using clothing-attached sensors compared
with body-attached sensors. It reports experiments in which statistical models
learnt from the movement of loose clothing are used to predict motion patterns
of the body of robotically simulated and real human behaviours.
Counterintuitively, the results show that fabric-attached sensors can have
better motion prediction performance than rigid-attached sensors. Specifically,
The fabric-attached sensor can improve the accuracy up to 40% and requires up
to 80% less duration of the past trajectory to achieve high prediction accuracy
(i.e., 95%) compared to the rigid-attached sensor.
",2023-09-17 10:56:06+00:00,cs.RO
"Adapted Large Language Models Can Outperform Medical Experts in Clinical
  Text Summarization","  Analyzing vast textual data and summarizing key information from electronic
health records imposes a substantial burden on how clinicians allocate their
time. Although large language models (LLMs) have shown promise in natural
language processing (NLP), their effectiveness on a diverse range of clinical
summarization tasks remains unproven. In this study, we apply adaptation
methods to eight LLMs, spanning four distinct clinical summarization tasks:
radiology reports, patient questions, progress notes, and doctor-patient
dialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP
metrics reveal trade-offs between models and adaptation methods. A clinical
reader study with ten physicians evaluates summary completeness, correctness,
and conciseness; in a majority of cases, summaries from our best adapted LLMs
are either equivalent (45%) or superior (36%) compared to summaries from
medical experts. The ensuing safety analysis highlights challenges faced by
both LLMs and medical experts, as we connect errors to potential medical harm
and categorize types of fabricated information. Our research provides evidence
of LLMs outperforming medical experts in clinical text summarization across
multiple tasks. This suggests that integrating LLMs into clinical workflows
could alleviate documentation burden, allowing clinicians to focus more on
patient care.
",2023-09-14 05:15:01+00:00,cs.CL
"Intelligent upper-limb exoskeleton integrated with soft wearable
  bioelectronics and deep-learning for human intention-driven strength
  augmentation based on sensory feedback","  The age and stroke-associated decline in musculoskeletal strength degrades
the ability to perform daily human tasks using the upper extremities. Although
there are a few examples of exoskeletons, they need manual operations due to
the absence of sensor feedback and no intention prediction of movements. Here,
we introduce an intelligent upper-limb exoskeleton system that uses cloud-based
deep learning to predict human intention for strength augmentation. The
embedded soft wearable sensors provide sensory feedback by collecting real-time
muscle signals, which are simultaneously computed to determine the user's
intended movement. The cloud-based deep-learning predicts four upper-limb joint
motions with an average accuracy of 96.2% at a 200-250 millisecond response
rate, suggesting that the exoskeleton operates just by human intention. In
addition, an array of soft pneumatics assists the intended movements by
providing 897 newton of force and 78.7 millimeter of displacement at maximum.
Collectively, the intent-driven exoskeleton can augment human strength by 5.15
times on average compared to the unassisted exoskeleton. This report
demonstrates an exoskeleton robot that augments the upper-limb joint movements
by human intention based on a machine-learning cloud computing and sensory
feedback.
",2023-09-09 01:30:07+00:00,cs.RO
Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges,"  Unstructured data in Electronic Health Records (EHRs) often contains critical
information -- complementary to imaging -- that could inform radiologists'
diagnoses. But the large volume of notes often associated with patients
together with time constraints renders manually identifying relevant evidence
practically infeasible. In this work we propose and evaluate a zero-shot
strategy for using LLMs as a mechanism to efficiently retrieve and summarize
unstructured evidence in patient EHR relevant to a given query. Our method
entails tasking an LLM to infer whether a patient has, or is at risk of, a
particular condition on the basis of associated notes; if so, we ask the model
to summarize the supporting evidence. Under expert evaluation, we find that
this LLM-based approach provides outputs consistently preferred to a pre-LLM
information retrieval baseline. Manual evaluation is expensive, so we also
propose and validate a method using an LLM to evaluate (other) LLM outputs for
this task, allowing us to scale up evaluation. Our findings indicate the
promise of LLMs as interfaces to EHR, but also highlight the outstanding
challenge posed by ""hallucinations"". In this setting, however, we show that
model confidence in outputs strongly correlates with faithful summaries,
offering a practical means to limit confabulations.
",2023-09-08 18:44:47+00:00,cs.CL
"PRISM: Leveraging Prototype Patient Representations with
  Feature-Missing-Aware Calibration for EHR Data Sparsity Mitigation","  Electronic Health Records (EHRs) contain a wealth of patient data; however,
the sparsity of EHRs data often presents significant challenges for predictive
modeling. Conventional imputation methods inadequately distinguish between real
and imputed data, leading to potential inaccuracies of patient representations.
To address these issues, we introduce PRISM, a framework that indirectly
imputes data by leveraging prototype representations of similar patients, thus
ensuring compact representations that preserve patient information. PRISM also
includes a feature confidence learner module, which evaluates the reliability
of each feature considering missing statuses. Additionally, PRISM introduces a
new patient similarity metric that accounts for feature confidence, avoiding
overreliance on imprecise imputed values. Our extensive experiments on the
MIMIC-III, MIMIC-IV, PhysioNet Challenge 2012, eICU datasets demonstrate
PRISM's superior performance in predicting in-hospital mortality and 30-day
readmission tasks, showcasing its effectiveness in handling EHR data sparsity.
For the sake of reproducibility and further research, we have made the code
publicly available at https://github.com/yhzhu99/PRISM.
",2023-09-08 07:01:38+00:00,cs.LG
CktGNN: Circuit Graph Neural Network for Electronic Design Automation,"  The electronic design automation of analog circuits has been a longstanding
challenge in the integrated circuit field due to the huge design space and
complex design trade-offs among circuit specifications. In the past decades,
intensive research efforts have mostly been paid to automate the transistor
sizing with a given circuit topology. By recognizing the graph nature of
circuits, this paper presents a Circuit Graph Neural Network (CktGNN) that
simultaneously automates the circuit topology generation and device sizing
based on the encoder-dependent optimization subroutines. Particularly, CktGNN
encodes circuit graphs using a two-level GNN framework (of nested GNN) where
circuits are represented as combinations of subgraphs in a known subgraph
basis. In this way, it significantly improves design efficiency by reducing the
number of subgraphs to perform message passing. Nonetheless, another critical
roadblock to advancing learning-assisted circuit design automation is a lack of
public benchmarks to perform canonical assessment and reproducible research. To
tackle the challenge, we introduce Open Circuit Benchmark (OCB), an
open-sourced dataset that contains $10$K distinct operational amplifiers with
carefully-extracted circuit specifications. OCB is also equipped with
communicative circuit generation and evaluation capabilities such that it can
help to generalize CktGNN to design various analog circuits by producing
corresponding datasets. Experiments on OCB show the extraordinary advantages of
CktGNN through representation-based optimization frameworks over other recent
powerful GNN baselines and human experts' manual designs. Our work paves the
way toward a learning-based open-sourced design automation for analog circuits.
Our source code is available at \url{https://github.com/zehao-dong/CktGNN}.
",2023-08-31 02:20:25+00:00,cs.LG
"Missing Data Imputation Based on Dynamically Adaptable Structural
  Equation Modeling with Self-Attention","  Addressing missing data in complex datasets including electronic health
records (EHR) is critical for ensuring accurate analysis and decision-making in
healthcare. This paper proposes dynamically adaptable structural equation
modeling (SEM) using a self-attention method (SESA), an approach to data
imputation in EHR. SESA innovates beyond traditional SEM-based methods by
incorporating self-attention mechanisms, thereby enhancing model adaptability
and accuracy across diverse EHR datasets. Such enhancement allows SESA to
dynamically adjust and optimize imputation and overcome the limitations of
static SEM frameworks. Our experimental analyses demonstrate the achievement of
robust predictive SESA performance for effectively handling missing data in
EHR. Moreover, the SESA architecture not only rectifies potential
mis-specifications in SEM but also synergizes with causal discovery algorithms
to refine its imputation logic based on underlying data structures. Such
features highlight its capabilities and broadening applicational potential in
EHR data analysis and beyond, marking a reasonable leap forward in the field of
data imputation.
",2023-08-23 19:01:17+00:00,cs.LG
Beyond MD17: the reactive xxMD dataset,"  System specific neural force fields (NFFs) have gained popularity in
computational chemistry. One of the most popular datasets as a bencharmk to
develop NFFs models is the MD17 dataset and its subsequent extension. These
datasets comprise geometries from the equilibrium region of the ground
electronic state potential energy surface, sampled from direct adiabatic
dynamics. However, many chemical reactions involve significant molecular
geometrical deformations, for example, bond breaking. Therefore, MD17 is
inadequate to represent a chemical reaction. To address this limitation in
MD17, we introduce a new dataset, called Extended Excited-state Molecular
Dynamics (xxMD) dataset. The xxMD dataset involves geometries sampled from
direct non-adiabatic dynamics, and the energies are computed at both
multireference wavefunction theory and density functional theory. We show that
the xxMD dataset involves diverse geometries which represent chemical
reactions. Assessment of NFF models on xxMD dataset reveals significantly
higher predictive errors than those reported for MD17 and its variants. This
work underscores the challenges faced in crafting a generalizable NFF model
with extrapolation capability.
",2023-08-22 03:23:36+00:00,cs.LG
"Ear-Keeper: Real-time Diagnosis of Ear Lesions Utilizing
  Ultralight-Ultrafast ConvNet and Large-scale Ear Endoscopic Dataset","  Deep learning-based ear disease diagnosis technology has proven effective and
affordable. However, due to the lack of ear endoscope datasets with diversity,
the practical potential of the deep learning model has not been thoroughly
studied. Moreover, existing research failed to achieve a good trade-off between
model inference speed and parameter size, rendering models inapplicable in
real-world settings. To address these challenges, we constructed the first
large-scale ear endoscopic dataset comprising eight types of ear diseases and
disease-free samples from two institutions. Inspired by ShuffleNetV2, we
proposed Best-EarNet, an ultrafast and ultralight network enabling real-time
ear disease diagnosis. Best-EarNet incorporates a novel Local-Global Spatial
Feature Fusion Module and multi-scale supervision strategy, which facilitates
the model focusing on global-local information within feature maps at various
levels. Utilizing transfer learning, the accuracy of Best-EarNet with only
0.77M parameters achieves 95.23% (internal 22,581 images) and 92.14% (external
1,652 images), respectively. In particular, it achieves an average frame per
second of 80 on the CPU. From the perspective of model practicality, the
proposed Best-EarNet is superior to state-of-the-art backbone models in ear
lesion detection tasks. Most importantly, Ear-keeper, an intelligent diagnosis
system based Best-EarNet, was developed successfully and deployed on common
electronic devices (smartphone, tablet computer and personal computer). In the
future, Ear-Keeper has the potential to assist the public and healthcare
providers in performing comprehensive scanning and diagnosis of the ear canal
in real-time video, thereby promptly detecting ear lesions.
",2023-08-21 10:20:46+00:00,cs.CV
ChatEDA: A Large Language Model Powered Autonomous Agent for EDA,"  The integration of a complex set of Electronic Design Automation (EDA) tools
to enhance interoperability is a critical concern for circuit designers. Recent
advancements in large language models (LLMs) have showcased their exceptional
capabilities in natural language processing and comprehension, offering a novel
approach to interfacing with EDA tools. This research paper introduces ChatEDA,
an autonomous agent for EDA empowered by a large language model, AutoMage,
complemented by EDA tools serving as executors. ChatEDA streamlines the design
flow from the Register-Transfer Level (RTL) to the Graphic Data System Version
II (GDSII) by effectively managing task planning, script generation, and task
execution. Through comprehensive experimental evaluations, ChatEDA has
demonstrated its proficiency in handling diverse requirements, and our
fine-tuned AutoMage model has exhibited superior performance compared to GPT-4
and other similar LLMs.
",2023-08-20 08:32:13+00:00,cs.AR
"Large Language Models to Identify Social Determinants of Health in
  Electronic Health Records","  Social determinants of health (SDoH) have an important impact on patient
outcomes but are incompletely collected from the electronic health records
(EHR). This study researched the ability of large language models to extract
SDoH from free text in EHRs, where they are most commonly documented, and
explored the role of synthetic clinical text for improving the extraction of
these scarcely documented, yet extremely valuable, clinical data. 800 patient
notes were annotated for SDoH categories, and several transformer-based models
were evaluated. The study also experimented with synthetic data generation and
assessed for algorithmic bias. Our best-performing models were fine-tuned
Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The
benefit of augmenting fine-tuning with synthetic data varied across model
architecture and size, with smaller Flan-T5 models (base and large) showing the
greatest improvements in performance (delta F1 +0.12 to +0.23). Model
performance was similar on the in-hospital system dataset but worse on the
MIMIC-III dataset. Our best-performing fine-tuned models outperformed zero- and
few-shot performance of ChatGPT-family models for both tasks. These fine-tuned
models were less likely than ChatGPT to change their prediction when
race/ethnicity and gender descriptors were added to the text, suggesting less
algorithmic bias (p<0.05). At the patient-level, our models identified 93.8% of
patients with adverse SDoH, while ICD-10 codes captured 2.0%. Our method can
effectively extracted SDoH information from clinic notes, performing better
compare to GPT zero- and few-shot settings. These models could enhance
real-world evidence on SDoH and aid in identifying patients needing social
support.
",2023-08-11 19:18:35+00:00,cs.CL
"The Still Secret Ballot: The Limited Privacy Cost of Transparent
  Election Results","  After an election, should officials release an electronic record of each
ballot? The release of ballots could bolster the legitimacy of the result. But
it may also facilitate vote revelation, where an analyst unravels the secret
ballot by uniquely linking votes on an anonymous ballot to the voter's name and
address in the public voter file. We first provide a theoretical model of how
vote revelation could occur under various election-reporting regimes. Perhaps
counterintuitively, releasing ballot records is no more revelatory than the
typical practice of releasing aggregate vote tallies by precinct and method. We
then present the first empirical evaluation of vote revelation, using the 2020
election in Maricopa County, Arizona, as a case study. For 99.8% of voters, the
release of ballot records led to no revelation of any vote choice. We conclude
the ballot can be both public and still as secret as it is under typical
reporting practices.
",2023-08-08 07:27:41+00:00,cs.CR
"Revolutionizing TCAD Simulations with Universal Device Encoding and
  Graph Attention Networks","  An innovative methodology that leverages artificial intelligence (AI) and
graph representation for semiconductor device encoding in TCAD device
simulation is proposed. A graph-based universal encoding scheme is presented
that not only considers material-level and device-level embeddings, but also
introduces a novel spatial relationship embedding inspired by interpolation
operations typically used in finite element meshing. Universal physical laws
from device simulations are leveraged for comprehensive data-driven modeling,
which encompasses surrogate Poisson emulation and current-voltage (IV)
prediction based on drift-diffusion model. Both are achieved using a novel
graph attention network, referred to as RelGAT. Comprehensive technical details
based on the device simulator Sentaurus TCAD are presented, empowering
researchers to adopt the proposed AI-driven Electronic Design Automation (EDA)
solution at the device level.
",2023-08-01 05:58:31+00:00,cs.LG
"A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue
  Information Extraction","  This paper focuses on term-status pair extraction from medical dialogues
(MD-TSPE), which is essential in diagnosis dialogue systems and the automatic
scribe of electronic medical records (EMRs). In the past few years, works on
MD-TSPE have attracted increasing research attention, especially after the
remarkable progress made by generative methods. However, these generative
methods output a whole sequence consisting of term-status pairs in one stage
and ignore integrating prior knowledge, which demands a deeper understanding to
model the relationship between terms and infer the status of each term. This
paper presents a knowledge-enhanced two-stage generative framework (KTGF) to
address the above challenges. Using task-specific prompts, we employ a single
model to complete the MD-TSPE through two phases in a unified generative form:
we generate all terms the first and then generate the status of each generated
term. In this way, the relationship between terms can be learned more
effectively from the sequence containing only terms in the first phase, and our
designed knowledge-enhanced prompt in the second phase can leverage the
category and status candidates of the generated term for status generation.
Furthermore, our proposed special status ""not mentioned"" makes more terms
available and enriches the training data in the second phase, which is critical
in the low-resource setting. The experiments on the Chunyu and CMDD datasets
show that the proposed method achieves superior results compared to the
state-of-the-art models in the full training and low-resource settings.
",2023-07-30 10:51:32+00:00,cs.CL
"PSO-Based Optimal Coverage Path Planning for Surface Defect Inspection
  of 3C Components with a Robotic Line Scanner","  The automatic inspection of surface defects is an important task for quality
control in the computers, communications, and consumer electronics (3C)
industry. Conventional devices for defect inspection (viz. line-scan sensors)
have a limited field of view, thus, a robot-aided defect inspection system
needs to scan the object from multiple viewpoints. Optimally selecting the
robot's viewpoints and planning a path is regarded as coverage path planning
(CPP), a problem that enables inspecting the object's complete surface while
reducing the scanning time and avoiding misdetection of defects. However, the
development of CPP strategies for robotic line scanners has not been
sufficiently studied by researchers. To fill this gap in the literature, in
this paper, we present a new approach for robotic line scanners to detect
surface defects of 3C free-form objects automatically. Our proposed solution
consists of generating a local path by a new hybrid region segmentation method
and an adaptive planning algorithm to ensure the coverage of the complete
object surface. An optimization method for the global path sequence is
developed to maximize the scanning efficiency. To verify our proposed
methodology, we conduct detailed simulation-based and experimental studies on
various free-form workpieces, and compare its performance with a
state-of-the-art solution. The reported results demonstrate the feasibility and
effectiveness of our approach.
",2023-07-10 09:11:52+00:00,cs.RO
"To Spike or Not To Spike: A Digital Hardware Perspective on Deep
  Learning Acceleration","  As deep learning models scale, they become increasingly competitive from
domains spanning from computer vision to natural language processing; however,
this happens at the expense of efficiency since they require increasingly more
memory and computing power. The power efficiency of the biological brain
outperforms any large-scale deep learning ( DL ) model; thus, neuromorphic
computing tries to mimic the brain operations, such as spike-based information
processing, to improve the efficiency of DL models. Despite the benefits of the
brain, such as efficient information transmission, dense neuronal
interconnects, and the co-location of computation and memory, the available
biological substrate has severely constrained the evolution of biological
brains. Electronic hardware does not have the same constraints; therefore,
while modeling spiking neural networks ( SNNs) might uncover one piece of the
puzzle, the design of efficient hardware backends for SNN s needs further
investigation, potentially taking inspiration from the available work done on
the artificial neural networks ( ANNs) side. As such, when is it wise to look
at the brain while designing new hardware, and when should it be ignored? To
answer this question, we quantitatively compare the digital hardware
acceleration techniques and platforms of ANNs and SNN s. As a result, we
provide the following insights: (i) ANNs currently process static data more
efficiently, (ii) applications targeting data produced by neuromorphic sensors,
such as event-based cameras and silicon cochleas, need more investigation since
the behavior of these sensors might naturally fit the SNN paradigm, and (iii)
hybrid approaches combining SNN s and ANNs might lead to the best solutions and
should be investigated further at the hardware level, accounting for both
efficiency and loss optimization.
",2023-06-27 19:04:00+00:00,cs.NE
"MeciFace: Mechanomyography and Inertial Fusion-based Glasses for Edge
  Real-Time Recognition of Facial and Eating Activities","  The increasing prevalence of stress-related eating behaviors and their impact
on overall health highlights the importance of effective and ubiquitous
monitoring systems. In this paper, we present MeciFace, an innovative wearable
technology designed to monitor facial expressions and eating activities in
real-time on-the-edge (RTE). MeciFace aims to provide a low-power,
privacy-conscious, and highly accurate tool for promoting healthy eating
behaviors and stress management. We employ lightweight convolutional neural
networks as backbone models for facial expression and eating monitoring
scenarios. The MeciFace system ensures efficient data processing with a tiny
memory footprint, ranging from 11KB to 19 KB. During RTE evaluation, the system
achieves an F1-score of < 86% for facial expression recognition and 94% for
eating/drinking monitoring, for the RTE of unseen users (user-independent
case).
",2023-06-19 09:47:33+00:00,cs.CV
TensorKrowch: Smooth integration of tensor networks in machine learning,"  Tensor networks are factorizations of high-dimensional tensors into networks
of smaller tensors. They have applications in physics and mathematics, and
recently have been proposed as promising machine learning architectures. To
ease the integration of tensor networks in machine learning pipelines, we
introduce TensorKrowch, an open source Python library built on top of PyTorch.
Providing a user-friendly interface, TensorKrowch allows users to construct any
tensor network, train it, and integrate it as a layer in more intricate deep
learning models. In this paper, we describe the main functionality and basic
usage of TensorKrowch, and provide technical details on its building blocks and
the optimizations performed to achieve efficient operation.
",2023-06-14 15:55:19+00:00,cs.LG
"Leveraging text data for causal inference using electronic health
  records","  In studies that rely on data from electronic health records (EHRs),
unstructured text data such as clinical progress notes offer a rich source of
information about patient characteristics and care that may be missing from
structured data. Despite the prevalence of text in clinical research, these
data are often ignored for the purposes of quantitative analysis due their
complexity. This paper presents a unified framework for leveraging text data to
support causal inference with electronic health data at multiple stages of
analysis. In particular, we consider how natural language processing and
statistical text analysis can be combined with standard inferential techniques
to address common challenges due to missing data, confounding bias, and
treatment effect heterogeneity. Through an application to a recent EHR study
investigating the effects of a non-randomized medical intervention on patient
outcomes, we show how incorporating text data in a traditional matching
analysis can help strengthen the validity of an estimated treatment effect and
identify patient subgroups that may benefit most from treatment. We believe
these methods have the potential to expand the scope of secondary analysis of
clinical data to domains where structured EHR data is limited, such as in
developing countries. To this end, we provide code and open-source replication
materials to encourage adoption and broader exploration of these techniques in
clinical research.
",2023-06-09 16:06:02+00:00,cs.CL
"Yet Another ICU Benchmark: A Flexible Multi-Center Framework for
  Clinical ML","  Medical applications of machine learning (ML) have experienced a surge in
popularity in recent years. The intensive care unit (ICU) is a natural habitat
for ML given the abundance of available data from electronic health records.
Models have been proposed to address numerous ICU prediction tasks like the
early detection of complications. While authors frequently report
state-of-the-art performance, it is challenging to verify claims of
superiority. Datasets and code are not always published, and cohort
definitions, preprocessing pipelines, and training setups are difficult to
reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular
framework that allows researchers to define reproducible and comparable
clinical ML experiments; we offer an end-to-end solution from cohort definition
to model evaluation. The framework natively supports most open-access ICU
datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future
ICU datasets. Combined with a transparent preprocessing pipeline and extensible
training code for multiple ML and deep learning models, YAIB enables unified
model development. Our benchmark comes with five predefined established
prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and
length of stay) developed in collaboration with clinicians. Adding further
tasks is straightforward by design. Using YAIB, we demonstrate that the choice
of dataset, cohort definition, and preprocessing have a major impact on the
prediction performance - often more so than model class - indicating an urgent
need for YAIB as a holistic benchmarking tool. We provide our work to the
clinical ML community to accelerate method development and enable real-world
clinical implementations. Software Repository:
https://github.com/rvandewater/YAIB.
",2023-06-08 11:16:20+00:00,cs.LG
"DKINet: Medication Recommendation via Domain Knowledge Informed Deep
  Learning","  Medication recommendation is a fundamental yet crucial branch of healthcare
that presents opportunities to assist physicians in making more accurate
medication prescriptions for patients with complex health conditions. Previous
studies have primarily focused on learning patient representation from
electronic health records (EHR). While considering the clinical manifestations
of the patient is important, incorporating domain-specific prior knowledge is
equally significant in diagnosing the patient's health conditions. However,
effectively integrating domain knowledge with the patient's clinical
manifestations can be challenging, particularly when dealing with complex
clinical manifestations. Therefore, in this paper, we first identify
comprehensive domain-specific prior knowledge, namely the Unified Medical
Language System (UMLS), which is a comprehensive repository of biomedical
vocabularies and standards, for knowledge extraction. Subsequently, we propose
a knowledge injection module that addresses the effective integration of domain
knowledge with complex clinical manifestations, enabling an effective
characterization of the health conditions of the patient. Furthermore,
considering the significant impact of a patient's medication history on their
current medication, we introduce a historical medication-aware patient
representation module to capture the longitudinal influence of historical
medication information on the representation of current patients. Extensive
experiments on three publicly benchmark datasets verify the superiority of our
proposed method, which outperformed other methods by a significant margin. The
code is available at: https://github.com/sherry6247/DKINet.
",2023-05-31 07:22:15+00:00,cs.AI
Non-linear MRD codes from cones over exterior sets,"  By using the notion of $d$-embedding $\Gamma$ of a (canonical) subgeometry
$\Sigma$ and of exterior set with respect to the $h$-secant variety
$\Omega_{h}(\mathcal{A})$ of a subset $\mathcal{A}$, $ 0 \leq h \leq n-1$, in
the finite projective space $\mathrm{PG}(n-1,q^n)$, $n \geq 3$, in this article
we construct a class of non-linear $(n,n,q;d)$-MRD codes for any $ 2 \leq d
\leq n-1$. A code $\mathcal{C}_{\sigma,T}$ of this class, where $1\in T \subset
\mathbb{F}_q^*$ and $\sigma$ is a generator of
$\mathrm{Gal}(\mathbb{F}_{q^n}|\mathbb{F}_q)$, arises from a cone of
$\mathrm{PG}(n-1,q^n)$ with vertex an $(n-d-2)$-dimensional subspace over a
maximum exterior set $\mathcal{E}$ with respect to $\Omega_{d-2}(\Gamma)$. We
prove that the codes introduced in [Cossidente, A., Marino, G., Pavese, F.:
Non-linear maximum rank distance codes. Des. Codes Cryptogr. 79, 597--609
(2016); Durante, N., Siciliano, A.: Non-linear maximum rank distance codes in
the cyclic model for the field reduction of finite geometries. Electron. J.
Comb. (2017); Donati, G., Durante, N.: A generalization of the normal rational
curve in $\mathrm{PG}(d,q^n)$ and its associated non-linear MRD codes. Des.
Codes Cryptogr. 86, 1175--1184 (2018)] are appropriate punctured ones of
$\mathcal{C}_{\sigma,T}$ and solve completely the inequivalence issue for this
class showing that $\mathcal{C}_{\sigma,T}$ is neither equivalent nor adjointly
equivalent to the non-linear MRD code $\mathcal{C}_{n,k,\sigma,I}$, $I
\subseteq \mathbb{F}_q$, obtained in [Otal, K., \""Ozbudak, F.: Some new
non-additive maximum rank distance codes. Finite Fields and Their Applications
50, 293--303 (2018).].
",2023-05-30 13:38:07+00:00,cs.IT
"I/O-efficient iterative matrix inversion with photonic integrated
  circuits","  Photonic integrated circuits have been extensively explored for optical
processing with the aim of breaking the speed bottleneck of digital
electronics. However, the input/output (IO) bottleneck remains one of the key
barriers. Here we report a novel photonic iterative processor (PIP) for
matrix-inversion-intensive applications. The direct reuse of inputted data in
the optical domain unlocks the potential to break the IO bottleneck. We
demonstrate notable IO advantages with a lossless PIP for real-valued matrix
inversion and integral-differential equation solving, as well as a coherent PIP
with optical loops integrated on-chip, enabling complex-valued computation and
a net inversion time of 1.2 ns. Furthermore, we estimate at least an order of
magnitude enhancement in IO efficiency of a PIP over photonic single-pass
processors and the state-of-the-art electronic processors for reservoir
training tasks and MIMO precoding tasks, indicating the huge potential of PIP
technology in practical applications.
",2023-05-26 17:07:50+00:00,cs.ET
Subpopulation-Specific Synthetic EHR for Better Mortality Prediction,"  Electronic health records (EHR) often contain different rates of
representation of certain subpopulations (SP). Factors like patient
demographics, clinical condition prevalence, and medical center type contribute
to this underrepresentation. Consequently, when training machine learning
models on such datasets, the models struggle to generalize well and perform
poorly on underrepresented SPs. To address this issue, we propose a novel
ensemble framework that utilizes generative models. Specifically, we train a
GAN-based synthetic data generator for each SP and incorporate synthetic
samples into each SP training set. Ultimately, we train SP-specific prediction
models. To properly evaluate this method, we design an evaluation pipeline with
2 real-world use case datasets, queried from the MIMIC database. Our approach
shows increased model performance over underrepresented SPs. Our code and
models are given as supplementary and will be made available on a public
repository.
",2023-05-25 09:22:12+00:00,cs.LG
IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers,"  Continuous-time models such as Neural ODEs and Neural Flows have shown
promising results in analyzing irregularly sampled time series frequently
encountered in electronic health records. Based on these models, time series
are typically processed with a hybrid of an initial value problem (IVP) solver
and a recurrent neural network within the variational autoencoder architecture.
Sequentially solving IVPs makes such models computationally less efficient. In
this paper, we propose to model time series purely with continuous processes
whose state evolution can be approximated directly by IVPs. This eliminates the
need for recurrent computation and enables multiple states to evolve in
parallel. We further fuse the encoder and decoder with one IVP solver utilizing
its invertibility, which leads to fewer parameters and faster convergence.
Experiments on three real-world datasets show that the proposed method can
systematically outperform its predecessors, achieve state-of-the-art results,
and have significant advantages in terms of data efficiency.
",2023-05-11 11:53:31+00:00,cs.LG
"Spatial Computing Opportunities in Biomedical Decision Support: The
  Atlas-EHR Vision","  We consider the problem of reducing the time needed by healthcare
professionals to understand patient medical history via the next generation of
biomedical decision support. This problem is societally important because it
has the potential to improve healthcare quality and patient outcomes. However,
navigating electronic health records is challenging due to the high
patient-doctor ratios, potentially long medical histories, the urgency of
treatment for some medical conditions, and patient variability. The current
electronic health record systems provides only a longitudinal view of patient
medical history, which is time-consuming to browse, and doctors often need to
engage nurses, residents, and others for initial analysis. To overcome this
limitation, we envision an alternative spatial representation of patients'
histories (e.g., electronic health records (EHRs)) and other biomedical data in
the form of Atlas-EHR. Just like Google Maps allows a global, national,
regional, and local view, the Atlas-EHR may start with an overview of the
patient's anatomy and history before drilling down to spatially anatomical
sub-systems, their individual components, or sub-components. Atlas-EHR presents
a compelling opportunity for spatial computing since healthcare is almost a
fifth of the US economy. However, the traditional spatial computing designed
for geographic use cases (e.g., navigation, land-surveys, mapping) faces many
hurdles in the biomedical domain. This paper presents a number of open research
questions under this theme in five broad areas of spatial computing.
",2023-05-09 20:56:49+00:00,cs.CY
"Hardware Honeypot: Setting Sequential Reverse Engineering on a Wrong
  Track","  Reverse engineering (RE) of finite state machines (FSMs) is a serious threat
when protecting designs against RE attacks. While most recent protection
techniques rely on the security of a secret key, this work presents a new
approach: hardware FSM honeypots. These honeypots lead the RE tools to a wrong
but, for the tools, very attractive FSM, while making the original FSM less
attractive. The results show that state-of-the-art RE methods favor the highly
attractive honeypot as FSM candidate or do no longer detect the correct,
original FSM.
",2023-05-05 17:38:37+00:00,cs.CR
"Low-Resource Multi-Granularity Academic Function Recognition Based on
  Multiple Prompt Knowledge","  Fine-tuning pre-trained language models (PLMs), e.g., SciBERT, generally
requires large numbers of annotated data to achieve state-of-the-art
performance on a range of NLP tasks in the scientific domain. However,
obtaining the fine-tune data for scientific NLP task is still challenging and
expensive. Inspired by recent advancement in prompt learning, in this paper, we
propose the Mix Prompt Tuning (MPT), which is a semi-supervised method to
alleviate the dependence on annotated data and improve the performance of
multi-granularity academic function recognition tasks with a small number of
labeled examples. Specifically, the proposed method provides multi-perspective
representations by combining manual prompt templates with automatically learned
continuous prompt templates to help the given academic function recognition
task take full advantage of knowledge in PLMs. Based on these prompt templates
and the fine-tuned PLM, a large number of pseudo labels are assigned to the
unlabeled examples. Finally, we fine-tune the PLM using the pseudo training
set. We evaluate our method on three academic function recognition tasks of
different granularity including the citation function, the abstract sentence
function, and the keyword function, with datasets from computer science domain
and biomedical domain. Extensive experiments demonstrate the effectiveness of
our method and statistically significant improvements against strong baselines.
In particular, it achieves an average increase of 5% in Macro-F1 score compared
with fine-tuning, and 6% in Macro-F1 score compared with other semi-supervised
method under low-resource settings. In addition, MPT is a general method that
can be easily applied to other low-resource scientific classification tasks.
",2023-05-05 05:32:50+00:00,cs.CL
"Mechanical Intelligence Simplifies Control in Terrestrial Limbless
  Locomotion","  Limbless locomotors, from microscopic worms to macroscopic snakes, traverse
complex, heterogeneous natural environments typically using undulatory body
wave propagation. Theoretical and robophysical models typically emphasize body
kinematics and active neural/electronic control. However, we contend that
because such approaches often neglect the role of passive, mechanically
controlled processes (those involving ""mechanical intelligence""), they fail to
reproduce the performance of even the simplest organisms. To uncover principles
of how mechanical intelligence aids limbless locomotion in heterogeneous
terradynamic regimes, here we conduct a comparative study of locomotion in a
model of heterogeneous terrain (lattices of rigid posts). We used a model
biological system, the highly studied nematode worm Caenorhabditis elegans, and
a robophysical device whose bilateral actuator morphology models that of
limbless organisms across scales. The robot's kinematics quantitatively
reproduced the performance of the nematodes with purely open-loop control;
mechanical intelligence simplified control of obstacle navigation and
exploitation by reducing the need for active sensing and feedback. An active
behavior observed in C. elegans, undulatory wave reversal upon head collisions,
robustified locomotion via exploitation of the systems' mechanical
intelligence. Our study provides insights into how neurally simple limbless
organisms like nematodes can leverage mechanical intelligence via appropriately
tuned bilateral actuation to locomote in complex environments. These principles
likely apply to neurally more sophisticated organisms and also provide a design
and control paradigm for limbless robots for applications like search and
rescue and planetary exploration.
",2023-04-17 23:04:28+00:00,cs.RO
Optimizing Data-driven Causal Discovery Using Knowledge-guided Search,"  Learning causal relationships solely from observational data often fails to
reveal the underlying causal mechanisms due to the vast search space of
possible causal graphs, which can grow exponentially, especially for greedy
algorithms using score-based approaches. Leveraging prior causal information,
such as the presence or absence of causal edges, can help restrict and guide
the score-based discovery process, leading to a more accurate search. In the
healthcare domain, prior knowledge is abundant from sources like medical
journals, electronic health records (EHRs), and clinical intervention outcomes.
This study introduces a knowledge-guided causal structure search (KGS) approach
that utilizes observational data and structural priors (such as causal edges)
as constraints to learn the causal graph. KGS leverages prior edge information
between variables, including the presence of a directed edge, the absence of an
edge, and the presence of an undirected edge. We extensively evaluate KGS in
multiple settings using synthetic and benchmark real-world datasets, as well as
in a real-life healthcare application related to oxygen therapy treatment. To
obtain causal priors, we use GPT-4 to retrieve relevant literature information.
Our results show that structural priors of any type and amount enhance the
search process, improving performance and optimizing causal discovery. This
guided strategy ensures that the discovered edges align with established causal
knowledge, enhancing the trustworthiness of findings while expediting the
search process. It also enables a more focused exploration of causal
mechanisms, potentially leading to more effective and personalized healthcare
solutions.
",2023-04-11 20:56:33+00:00,cs.AI
"A Transformer-Based Deep Learning Approach for Fairly Predicting
  Post-Liver Transplant Risk Factors","  Liver transplantation is a life-saving procedure for patients with end-stage
liver disease. There are two main challenges in liver transplant: finding the
best matching patient for a donor and ensuring transplant equity among
different subpopulations. The current MELD scoring system evaluates a patient's
mortality risk if not receiving an organ within 90 days. However, the
donor-patient matching should also consider post-transplant risk factors, such
as cardiovascular disease, chronic rejection, etc., which are all common
complications after transplant. Accurate prediction of these risk scores
remains a significant challenge. In this study, we used predictive models to
solve the above challenges. Specifically, we proposed a deep-learning model to
predict multiple risk factors after a liver transplant. By formulating it as a
multi-task learning problem, the proposed deep neural network was trained to
simultaneously predict the five post-transplant risks and achieve equal good
performance by exploiting task-balancing techniques. We also proposed a novel
fairness-achieving algorithm to ensure prediction fairness across different
subpopulations. We used electronic health records of 160,360 liver transplant
patients, including demographic information, clinical variables, and laboratory
values, collected from the liver transplant records of the United States from
1987 to 2018. The model's performance was evaluated using various performance
metrics such as AUROC and AUPRC. Our experiment results highlighted the success
of our multitask model in achieving task balance while maintaining accuracy.
The model significantly reduced the task discrepancy by 39%. Further
application of the fairness-achieving algorithm substantially reduced fairness
disparity among all sensitive attributes (gender, age group, and
race/ethnicity) in each risk factor.
",2023-04-05 22:54:26+00:00,cs.LG
FakET: Simulating Cryo-Electron Tomograms with Neural Style Transfer,"  In cryo-electron microscopy, accurate particle localization and
classification are imperative. Recent deep learning solutions, though
successful, require extensive training data sets. The protracted generation
time of physics-based models, often employed to produce these data sets, limits
their broad applicability. We introduce FakET, a method based on Neural Style
Transfer, capable of simulating the forward operator of any cryo transmission
electron microscope. It can be used to adapt a synthetic training data set
according to reference data producing high-quality simulated micrographs or
tilt-series. To assess the quality of our generated data, we used it to train a
state-of-the-art localization and classification architecture and compared its
performance with a counterpart trained on benchmark data. Remarkably, our
technique matches the performance, boosts data generation speed 750 times, uses
33 times less memory, and scales well to typical transmission electron
microscope detector sizes. It leverages GPU acceleration and parallel
processing. The source code is available at https://github.com/paloha/faket.
",2023-04-04 17:59:09+00:00,cs.LG
"X-CANIDS: Signal-Aware Explainable Intrusion Detection System for
  Controller Area Network-Based In-Vehicle Network","  Controller Area Network (CAN) is an essential networking protocol that
connects multiple electronic control units (ECUs) in a vehicle. However,
CAN-based in-vehicle networks (IVNs) face security risks owing to the CAN
mechanisms. An adversary can sabotage a vehicle by leveraging the security
risks if they can access the CAN bus. Thus, recent actions and cybersecurity
regulations (e.g., UNR 155) require carmakers to implement intrusion detection
systems (IDSs) in their vehicles. The IDS should detect cyberattacks and
provide additional information to analyze conducted attacks. Although many IDSs
have been proposed, considerations regarding their feasibility and
explainability remain lacking. This study proposes X-CANIDS, which is a novel
IDS for CAN-based IVNs. X-CANIDS dissects the payloads in CAN messages into
human-understandable signals using a CAN database. The signals improve the
intrusion detection performance compared with the use of bit representations of
raw payloads. These signals also enable an understanding of which signal or ECU
is under attack. X-CANIDS can detect zero-day attacks because it does not
require any labeled dataset in the training phase. We confirmed the feasibility
of the proposed method through a benchmark test on an automotive-grade embedded
device with a GPU. The results of this work will be valuable to carmakers and
researchers considering the installation of in-vehicle IDSs for their vehicles.
",2023-03-22 03:11:02+00:00,cs.CR
"Convergence of variational Monte Carlo simulation and scale-invariant
  pre-training","  We provide theoretical convergence bounds for the variational Monte Carlo
(VMC) method as applied to optimize neural network wave functions for the
electronic structure problem. We study both the energy minimization phase and
the supervised pre-training phase that is commonly used prior to energy
minimization. For the energy minimization phase, the standard algorithm is
scale-invariant by design, and we provide a proof of convergence for this
algorithm without modifications. The pre-training stage typically does not
feature such scale-invariance. We propose using a scale-invariant loss for the
pretraining phase and demonstrate empirically that it leads to faster
pre-training.
",2023-03-21 05:41:24+00:00,cs.LG
Training Deep Boltzmann Networks with Sparse Ising Machines,"  The slowing down of Moore's law has driven the development of unconventional
computing paradigms, such as specialized Ising machines tailored to solve
combinatorial optimization problems. In this paper, we show a new application
domain for probabilistic bit (p-bit) based Ising machines by training deep
generative AI models with them. Using sparse, asynchronous, and massively
parallel Ising machines we train deep Boltzmann networks in a hybrid
probabilistic-classical computing setup. We use the full MNIST and Fashion
MNIST (FMNIST) dataset without any downsampling and a reduced version of
CIFAR-10 dataset in hardware-aware network topologies implemented in moderately
sized Field Programmable Gate Arrays (FPGA). For MNIST, our machine using only
4,264 nodes (p-bits) and about 30,000 parameters achieves the same
classification accuracy (90%) as an optimized software-based restricted
Boltzmann Machine (RBM) with approximately 3.25 million parameters. Similar
results follow for FMNIST and CIFAR-10. Additionally, the sparse deep Boltzmann
network can generate new handwritten digits and fashion products, a task the
3.25 million parameter RBM fails at despite achieving the same accuracy. Our
hybrid computer takes a measured 50 to 64 billion probabilistic flips per
second, which is at least an order of magnitude faster than superficially
similar Graphics and Tensor Processing Unit (GPU/TPU) based implementations.
The massively parallel architecture can comfortably perform the contrastive
divergence algorithm (CD-n) with up to n = 10 million sweeps per update, beyond
the capabilities of existing software implementations. These results
demonstrate the potential of using Ising machines for traditionally
hard-to-train deep generative Boltzmann networks, with further possible
improvement in nanodevice-based realizations.
",2023-03-19 18:10:15+00:00,cs.ET
Graded Differential Categories and Graded Differential Linear Logic,"  In Linear Logic ($\mathsf{LL}$), the exponential modality $!$ brings forth a
distinction between non-linear proofs and linear proofs, where linear means
using an argument exactly once. Differential Linear Logic ($\mathsf{DiLL}$) is
an extension of Linear Logic which includes additional rules for $!$ which
encode differentiation and the ability of linearizing proofs. On the other
hand, Graded Linear Logic ($\mathsf{GLL}$) is a variation of Linear Logic in
such a way that $!$ is now indexed over a semiring $R$. This $R$-grading allows
for non-linear proofs of degree $r \in R$, such that the linear proofs are of
degree $1 \in R$. There has been recent interest in combining these two
variations of $\mathsf{LL}$ together and developing Graded Differential Linear
Logic ($\mathsf{GDiLL}$). In this paper we present a sequent calculus for
$\mathsf{GDiLL}$, as well as introduce its categorical semantics, which we call
graded differential categories, using both coderelictions and deriving
transformations. We prove that symmetric powers always give graded differential
categories, and provide other examples of graded differential categories. We
also discuss graded versions of (monoidal) coalgebra modalities, additive
bialgebra modalities, and the Seely isomorphisms, as well as their
implementations in the sequent calculus of $\mathsf{GDiLL}$.
",2023-03-19 06:33:22+00:00,cs.LO
"Tensor-based Multimodal Learning for Prediction of Pulmonary Arterial
  Wedge Pressure from Cardiac MRI","  Heart failure is a serious and life-threatening condition that can lead to
elevated pressure in the left ventricle. Pulmonary Arterial Wedge Pressure
(PAWP) is an important surrogate marker indicating high pressure in the left
ventricle. PAWP is determined by Right Heart Catheterization (RHC) but it is an
invasive procedure. A non-invasive method is useful in quickly identifying
high-risk patients from a large population. In this work, we develop a tensor
learning-based pipeline for identifying PAWP from multimodal cardiac Magnetic
Resonance Imaging (MRI). This pipeline extracts spatial and temporal features
from high-dimensional scans. For quality control, we incorporate an epistemic
uncertainty-based binning strategy to identify poor-quality training samples.
To improve the performance, we learn complementary information by integrating
features from multimodal data: cardiac MRI with short-axis and four-chamber
views, and Electronic Health Records. The experimental analysis on a large
cohort of $1346$ subjects who underwent the RHC procedure for PAWP estimation
indicates that the proposed pipeline has a diagnostic value and can produce
promising performance with significant improvement over the baseline in
clinical practice (i.e., $\Delta$AUC $=0.10$, $\Delta$Accuracy $=0.06$, and
$\Delta$MCC $=0.39$). The decision curve analysis further confirms the clinical
utility of our method.
",2023-03-14 00:05:08+00:00,cs.LG
EHRDiff: Exploring Realistic EHR Synthesis with Diffusion Models,"  Electronic health records (EHR) contain a wealth of biomedical information,
serving as valuable resources for the development of precision medicine
systems. However, privacy concerns have resulted in limited access to
high-quality and large-scale EHR data for researchers, impeding progress in
methodological development. Recent research has delved into synthesizing
realistic EHR data through generative modeling techniques, where a majority of
proposed methods relied on generative adversarial networks (GAN) and their
variants for EHR synthesis. Despite GAN-based methods attaining
state-of-the-art performance in generating EHR data, these approaches are
difficult to train and prone to mode collapse. Recently introduced in
generative modeling, diffusion models have established cutting-edge performance
in image generation, but their efficacy in EHR data synthesis remains largely
unexplored. In this study, we investigate the potential of diffusion models for
EHR data synthesis and introduce a novel method, EHRDiff. Through extensive
experiments, EHRDiff establishes new state-of-the-art quality for synthetic EHR
data, protecting private information in the meanwhile.
",2023-03-10 02:15:58+00:00,cs.LG
Breaking Symmetries Leads to Diverse Quadrupedal Gaits,"  Symmetry manifests itself in legged locomotion in a variety of ways. No
matter where a legged system begins to move periodically, the torso and limbs
coordinate with each other's movements in a similar manner. Also, in many gaits
observed in nature, the legs on both sides of the torso move in exactly the
same way, sometimes they are just half a period out of phase. Furthermore, when
some animals move forward and backward, their movements are strikingly similar
as if the time had been reversed. This work aims to generalize these phenomena
and propose formal definitions of symmetries in legged locomotion using group
theory terminology. Symmetries in some common quadrupedal gaits such as
pronking, bounding, half-bounding, and galloping have been discussed. Moreover,
a spring-mass model has been used to demonstrate how breaking symmetries can
alter gaits in a legged system. Studying the symmetries may provide insight
into which gaits may be suitable for a particular robotic design, or may enable
roboticists to design more agile and efficient robot controllers by using
certain gaits.
",2023-03-08 19:48:43+00:00,cs.RO
Photonic Neural Networks: A Compact Review,"  It has long been known that photonic science and especially photonic
communications can raise the speed of technologies and producing manufacturing.
More recently, photonic science has also been interested in its capabilities to
implement low-precision linear operations, such as matrix multiplications, fast
and effciently. For a long time most scientists taught that Electronics is the
end of science but after many years and about 35 years ago had been understood
that electronics do not answer alone and should have a new science. Today we
face modern ways and instruments for doing tasks as soon as possible in
proportion to many decays before. The velocity of progress in science is very
fast. All our progress in science area is dependent on modern knowledge about
new methods. In this research, we want to review the concept of a photonic
neural network. For this research was selected 18 main articles were among the
main 30 articles on this subject from 2015 to the 2022 year. These articles
noticed three principles: 1- Experimental concepts, 2- Theoretical concepts,
and, finally 3- Mathematic concepts. We should be careful with this research
because mathematics has a very important and constructive role in our topics!
One of the topics that are very valid and also new, is simulation. We used to
work with simulation in some parts of this research. First, briefly, we start
by introducing photonics and neural networks. In the second we explain the
advantages and disadvantages of a combination of both in the science world and
industries and technologies about them. Also, we are talking about the
achievements of a thin modern science. Third, we try to introduce some
important and valid parameters in neural networks. In this manner, we use many
mathematic tools in some portions of this article.
",2023-02-16 16:10:02+00:00,cs.NE
"The Independence Postulate, the Many Worlds Theory, and Constructor
  Theory","  The Many Worlds Theory and Constructor Theory are in conflict with the
Independence Postulate. The conflict with the Many Worlds Theory is shown
through the existence of a finite experiment that measures the spin of a large
number of electrons. After the experiment there are branches of positive
probability which contain forbidden sequences that break the Independence
Postulate. Constructor Theory consists of counterfactuals, decreeing certain
processes can or cannot occur. However this binary classification meets
challenges when describing whether a forbidden sequence can be found or
created.
",2023-02-14 17:48:23+00:00,cs.CC
Roadmap for Unconventional Computing with Nanotechnology,"  In the ""Beyond Moore's Law"" era, with increasing edge intelligence,
domain-specific computing embracing unconventional approaches will become
increasingly prevalent. At the same time, adopting a variety of
nanotechnologies will offer benefits in energy cost, computational speed,
reduced footprint, cyber resilience, and processing power. The time is ripe for
a roadmap for unconventional computing with nanotechnologies to guide future
research, and this collection aims to fill that need. The authors provide a
comprehensive roadmap for neuromorphic computing using electron spins,
memristive devices, two-dimensional nanomaterials, nanomagnets, and various
dynamical systems. They also address other paradigms such as Ising machines,
Bayesian inference engines, probabilistic computing with p-bits, processing in
memory, quantum memories and algorithms, computing with skyrmions and spin
waves, and brain-inspired computing for incremental learning and
problem-solving in severely resource-constrained environments. These approaches
have advantages over traditional Boolean computing based on von Neumann
architecture. As the computational requirements for artificial intelligence
grow 50 times faster than Moore's Law for electronics, more unconventional
approaches to computing and signal processing will appear on the horizon, and
this roadmap will help identify future needs and challenges. In a very fertile
field, experts in the field aim to present some of the dominant and most
promising technologies for unconventional computing that will be around for
some time to come. Within a holistic approach, the goal is to provide pathways
for solidifying the field and guiding future impactful discoveries.
",2023-01-17 07:00:28+00:00,cs.ET
"Waveflow: boundary-conditioned normalizing flows applied to fermionic
  wavefunctions","  An efficient and expressive wavefunction ansatz is key to scalable solutions
for complex many-body electronic structures. While Slater determinants are
predominantly used for constructing antisymmetric electronic wavefunction
ans\""{a}tze, this construction can result in limited expressiveness when the
targeted wavefunction is highly complex. In this work, we introduce Waveflow,
an innovative framework for learning many-body fermionic wavefunctions using
boundary-conditioned normalizing flows. Instead of relying on Slater
determinants, Waveflow imposes antisymmetry by defining the fundamental domain
of the wavefunction and applying necessary boundary conditions. A key challenge
in using normalizing flows for this purpose is addressing the topological
mismatch between the prior and target distributions. We propose using O-spline
priors and I-spline bijections to handle this mismatch, which allows for
flexibility in the node number of the distribution while automatically
maintaining its square-normalization property. We apply Waveflow to a
one-dimensional many-electron system, where we variationally minimize the
system's energy using variational quantum Monte Carlo (VQMC). Our experiments
demonstrate that Waveflow can effectively resolve topological mismatches and
faithfully learn the ground-state wavefunction.
",2022-11-27 14:32:09+00:00,cs.LG
"A Comprehensive Benchmark for COVID-19 Predictive Modeling Using
  Electronic Health Records in Intensive Care","  The COVID-19 pandemic has posed a heavy burden to the healthcare system
worldwide and caused huge social disruption and economic loss. Many deep
learning models have been proposed to conduct clinical predictive tasks such as
mortality prediction for COVID-19 patients in intensive care units using
Electronic Health Record (EHR) data. Despite their initial success in certain
clinical applications, there is currently a lack of benchmarking results to
achieve a fair comparison so that we can select the optimal model for clinical
use. Furthermore, there is a discrepancy between the formulation of traditional
prediction tasks and real-world clinical practice in intensive care. To fill
these gaps, we propose two clinical prediction tasks, Outcome-specific
length-of-stay prediction and Early mortality prediction for COVID-19 patients
in intensive care units. The two tasks are adapted from the naive
length-of-stay and mortality prediction tasks to accommodate the clinical
practice for COVID-19 patients. We propose fair, detailed, open-source
data-preprocessing pipelines and evaluate 17 state-of-the-art predictive models
on two tasks, including 5 machine learning models, 6 basic deep learning models
and 6 deep learning predictive models specifically designed for EHR data. We
provide benchmarking results using data from two real-world COVID-19 EHR
datasets. One dataset is publicly available without needing any inquiry and
another dataset can be accessed on request. We provide fair, reproducible
benchmarking results for two tasks. We deploy all experiment results and models
on an online platform. We also allow clinicians and researchers to upload their
data to the platform and get quick prediction results using our trained models.
We hope our efforts can further facilitate deep learning and machine learning
research for COVID-19 predictive modeling.
",2022-09-16 09:09:15+00:00,cs.LG
"Self-supervised Representation Learning on Electronic Health Records
  with Graph Kernel Infomax","  Learning Electronic Health Records (EHRs) representation is a preeminent yet
under-discovered research topic. It benefits various clinical decision support
applications, e.g., medication outcome prediction or patient similarity search.
Current approaches focus on task-specific label supervision on vectorized
sequential EHR, which is not applicable to large-scale unsupervised scenarios.
Recently, contrastive learning shows great success on self-supervised
representation learning problems. However, complex temporality often degrades
the performance. We propose Graph Kernel Infomax, a self-supervised graph
kernel learning approach on the graphical representation of EHR, to overcome
the previous problems. Unlike the state-of-the-art, we do not change the graph
structure to construct augmented views. Instead, we use Kernel Subspace
Augmentation to embed nodes into two geometrically different manifold views.
The entire framework is trained by contrasting nodes and graph representations
on those two manifold views through the commonly used contrastive objectives.
Empirically, using publicly available benchmark EHR datasets, our approach
yields performance on clinical downstream tasks that exceeds the
state-of-the-art. Theoretically, the variation on distance metrics naturally
creates different views as data augmentation without changing graph structures.
",2022-09-01 16:15:08+00:00,cs.LG
One-Time Certificates for Reliable and Secure Document Signing,"  Electronic documents are signed using private keys and verified using the
corresponding digital certificates through the well-known public key
infrastructure model. Private keys must be kept in a safe container so they can
be reused. This makes private key management a critical component of public key
infrastructures with no failproof answer. Therefore, existing solutions must
employ cumbersome and often expensive revocation methods to handle private key
compromises. We propose a new cryptographic key management model built with
long-term, irrevocable digital certificates, each bound to a single document.
Our model issues a unique digital certificate for each new document to be
signed. We demonstrate that private keys associated with these certificates
should be deleted after each signature, eliminating the need to store those
keys. Furthermore, we show that these certificates do not require any
revocation mechanism to be trusted. We analyze the overhead caused by the
frequent generation of new key pairs for each document, provide a security
overview and show the advantages over the traditional model.
",2022-08-08 07:39:54+00:00,cs.CR
RF-Photonic Deep Learning Processor with Shannon-Limited Data Movement,"  Edholm's Law predicts exponential growth in data rate and spectrum bandwidth
for communications and is forecasted to remain true for the upcoming deployment
of 6G. Compounding this issue is the exponentially increasing demand for deep
neural network (DNN) compute, including DNNs for signal processing. However,
the slowing of Moore's Law due to the limitations of transistor-based
electronics means that completely new paradigms for computing will be required
to meet these increasing demands for advanced communications. Optical neural
networks (ONNs) are promising DNN accelerators with ultra-low latency and
energy consumption. Yet state-of-the-art ONNs struggle with scalability and
implementing linear with in-line nonlinear operations. Here we introduce our
multiplicative analog frequency transform ONN (MAFT-ONN) that encodes the data
in the frequency domain, achieves matrix-vector products in a single shot using
photoelectric multiplication, and uses a single electro-optic modulator for the
nonlinear activation of all neurons in each layer. We experimentally
demonstrate the first hardware accelerator that computes fully-analog deep
learning on raw RF signals, performing single-shot modulation classification
with 85% accuracy, where a 'majority vote' multi-measurement scheme can boost
the accuracy to 95% within 5 consecutive measurements. In addition, we
demonstrate frequency-domain finite impulse response (FIR)
linear-time-invariant (LTI) operations, enabling a powerful combination of
traditional and AI signal processing. We also demonstrate the scalability of
our architecture by computing nearly 4 million fully-analog
multiplies-and-accumulates for MNIST digit classification. Our latency
estimation model shows that due to the Shannon capacity-limited analog data
movement, MAFT-ONN is hundreds of times faster than traditional RF receivers
operating at their theoretical peak performance.
",2022-07-08 16:37:13+00:00,cs.ET
"Tree-Guided Rare Feature Selection and Logic Aggregation with Electronic
  Health Records Data","  Statistical learning with a large number of rare binary features is commonly
encountered in analyzing electronic health records (EHR) data, especially in
the modeling of disease onset with prior medical diagnoses and procedures.
Dealing with the resulting highly sparse and large-scale binary feature matrix
is notoriously challenging as conventional methods may suffer from a lack of
power in testing and inconsistency in model fitting while machine learning
methods may suffer from the inability of producing interpretable results or
clinically-meaningful risk factors. To improve EHR-based modeling and utilize
the natural hierarchical structure of disease classification, we propose a
tree-guided feature selection and logic aggregation approach for large-scale
regression with rare binary features, in which dimension reduction is achieved
through not only a sparsity pursuit but also an aggregation promoter with the
logic operator of ``or''. We convert the combinatorial problem into a convex
linearly-constrained regularized estimation, which enables scalable computation
with theoretical guarantees. In a suicide risk study with EHR data, our
approach is able to select and aggregate prior mental health diagnoses as
guided by the diagnosis hierarchy of the International Classification of
Diseases. By balancing the rarity and specificity of the EHR diagnosis records,
our strategy improves both prediction and model interpretation. We identify
important higher-level categories and subcategories of mental health conditions
and simultaneously determine the level of specificity needed for each of them
in predicting suicide risk.
",2022-06-18 03:52:43+00:00,cs.LG
"CAN-MM: Multiplexed Message Authentication Code for Controller Area
  Network message authentication in road vehicles","  The automotive market is increasingly profitable for cyberattacks with the
constant shift toward fully interconnected vehicles. Electronic Control Units
(ECUs) installed on cars often operate in a critical and hostile environment.
Hence, both carmakers and governments have decided to support a series of
initiatives to mitigate risks and threats belonging to the automotive domain.
The Controller Area Network (CAN) is the primary communication protocol in the
automotive field, and the integrity of the communication over this network is
assured through Message Authentication Codes (MAC). However, limitations in
throughput and frame size limit the application of this technique to specific
versions of the CAN protocol, leaving several vehicles still unprotected. This
paper presents CAN Multiplexed MAC (CAN-MM), a new approach exploiting
frequency modulation to multiplex MAC data with standard CAN communication.
CAN-MM allows transmitting MAC payloads maintaining full-back compatibility
with all versions of the standard CAN protocol. Moreover, multiplexing allows
sending DATA and MAC simultaneously.
",2022-06-06 13:21:22+00:00,cs.CR
"Towards Secure Virtual Elections: Multiparty Computation of Order Based
  Voting Rules","  Electronic voting systems are essential for holding virtual elections, and
the need for such systems increases due to the COVID-19 pandemic and the social
distancing that it mandates. One of the main challenges in e-voting systems is
to secure the voting process: namely, to certify that the computed results are
consistent with the cast ballots, and that the privacy of the voters is
preserved. We propose herein a secure voting protocol for elections that are
governed by order-based voting rules. Our protocol offers perfect ballot
secrecy, in the sense that it issues only the required output, while no other
information on the cast ballots is revealed. Such perfect secrecy, which is
achieved by employing secure multiparty computation tools, may increase the
voters' confidence and, consequently, encourage them to vote according to their
true preferences. Evaluation of the protocol's computational costs establishes
that it is lightweight and can be readily implemented in real-life electronic
elections.
",2022-05-21 12:17:21+00:00,cs.CR
TRIP: Trust-Limited Coercion-Resistant In-Person Voter Registration,"  Remote electronic voting is convenient and flexible, but presents risks of
coercion and vote buying. One promising mitigation strategy enables voters to
give a coercer fake voting credentials, which silently cast votes that do not
count. However, current proposals make problematic assumptions during
credential issuance, such as relying on a trustworthy registrar, on trusted
hardware, or on voters interacting with multiple registrars. We present TRIP,
the first voter registration scheme that addresses these challenges by
leveraging the physical security of in-person interaction. Voters use a kiosk
in a privacy booth to print real and fake paper credentials, which appear
indistinguishable to others. Voters interact with only one authority, need no
trusted hardware during credential issuance, and need not trust the registrar
except when actually under coercion. For verifiability, each credential
includes an interactive zero-knowledge proof, which is sound in real
credentials and unsound in fake credentials. Voters learn the difference by
observing the order of printing steps, and need not understand the technical
details. We prove formally that TRIP satisfies coercion-resistance and
verifiability. In a user study with 150 participants, 83% successfully used
TRIP.
",2022-02-14 13:35:46+00:00,cs.CR
Structure-based Optical Logics Without Using Transistors,"  The commercialization of transistors capable of both switching and
amplification in 1960 resulted in the development of second-generation
computers, which resulted in the miniaturization and lightening while
accelerating the reduction and development of production costs. However, the
self-resistance and the resistance used in conjunction with semiconductors,
which are the basic principles of computers, generate a lot of heat, which
results in semiconductor obsolescence, and limits the computation speed (clock
rate). In implementing logic operation, this paper proposes the concept of
Structure-based Computer which can implement NOT gate made of semiconductor
transistor only by Structure-based twist of cable without resistance. In
Structure-based computer, the theory of 'inverse signal pair' of digital
signals was introduced so that it could operate in a different way than
semiconductor-based transistors. In this paper, we propose a new hardware
called Structure-based computer that can solve various problems in
semiconductor computers only with the wiring structure of the conductor itself,
not with the silicon-based semiconductor. Furthermore, we propose a
deep-priority exploration-based simulation method that can easily implement and
test complex Structure-based computer circuits. Furthermore, this paper
suggests a mechanism to implement optical computers currently under development
and research based on structures rather than devices.
",2020-10-25 11:41:10+00:00,cs.ET
"Blockchain in Healthcare and Medicine: A Contemporary Research of
  Applications, Challenges, and Future Perspectives","  Blockchain technology is one of the most contemporary and disruptive
technologies in the world. It has gained considerable attention in numerous
applications such as financial services, cybersecurity applications, Internet
of Things (IoT), network data management. Now its range of applications is
beyond the financial services as the healthcare industry has also adopted
blockchain technology in its various subdomains such as Electronic Health
Records (EHR), medical supply chain management system, genomic market,
neuroscience technology, clinical research, and pharmaceutical medicine.
Blockchain is considered a secure and viable solution for storing and accessing
patients medical records and the patients can diagnosed and treated with safe
and secure data sharing. Blockchain technology will revolutionize the
healthcare systems with personalized, authentic, and secure access to the
clinical data of patients and that data can be used for further health
improvements and clinical researches. In this paper, we conduct a contemporary
research on existing applications and developments in healthcare industry with
the use of blockchain technology. We also discuss some robust applications and
various existing companies that are using blockchain solutions for securing
their data along with some current challenges and future perspectives.
",2020-03-30 20:18:13+00:00,cs.CR
Evaluation of Rounding Functions in Nearest-Neighbor Interpolation,"  A novel evaluation study of the most appropriate round function for
nearest-neighbor (NN) image interpolation is presented. Evaluated rounding
functions are selected among the five rounding rules defined by the Institute
of Electrical and Electronics Engineers (IEEE) 754-2008 standard. Both full-
and no-reference image quality assessment (IQA) metrics are used to study and
evaluate the influence of rounding functions on NN interpolation image quality.
The concept of achieved occurrences over targeted occurrences is used to
determine the percentage of achieved occurrences based on the number of test
images used. Inferential statistical analysis is applied to deduce from a small
number of images and draw a conclusion of the behavior of each rounding
function on a bigger number of images. Under the normal distribution and at the
level of confidence equals to 95%, the maximum and minimum achievable
occurrences by each evaluated rounding function are both provided based on the
inferential analysis-based experiments.
",2020-03-15 18:17:36+00:00,cs.CV
FDive: Learning Relevance Models using Pattern-based Similarity Measures,"  The detection of interesting patterns in large high-dimensional datasets is
difficult because of their dimensionality and pattern complexity. Therefore,
analysts require automated support for the extraction of relevant patterns. In
this paper, we present FDive, a visual active learning system that helps to
create visually explorable relevance models, assisted by learning a
pattern-based similarity. We use a small set of user-provided labels to rank
similarity measures, consisting of feature descriptor and distance function
combinations, by their ability to distinguish relevant from irrelevant data.
Based on the best-ranked similarity measure, the system calculates an
interactive Self-Organizing Map-based relevance model, which classifies data
according to the cluster affiliation. It also automatically prompts further
relevance feedback to improve its accuracy. Uncertain areas, especially near
the decision boundaries, are highlighted and can be refined by the user. We
evaluate our approach by comparison to state-of-the-art feature selection
techniques and demonstrate the usefulness of our approach by a case study
classifying electron microscopy images of brain cells. The results show that
FDive enhances both the quality and understanding of relevance models and can
thus lead to new insights for brain research.
",2019-07-29 15:37:43+00:00,cs.LG
"Model-less Active Compliance for Continuum Robots using Recurrent Neural
  Networks","  Endowing continuum robots with compliance while it is interacting with the
internal environment of the human body is essential to prevent damage to the
robot and the surrounding tissues. Compared with passive compliance, active
compliance has the advantages in terms of increasing the force transmission
ability and improving safety with monitored force output. Previous studies have
demonstrated that active compliance can be achieved based on a complex model of
the mechanics combined with a traditional machine learning technique such as a
support vector machine. This paper proposes a recurrent neural network based
approach that avoids the complexity of modeling while capturing nonlinear
factors such as hysteresis, friction and delay of the electronics that are not
easy to model. The approach is tested on a 3-tendon single-segment continuum
robot with force sensors on each cable. Experiments are conducted to
demonstrate that the continuum robot with an RNN based feed-forward controller
is capable of responding to external forces quickly and entering an unknown
environment compliantly.
",2019-02-24 13:32:13+00:00,cs.RO
"Confidence Trigger Detection: Accelerating Real-time
  Tracking-by-detection Systems","  Real-time object tracking necessitates a delicate balance between speed and
accuracy, a challenge exacerbated by the computational demands of deep learning
methods. In this paper, we propose Confidence-Triggered Detection (CTD), an
innovative approach that strategically bypasses object detection for frames
closely resembling intermediate states, leveraging tracker confidence scores.
CTD not only enhances tracking speed but also preserves accuracy, surpassing
existing tracking algorithms. Through extensive evaluation across various
tracker confidence thresholds, we identify an optimal trade-off between
tracking speed and accuracy, providing crucial insights for parameter
fine-tuning and enhancing CTD's practicality in real-world scenarios. Our
experiments across diverse detection models underscore the robustness and
versatility of the CTD framework, demonstrating its potential to enable
real-time tracking in resource-constrained environments.
",2019-02-02 01:52:53+00:00,cs.CV
"Contextual Hourglass Network for Semantic Segmentation of High
  Resolution Aerial Imagery","  Semantic segmentation for aerial imagery is a challenging and important
problem in remotely sensed imagery analysis. In recent years, with the success
of deep learning, various convolutional neural network (CNN) based models have
been developed. However, due to the varying sizes of the objects and imbalanced
class labels, it can be challenging to obtain accurate pixel-wise semantic
segmentation results. To address those challenges, we develop a novel semantic
segmentation method and call it Contextual Hourglass Network. In our method, in
order to improve the robustness of the prediction, we design a new contextual
hourglass module which incorporates attention mechanism on processed
low-resolution featuremaps to exploit the contextual semantics. We further
exploit the stacked encoder-decoder structure by connecting multiple contextual
hourglass modules from end to end. This architecture can effectively extract
rich multi-scale features and add more feedback loops for better learning
contextual semantics through intermediate supervision. To demonstrate the
efficacy of our semantic segmentation method, we test it on Potsdam and
Vaihingen datasets. Through the comparisons to other baseline methods, our
method yields the best results on overall performance.
",2018-10-30 15:33:47+00:00,cs.CV
