{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "csv_path = '/Users/bryansoh/Documents/NUS/PLP/Group Project/plp_practice_proj-1/arxiv/arxiv_cs_papers_2022_2024_clean.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Step 2: Load a pre-trained LLM model for embeddings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # A good model for embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Step 3: Initialize Chroma vector store\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(\"research_papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "# Step 4: Function to get embeddings\n",
    "def get_embeddings(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Step 5: Embed title and summary columns\n",
    "df['combined'] = df['Title'] + ' ' + df['Summary']\n",
    "combined_texts = df['combined'].tolist()\n",
    "\n",
    "# Process in batches to avoid memory issues\n",
    "batch_size = 100  # Adjust batch size as needed\n",
    "\n",
    "# Use tqdm for progress tracking\n",
    "with tqdm(total=len(combined_texts), desc=\"Processing batches\", unit=\"doc\") as pbar:\n",
    "    for i in range(0, len(combined_texts), batch_size):\n",
    "        batch_texts = combined_texts[i:i + batch_size]\n",
    "        embeddings = get_embeddings(batch_texts)\n",
    "        \n",
    "        # Step 6: Store embeddings and metadata in Chroma\n",
    "        for idx, embed in enumerate(embeddings):\n",
    "            global_idx = i + idx  # Ensure we have a global index to avoid out-of-bound errors\n",
    "            \n",
    "            if global_idx < len(df):  # Ensure global_idx is within the bounds of the dataframe\n",
    "                # Add unique IDs and ensure embeddings are converted properly\n",
    "                collection.add(\n",
    "                    ids=[f\"doc_{global_idx}\"],  # Generate unique IDs for each document\n",
    "                    documents=[batch_texts[idx]],\n",
    "                    embeddings=embed.cpu().numpy().tolist(),  # Ensure embeddings are lists of floats\n",
    "                    metadatas={\n",
    "                        \"Title\": df['Title'][global_idx],\n",
    "                        \"Summary\": df['Summary'][global_idx],\n",
    "                        \"Updated\": str(df['Updated'][global_idx]),\n",
    "                        \"Category\": df['Category'][global_idx]\n",
    "                    }\n",
    "                )\n",
    "        # Update the progress bar by the batch size\n",
    "        pbar.update(len(batch_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Function to perform vector-based search\n",
    "def vector_search(query, top_n=5):\n",
    "    query_embedding = get_embeddings([query])\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding.cpu().numpy().tolist(),\n",
    "        n_results=top_n\n",
    "    )\n",
    "    # Flatten the metadata list if needed\n",
    "    vector_results = flatten(results['metadatas'])\n",
    "    return vector_results\n",
    "\n",
    "# Flatten function\n",
    "def flatten(results):\n",
    "    flat_results = []\n",
    "    for sublist in results:\n",
    "        if isinstance(sublist, list):\n",
    "            flat_results.extend(sublist)\n",
    "        else:\n",
    "            flat_results.append(sublist)\n",
    "    return flat_results\n",
    "\n",
    "# Step 8: Function to perform keyword-based search\n",
    "def keyword_search(query, top_n=5):\n",
    "    keyword_results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if query.lower() in row['combined'].lower():\n",
    "            keyword_results.append({\n",
    "                \"Title\": row['Title'],\n",
    "                \"Updated\": str(row['Updated']),\n",
    "                \"Category\": row['Category']\n",
    "            })\n",
    "        if len(keyword_results) >= top_n:\n",
    "            break\n",
    "    return keyword_results\n",
    "\n",
    "# Step 9: Hybrid search that combines vector and keyword search results\n",
    "def hybrid_search(query, top_n=5):  # Changed top_n to 5\n",
    "    # Perform vector and keyword search\n",
    "    vector_results = vector_search(query, top_n)\n",
    "    keyword_results = keyword_search(query, top_n)\n",
    "\n",
    "    # Combine results, ensuring no duplicates\n",
    "    combined_results = []\n",
    "    seen_titles = set()\n",
    "\n",
    "    # Add vector search results\n",
    "    for result in vector_results:\n",
    "        if isinstance(result, dict) and 'Title' in result:\n",
    "            if result['Title'] not in seen_titles:\n",
    "                combined_results.append(result)\n",
    "                seen_titles.add(result['Title'])\n",
    "\n",
    "    # Add keyword search results\n",
    "    for result in keyword_results:\n",
    "        if result['Title'] not in seen_titles:\n",
    "            combined_results.append(result)\n",
    "            seen_titles.add(result['Title'])\n",
    "\n",
    "    # Limit to top_n results\n",
    "    return combined_results[:top_n]\n",
    "\n",
    "# Step 10: Example usage\n",
    "query = input(\"Enter a keyword to search: \")\n",
    "results = hybrid_search(query, top_n=5)  # Changed top_n to 5\n",
    "\n",
    "# Print the results without the summary\n",
    "for result in results:\n",
    "    title = result.get('Title', 'No Title')\n",
    "    category = result.get('Category', 'No Category')\n",
    "    updated = result.get('Updated', 'No Date')\n",
    "    \n",
    "    # Print the formatted results without the summary\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Updated: {updated}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
